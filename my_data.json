[{"_additional": {"id": "d15d6ad1-03a0-48bb-9821-8a9cc5847234", "vector": [-0.008314788, -0.3217659, -0.080114394, -0.18005024, -0.006959633, -0.16126756, -0.20056473, -0.06903009, 0.0106484685, 0.019812461, -0.06475419, 0.23374104, 0.11799327, 0.0105029475, 0.25289577, -0.03385262, 0.10562768, -0.10547904, -0.3972621, -0.027526569, -0.23296751, -0.019928811, 0.09254084, 0.061109126, -0.062943846, 0.16705361, 0.085564524, -0.08677456, -0.17522568, -0.10748898, -0.027835127, 0.093510255, 0.17326617, -0.17830572, -0.14952491, 0.121562414, 0.055778097, 0.061034482, -0.061909113, -0.0748007, -0.05980849, -0.0067994595, -0.01585118, 0.104983106, -0.0007827262, -0.11536078, 0.02847961, -0.019656258, -0.05894088, -0.00067932904, -0.046057735, -0.12842236, -0.07886159, -0.10049829, -0.043753993, 0.1439177, 0.2451609, 0.013484159, -0.01180999, 0.009937918, -0.17749502, -0.0590817, -0.24633475, 0.28300944, 0.23904559, 0.061473094, 0.030031944, -0.079927586, -0.11948799, 0.28694594, -0.16282764, -0.21611805, 0.052852023, 0.15638717, 0.12631744, -0.14403392, 0.13544478, -0.08254052, 0.10267639, 0.026855536, -0.0047309333, -0.021291144, 0.034558956, 0.046411507, 0.05536896, 0.018483667, 0.15402246, 0.053310778, 0.16440967, -0.09066672, -0.19810447, -0.01905878, -0.09175368, 0.11477016, 0.034991845, 0.19529389, -0.094063565, -0.16572337, -0.010026352, 0.014974105, -0.20396426, -0.046430968, 0.10091933, -0.0867376, 0.10693797, -0.35545075, 0.008435536, 0.16904452, -0.021876484, -0.08185603, 0.0068793753, 0.0714475, 0.0032368025, -0.14648508, -0.018302122, 0.023265574, -0.17125668, -0.019936442, 0.09499828, -0.05191355, 0.047072675, 0.03212022, 0.071468465, -0.054828815, -0.0049039056, -0.09537551, -0.12884976, 0.11280747, 0.074189186, -0.0020974437, 0.22160071, -0.02477304, 0.11262752, 0.12050311, 0.051836405, -0.10066743, 0.2380503, -0.018656274, 0.053903997, 0.19693525, -0.03138471, 0.3832425, 0.0254784, -0.009513019, -0.1600565, 0.25133932, -0.1965623, -0.013059886, 0.066628665, -0.3706001, -0.04818604, 0.030491345, 0.17723776, -0.21503648, 0.26357237, -0.015862599, 0.009028087, 0.07141847, -0.13124974, -0.03813206, -0.2721353, 0.054127917, -0.12524839, -0.3105388, 0.13526249, -0.032783825, 0.082173936, -0.061702624, -0.012824589, 0.18965945, -0.04065021, 0.010947738, 0.042931516, 0.03488511, 0.06213508, 0.00023311973, -0.27916533, -0.04993327, 0.044572912, 0.07271135, 0.322274, 0.15609296, -0.017965456, 0.07854931, -0.0049357275, -0.106121376, 0.15149322, -0.035047974, -0.12338747, -0.08791206, -0.1655707, 0.072127186, 0.16037588, 0.100111514, -0.17298852, -0.006461103, 0.22175764, 0.023270579, 0.05491587, -0.03876572, -0.37534955, -0.03495954, 0.051931795, -0.18009211, 0.07155804, -0.06184341, 0.045640565, 0.020609075, -0.012002994, 0.16554111, -0.10401675, -0.18363622, 0.007779884, 0.14907129, 0.11701269, 0.018178044, -0.088203445, -0.012786899, -0.11053451, -0.006548489, 0.036886293, -0.08857017, -0.06362637, -0.42686766, -0.17858249, -0.17256746, 0.18537308, 0.21767673, 0.0078628985, 0.15111089, 0.18356122, 0.05624346, 0.17506489, 0.14916854, -0.07070196, 0.014121343, 0.10485676, -0.1901651, 0.053718697, -0.055546284, 0.12140381, -0.05613262, 0.11992066, 0.029726397, 0.06675581, 0.08650463, -0.26211396, 0.07273756, -0.056215845, 0.13498154, -0.41999188, 0.043870386, -0.1835113, 0.115604974, -0.34870207, 0.21717663, -0.28329092, -0.037504517, -0.1214143, 0.14262529, 0.11755849, -0.014023227, -0.10365431, 0.037379622, -0.0027851264, -0.066788085, -0.12941712, 0.05948794, -0.24562033, -0.16208714, -0.0947719, 0.06691809, -0.023054752, -0.09424709, 0.08735631, 0.3412777, -0.03531871, -0.15801764, -0.26932368, -0.096136756, 0.15340716, -0.20851465, -0.21659258, 0.21093747, 0.08800344, -0.15235859, 0.027721023, -0.072946385, 0.15039425, -0.106360465, 0.20428433, 0.04423319, 0.1198856, -0.008129888, 0.02549415, 0.0974438, -0.008786086, 0.351307, 0.044761013, -0.21731535, 0.2190147, -0.053046953, -0.21902308, -0.11468223, -0.021128966, -0.10926409, 0.09472556, 0.09435721, 0.042300936, 0.14239772, -0.025830986, -0.08255646, -0.13622148, 0.1628699, -0.06086609, 0.13731049, -0.16671762, 0.20985126, -0.17630766, -0.065047875, -0.076421246, -0.16229485, 0.1945668, 0.34847516, -0.07840035, 0.040880468, -0.06419799, 0.09423158, -0.15328202, -0.19306596, 0.16168295, -0.021282068, 0.003288437, 0.1948506, 0.13915877, 0.2650781, 0.10277779, 0.05753548, -0.1271697, 0.078534596, 0.1796176, 0.22393487, -0.011397454, 0.012014284, 0.11143609, 0.08980463, 0.14918382, 0.3074651, -0.014800405, 0.023403486, -0.05801515, 0.23951678, -0.19227764, -0.016430901, 0.09630815, -0.018154109, -0.03459712, -0.059997667, 0.091001526, -0.22851667, 0.13089843, -0.07909151, -0.10325951, 0.30787918, -0.04163817, 0.015237109, 0.013879593, -0.09046843, -0.08791398, 0.19699468, 0.17040248, 0.1936207, -0.007524839, -0.05138495, 0.2156548, -0.031205123, 0.013375654, -0.09042435, -0.13319445, 0.3114978, 0.3043876, 0.016544871, 0.23353103, -0.081439085]}, "content": "I think the paradigm and there's a good quote from Stan from dust, and so I'm going to shamelessly steal it here. But he has a great quote. That's like, no GPUs before PMF, which is basically like no GPUs, no fine tuning of models before PMF product market fit before you know what you're doing. And I think like, the power of large language models is that they're so good as just like arbitrary tasks, and you can get them to do like, basically whatever. And so experimenting with like different pipelines or different things that you're doing is really it's it's so much easier than before. And so I think the common thing will basically be like, you know, experiment with the best models, then when you actually get something that's like working, and you want to scale it up, not even that's like what like, when it's working, and it's just for you, it's probably fine. But when you want to like scale it up, then you need to worry about like fine tuning models. And so I think it's also kind of like a progression as well. Like, you know, if I if I was building an application, I would never start with a fine, I would never start with fine tuning. No, I'd start with the language model. And then when I start with the biggest language model, GPT-3 or something like that. And then when, yeah, when when, when I get to the point where I have enough confidence that I need to scale it up, then I'd start thinking about that. And I think that'll be like a pretty common workflow. And I've already seen a few people in Yeah, I've already seen a few people like doing that. It's, it's not that crazy, right? ", "podNum": 36, "speaker": "Harrison Chase"}, {"_additional": {"id": "d25eae6b-2b70-46c8-ae66-287b2e2b0b49", "vector": [-0.014409381, -0.23331475, -0.26205263, -0.24569573, -0.18393469, -0.1941721, 0.054228704, -0.06900654, 0.080022104, -0.040589657, -0.087011576, -0.032990035, -0.18746327, -0.06538462, 0.2798026, -0.12935475, 0.13439848, -0.2783702, -0.42895687, -0.042939294, -0.14531107, -0.26467147, 0.06181332, -0.060060397, -0.10082871, 0.00077546324, 0.09843147, 0.019010605, -0.2920314, -0.060465124, 0.10566837, 0.1608278, -0.28925362, -0.11502618, -0.051797513, 0.08475262, 0.092769235, -0.0391268, 0.16072747, -0.14865059, -0.12771757, -0.23384257, -0.06457984, 0.21519004, 0.063625716, 0.03472459, -0.09771243, 0.060249228, 0.124453686, 0.03097012, 0.3502408, -0.0029296677, 0.043060422, -0.080650695, -0.08350151, 0.36268964, 0.10475608, -0.013431619, -0.0038173813, -0.120872915, 0.26643085, -0.22080605, -0.07654448, 0.49923137, 0.0051472783, -0.32212633, 0.050813165, -0.14598788, 0.035140205, -0.107339285, -0.21808888, -0.09120574, 0.009618272, -0.0075292788, 0.18762599, -0.1074327, 0.12245455, -0.16160974, -0.066508524, 0.10758837, 0.27903223, -0.1574106, 0.15594056, -0.010760446, 0.22587788, -0.023616573, -0.17675345, 0.09775705, -0.34428754, -0.013908491, -0.118872404, -0.077671625, 0.14967488, 0.08014229, -0.08759767, 0.12522276, -0.15007316, -0.17090744, -0.08753965, 0.10522642, -0.05245168, -0.00976641, 0.07370278, -0.39216375, 0.013866395, -0.1009104, 0.19112377, 0.20729132, -0.013647159, -0.25439864, -0.027035093, 0.004246929, 0.011144032, 0.019027015, 0.28639123, 0.1719377, -0.1710961, 0.14294465, 0.32082373, -0.30872205, 0.10009142, 0.08747556, 0.27450427, -0.001548484, -0.14962408, -0.19524242, 0.0057707955, 0.23789008, 0.13440658, 0.2835746, -0.059273094, 0.2085557, 0.15383683, 0.32795522, 0.026955644, 0.038681436, -0.057796482, -0.030547753, 0.15117028, 0.041502137, 0.06314049, -0.086699925, 0.24883898, -0.14732967, -0.39865467, 0.12768662, -0.0055028424, -0.032030497, 0.1100145, 0.05453512, -0.01717841, 0.15051736, 0.37629953, 0.0063419063, 0.32856488, 0.025669655, 0.08629253, 0.24791014, -0.051637262, 0.010172176, -0.13154513, 0.053097785, -0.015524641, -0.0010185583, 0.09660547, -0.38996968, -0.09133685, 0.24476154, -0.08416957, 0.04528283, -0.20879084, 0.02073515, 0.0902644, 0.003592183, 0.26455188, 0.03219971, -0.06459583, -0.080648445, -0.027217904, 0.023348833, -0.11146575, 0.059467018, 0.019866893, 0.20526133, 0.011296417, 0.008917466, 0.1042856, -0.12465165, 0.03269471, -0.2350347, -0.0820623, 0.057326447, 0.012698964, 0.08603265, 0.22425866, 0.089882195, 0.06997344, 0.1264294, -0.37283382, -0.008008164, -0.22767544, -0.35283852, 0.11277258, 0.032711923, 0.21163757, -0.0018631915, 0.36056152, 0.042548794, -0.11181164, 0.21551019, 0.088484235, -0.07158261, -0.2921059, 0.15581937, 0.13875498, -0.14581926, -0.3104371, 0.14976282, -0.0040078647, -0.09829227, 0.011497508, -0.21082877, 0.14609353, -0.42474803, -0.22366063, -0.20232193, -0.16163082, 0.14152904, 0.1463557, 0.1263967, 0.17731552, 0.25132802, -0.049829483, 0.21395902, -0.20349133, 0.07880656, 0.360289, -0.14817858, 0.11506724, -0.03245148, -0.079690084, -0.09057496, -0.05591449, -0.09727659, 0.28565195, 0.38009885, -0.03844449, -0.0115636885, -0.1989138, 0.24328257, -0.2621461, -0.052076746, 0.15305793, 0.015371025, -0.24075074, 0.06036845, -0.4661509, 0.021788469, -0.054403793, 0.47967312, 0.20024198, -0.31029812, -0.12307557, -0.25700402, -0.14152956, -0.104662746, -0.22420682, 0.33238813, -0.23007822, 0.01368405, -0.08443439, 0.24422865, -0.25829443, 0.22539572, 0.041426282, 0.100705676, -0.058721486, -0.40318754, -0.20803814, 0.1974228, 0.11415962, -0.04065131, -0.0010788267, 0.068407245, 0.3234034, -0.15210879, 0.00087620626, -0.06490861, 0.14215423, -0.29683492, 0.20087074, -0.06919787, -0.5326385, 0.17283465, -0.03808282, -0.14454566, -0.058345716, 0.06198923, 0.38789734, 0.18380807, 0.13935806, 0.059803855, -0.16253732, 0.04792048, -0.090687685, -0.08704064, -0.072247215, 0.08730379, 0.5063663, 0.10411388, 0.07833606, -0.18920839, -0.100818336, -0.1672192, -0.31864274, -0.032426, -0.3273544, -0.1224783, 0.25100148, -0.14327322, 0.073797315, 0.17375927, 0.08975377, 0.23219879, -0.11136979, 0.161978, -0.123154424, 0.3883849, -0.18949002, -0.028904716, -0.0594531, -0.07474719, -0.09041736, 0.3392025, 0.40922785, 0.56817, -0.033931877, 0.03791401, -0.17242372, 0.072820485, -0.03431012, 0.16972633, 0.13720806, 0.15366037, 0.019110894, 0.13997228, 0.31281146, 0.2622898, 0.07288726, -0.107613616, -0.22756271, 0.008839677, -0.10365472, 0.08259247, -0.36775044, 0.040989608, -0.18132706, -0.20066501, 0.25220314, -0.54424405, 0.25400898, 0.054242015, -0.042513013, 0.598455, -0.33886504, 0.14923787, 0.19550775, 0.018960172, -0.47617173, 0.24165808, -0.01908913, -0.29517385, -0.18330747, 0.052398827, 0.20862548, 0.09280825, -0.02102281, 0.019098548, -0.18259394, 0.3020651, 0.12921767, 0.15798478, 0.0543379, -0.25887576]}, "content": "Yeah, it's super interesting. And I really do want to come back into privacy and focus on it and the particular details of how to deliver it and the new technology. But I think kind of a conversation we're very curious about, can you talk about how you came across Weaviate and then we can dive into the Spark connector?", "podNum": 32, "speaker": "Connor Shorten"}, {"_additional": {"id": "d26a9ae5-09f5-42fa-b95a-a7546ca8314e", "vector": [-0.08991312, -0.38563177, 0.23060493, -0.40273222, 0.051147252, 0.01374172, -0.12532608, 0.13606237, -0.1480094, 0.069589496, -0.05516647, -0.075060554, -0.03348004, 0.052848, 0.1969793, -0.17759813, 0.18397735, -0.36486366, -0.26317295, -0.065668635, -0.34966865, 0.11532394, 0.20209847, -0.0803906, -0.03404409, -0.03956626, 0.14850454, 0.15715168, -0.0740344, -0.16020168, 0.15213998, -0.23124374, 0.15143152, -0.22369178, -0.18306483, 0.30532786, 0.32936254, -0.0014099876, 0.035296015, -0.0017387973, -0.039360248, -0.39417496, 0.020855762, 0.05489817, -0.03776236, -0.21704285, -0.0046890466, -0.15724207, 0.29315916, 0.3646063, 0.19822957, 0.07018616, 0.1167373, -0.15012486, 0.20026982, 0.36119863, 0.037445962, 0.17810796, -0.0013837987, -0.18379359, 0.20656534, -0.09989258, -0.1920181, 0.5792288, 0.041558318, -0.20038478, -0.046918843, -0.09667841, -0.3454704, -0.07867361, -0.3713462, 0.14527157, 0.22471441, -0.02304014, 0.10934169, 0.10660229, 0.124641456, -0.14144787, 0.020674324, -0.10287724, 0.07375377, -0.1899638, 0.074894555, -0.072776936, 0.07899695, 0.15851529, 0.019096546, -0.06419982, 0.020301087, -0.082590066, -0.49944544, 0.060660034, 0.10265341, -0.17147149, -0.3978409, 0.046658095, -0.027083466, -0.1648146, -0.3956329, 0.4926647, -0.0584884, 0.08977456, 0.20193352, -0.49472013, 0.023478983, -0.17327791, 0.1438176, 0.2700831, 0.08225187, -0.17895575, 0.12189344, -0.06358289, -0.27532732, -0.03039018, 0.13887446, 0.14270633, -0.21059914, -0.00027184686, 0.16838343, -0.33543202, 0.21661389, 0.063654535, 0.1820746, 0.14242835, -0.26638076, -0.2869211, 0.40011537, 0.26155242, -0.061945677, 0.2764757, 0.17289358, 0.113448866, 0.3021529, 0.41126168, -0.20839125, -0.047923077, -0.23818927, -0.2140839, 0.21439485, 0.2301745, 0.13148011, 0.10343479, 0.24571037, -0.1369346, -0.2640437, 0.14072365, 0.080444954, -0.14831479, -0.00027343133, -0.087236606, -0.24138482, 0.3258895, 0.2396468, 0.05204287, 0.52010804, 0.1585138, 0.4878125, 0.15813318, -0.03283303, -0.07494969, -0.04409352, -0.15822643, -0.036572207, -0.24603963, -0.19512236, -0.27571738, 0.08630707, 0.21842152, 0.026541406, 0.04746927, -0.15580846, 0.12950407, -0.15513748, 0.11261499, 0.37962303, -0.10020848, 0.36271334, 0.0848847, 0.015621672, 0.09236934, -0.19227214, 0.085122615, 0.051325917, 0.17974377, -0.089399286, -0.040727653, -0.14162342, 0.003423908, -0.023168841, -0.079658985, 0.20541705, -0.27811876, -0.39966023, -0.08882516, 0.13610591, -0.044144075, 0.0063915104, 0.1968565, -0.28388304, -0.10146739, -0.021786243, -0.44643986, 0.094425164, -0.1989987, 0.4092022, -0.0008844603, 0.20678838, 0.08226123, -0.11779031, 0.029928716, 0.0018887537, -0.16871314, -0.07202307, 0.020223143, 0.2522875, -0.14627327, -0.4476899, -0.011729054, 0.0054953, -0.119503655, 0.08062238, 0.07099673, -0.11291445, -0.45999798, -0.03955418, -0.28369358, -0.049077738, -0.044859856, 0.39045122, 0.13087057, 0.25496987, 0.34652922, -0.16263585, 0.04033373, -0.015115683, 0.077277415, 0.06203292, -0.0528971, 0.041160274, 0.03094987, 0.034048695, 0.03461002, 0.007484565, -0.061014768, 0.302443, 0.63518876, -0.23296058, 0.31616423, -0.2046526, 0.44069505, -0.1741576, 0.1403792, -0.22038417, 0.1600325, -0.08970506, -0.021557316, -0.6151568, -0.069563456, 0.03442629, 0.487218, 0.053495526, -0.46847168, -0.277903, -0.29058406, 0.17290752, -0.38461375, -0.26282874, 0.30275574, -0.23957296, -0.049517766, -0.0639293, 0.031004757, -0.012126192, 0.19345075, -0.2823509, 0.25939324, -0.20849818, -0.37900558, -0.33940315, 0.31981555, -0.007595966, -0.04377897, 0.033374716, 0.091361545, -0.3458902, -0.24853282, 0.17715071, 0.19338323, -0.0722855, -0.25171885, 0.30666146, 0.36704576, -0.37841955, 0.059300017, -0.155959, -0.05594845, -0.023006631, 0.25621977, 0.1834495, -0.0015468895, 0.032896336, -0.17558302, -0.059393678, 0.07631374, -0.033917636, 0.054013986, -0.33253136, 0.41533494, 0.21363473, -0.019657822, 0.3514022, 0.11179476, 0.028568203, 0.017865816, -0.08818409, -0.029466683, -0.28951946, 0.18534899, 0.049054682, -0.21900849, 0.04877253, 0.11055812, 0.024022087, 0.20943801, -0.08680555, 0.39679897, -0.2333417, 0.058113273, -0.20947689, 0.112434745, 0.18200083, -0.042545002, -0.2209516, 0.24927066, 0.32979283, 0.19194637, -0.23639537, 0.23016356, -0.18962766, -0.15493315, 0.047020096, 0.3681403, 0.16378035, -0.17194779, 0.17251074, 0.14612688, 0.12828268, 0.16582274, -0.08255919, 0.1024484, -0.07848865, 0.043644335, -0.40228143, -0.14490545, 0.21768875, -0.15203987, -0.06853136, -0.034666877, -0.109207146, -0.1910752, 0.41045788, 0.2612668, -0.07023012, 0.43834737, -0.2161156, 0.13514356, 0.26807442, -0.10927863, -0.123200476, -0.076753594, -0.26131803, -0.42053857, 0.016776586, 0.055429593, 0.16906714, -0.06559723, -0.17753589, -0.09994001, -0.1374786, 0.2917971, 0.32435733, 0.1029925, -0.14026932, -0.122116484]}, "content": "Awesome. So I'm also super excited to welcome our external guest, Sam Bean. Sam is working on You.com. Sam, thank you so much for joining the podcast. And can you tell us a little bit about what You.com is? And yeah, maybe we could just start from there.", "podNum": 32, "speaker": "Connor Shorten"}, {"_additional": {"id": "d2a18fbe-62a0-48e5-b2c1-7e95b63ff528", "vector": [0.022744596, -0.13569246, -0.21762617, -0.3526895, -0.079463296, -0.17300014, 0.4023498, -0.04810716, 0.2531192, 0.013081117, 0.20209041, 0.18466412, 0.06806161, 0.055981845, 0.17981319, -0.08369176, -0.018403454, -0.19810307, -0.45318106, -0.065236524, -0.02571604, -0.10391094, 0.16143844, 0.06736479, -0.18343829, 0.12707622, 0.009017286, -0.059568875, 0.016349664, -0.2467767, -0.088796236, 0.14475536, 0.13371727, -0.19779122, -0.19589911, 0.18834026, 0.015538582, 0.01904492, 0.014431843, -0.029241307, -0.02042547, -0.31666157, -0.040840752, 0.14663704, 0.0770427, 0.23490033, -0.039461333, 0.05351035, -0.028843343, 0.20286696, 0.07488239, 0.16684057, 0.047400888, 0.16046079, 0.024241535, 0.12646925, 0.22961819, -0.26206183, -0.15872633, -0.09823092, 0.09448993, -0.1636103, -0.20436868, 0.3332555, 0.1653425, -0.2475601, 0.08823153, -0.25044316, -0.3102114, 0.15353978, 0.059690803, -0.043483358, 0.05732238, 0.051048435, -0.12901565, 0.015045732, 0.09626509, -0.24431424, 0.025729535, -0.050613575, -0.009226228, -0.08980017, 0.16783236, 0.15029444, 0.0906659, 0.0015833026, 0.0097950995, 0.012381301, -0.07240421, 0.09779533, -0.36862063, 0.067083575, 0.192832, -0.15820137, 0.13222905, 0.20487265, -0.090871505, -0.23411559, -0.01030285, 0.26101938, -0.20293252, 0.10978862, -0.17473793, -0.5206041, 0.09125035, -0.24153943, -0.03836605, 0.19951913, 0.2994906, 0.031746656, -0.17933965, -0.012166813, 0.083994985, 0.12407099, -0.040466215, -0.11437934, -0.14598563, 0.093462706, -0.0041631674, -0.23503576, 0.12341005, -0.03648288, 0.07086363, 0.17162009, 0.0909322, -0.1318013, 0.10831879, 0.21248214, -0.04807147, 0.1320316, 0.33050895, -0.08262955, -0.05314037, 0.13435395, -0.12831725, -0.17072423, 0.1848062, 0.0012430826, -0.11344634, 0.0038338865, 0.061443206, 0.21687154, 0.17866828, -0.16155505, -0.3908109, 0.23511325, 0.0106172925, 0.06639455, 0.16803572, -0.15685582, -0.06134665, -0.10982265, 0.18283747, -0.05564136, 0.01624858, -0.022641761, 0.0098925745, 0.14697018, 0.08719968, 0.08985579, -0.14796364, 0.04159478, -0.016722767, -0.07880747, 0.1194584, -0.27548933, 0.011763315, 0.034834128, -0.008515103, 0.023101559, -0.07099808, -0.11094117, 0.0027142146, -0.06920674, 0.037919275, 0.1250265, -0.3332334, 0.012607903, 0.04263444, 0.22587118, 0.07287669, -0.16970442, 0.075403385, 0.01547631, 0.09331433, -0.05959017, -0.17131402, 0.1075575, -0.2924789, 0.0010221516, 0.001600738, 0.119122304, -0.04055218, 0.20785081, 0.16851543, -0.24395463, 0.0042163166, 0.1923698, -0.074389756, -0.034362856, -0.34081563, -0.19790475, -0.07096959, -0.231575, 0.2703503, -0.035975426, 0.1710924, -0.14091109, -0.12270577, 0.19241938, -0.04724452, -0.2151961, -0.09070342, 0.100484796, 0.115409136, -0.09917767, -0.108588986, 0.110653, -0.055966336, -0.06183526, -0.17727995, -0.04753083, -0.19175564, -0.44215822, -0.39562082, -0.12271543, -0.016490983, 0.20535591, 0.12939666, 0.0012906151, 0.18506502, -0.12834097, -0.11561279, 0.24583553, -0.10546891, -0.17392938, -0.12322231, -0.08545862, 0.14061102, -0.16823304, 0.15489519, -0.013220496, 0.13978848, -0.15022694, 0.2200845, 0.25416037, -0.063579746, 0.22997789, -0.10240735, 0.38686013, -0.31075358, 0.14569129, 0.1344514, -0.017345268, -0.15956703, -0.1966908, -0.21317825, 0.0039857277, -0.014644758, -0.0053990996, 0.18287799, -0.13559267, -0.03687158, -0.13621882, -0.12812693, -0.13949324, -0.36474726, 0.3598023, -0.31715825, -0.06432834, 0.09658374, 0.03599056, -0.031656694, 0.0892014, -0.058411002, 0.007912649, -0.06114587, -0.3689193, -0.38084707, 0.14612783, 0.11196468, -0.2872207, 0.24412253, 0.16695377, 0.019420376, -0.080517285, 0.096304834, 0.12143586, 0.119470954, -0.12479276, 0.19719298, 0.3163662, -0.24444036, 0.10958972, 0.13590224, -0.008009101, 0.0086433245, 0.12509026, 0.09678225, 0.14166674, 0.00833743, -0.05257515, 0.060682137, -0.083878554, -0.026326563, -0.18997686, 0.30618382, 0.1724644, 0.06183635, 0.12293281, 0.05969113, -0.18717642, -0.0068815392, 0.035850015, -0.15339132, 0.0202027, -0.21832106, -0.036780544, -0.06528519, -0.0092634875, 0.028912248, -0.089185365, 0.035988547, 0.23758449, -0.07617904, 0.059527338, 0.16869116, 0.15757754, -0.0663029, -0.0071316403, 0.12865323, 0.048264794, 0.034225166, 0.20215423, 0.39674154, 0.27781782, -0.051534694, 0.05013621, -0.19464333, -0.070409425, 0.15984137, 0.18794642, 0.06826421, -0.054471474, -0.0076774484, 0.16259566, 0.018589852, 0.44932517, 0.041186843, -0.036393467, -0.039801694, 0.13570832, 0.046404775, 0.107570305, 0.15969251, -0.087219514, -0.24951471, -0.05724242, 0.14238612, -0.19478099, -0.06288366, 0.07488116, -0.15347514, 0.50162643, -0.16023648, 0.17623244, -0.025225405, -0.026146064, -0.18465634, 0.043373484, -0.008901948, -0.005251248, 0.17373897, -0.0014673993, 0.14438923, -0.11105202, 0.08182623, -0.14644983, -0.031000856, 0.1781449, 0.13279094, 0.06684699, 0.33543533, -0.061929792]}, "content": "What I'm proud of is the human verification aspect and the fact that we've gotten, you know, at this point over 12,000 people contributing to sourcing and validating these facts. So really the human, I don't want to forget about humans in this process too, because AI is better with humans. Humans plus AI makes it, makes all the output better. And that really is that virtuous loop, right? That flywheel. But as far as our secret, you know, aside from the thing. So I think that's a big part of our product. ", "podNum": 30, "speaker": "Marco Bianco"}, {"_additional": {"id": "d2b10edd-0e98-4eaa-b286-35548d94f8be", "vector": [-0.11797936, -0.17125112, -0.16918251, -0.17445484, -0.028640782, -0.1515297, -0.158032, -0.0419172, 0.0309246, -0.0010665343, 0.02971778, 0.064944625, 0.069375165, 0.06930551, -0.17329268, 0.060400236, 0.0022796653, 0.13995329, -0.4448327, -0.056341648, 0.1255645, -0.008445334, 0.02561754, 0.08637147, -0.0051578246, 0.012723058, -0.12644562, 0.08049744, 0.16235457, -0.13930269, -0.01758369, 0.12104666, 0.000754375, 0.0018033031, -0.472334, 0.19693358, -0.11510591, 0.17509106, -0.019234207, 0.17443244, -0.10733317, -0.092106394, -0.00944501, 0.14653094, 0.2277865, 0.15795237, -0.19761184, -0.09898768, -0.03391642, -0.0096498765, -0.4083678, -0.104303, -0.45403367, -0.17003198, -0.08258246, 0.16539675, 0.17414759, -0.43277034, -0.10609439, -0.16244648, -0.028076898, -0.08026538, 0.08829397, 0.20822021, 0.26478118, -0.09227269, 0.17794135, -0.040720444, 0.097492516, 0.214701, -0.087196946, -0.11841221, -0.2765699, 0.0014793575, -0.10638016, -0.057394993, 0.058832668, 0.08619996, 0.16684407, -0.22824667, 0.17004584, -0.21450965, -0.09376574, -0.08430268, 0.043606512, 0.20356086, 0.2270965, -0.067010924, 0.07944469, -0.07091354, -0.0076009445, -0.2913231, -0.079792, 0.06444975, 0.05501002, 0.17117941, 0.04416786, -0.37712508, 0.119040474, 0.21102548, -0.31746736, 0.23928827, -0.10622415, -0.43760878, 0.09460634, -0.1598772, 0.06831197, -0.0033580982, 0.28214157, 0.02140351, -0.03259583, 0.053288165, -0.20035094, -0.07282137, -0.06525904, -0.21522567, 0.111328825, 0.010888308, -0.073007554, 0.089985706, 0.052115947, -0.2476054, 0.2934104, 0.22003993, 0.34719792, -0.10736458, -0.07271795, 0.2422039, 0.21315119, -0.14831237, 0.4718829, -0.1140805, -0.019457916, 0.17020603, -0.16173013, -0.14642768, 0.24719055, -0.13106309, -0.28060043, -0.04234575, -0.23373729, 0.30310476, 0.06088732, -0.20042512, -0.096353434, 0.4010832, -0.15345839, -0.20362777, 0.07314123, -0.2610983, -0.05903183, -0.37170333, 0.18076439, 0.080711454, 0.12232523, -0.035123684, -0.021936689, 0.21162196, -0.053842872, -0.09543147, -0.09953534, 0.07526968, 0.040064298, -0.12700759, 0.33749312, -0.09114218, 0.044200197, -0.030320195, 0.076440796, 0.16463229, 0.032256823, -0.17816037, -0.29132938, 0.13373712, -0.017573193, -0.024591088, -0.43214953, -0.38395077, 0.029674621, 0.23506247, 0.12755257, -0.04584938, 0.26817927, 0.28975013, -0.21196361, -0.17574412, 0.055457763, 0.099124424, -0.41473967, -0.10056031, 0.04047305, -0.11509627, 0.17165326, 0.099300414, -0.07898467, -0.03318251, 0.2965775, 0.15337157, -0.28920764, -0.028321285, -0.3883983, -0.4017565, -0.06495673, -0.22665259, 0.04223418, -0.14691204, 0.036452405, -0.010908134, -0.29289293, 0.4488725, -0.061740827, -0.17370105, 0.077035144, 0.20008203, 0.1881255, 0.0098119825, -0.2940105, -0.1692069, -0.21203426, 0.03293895, 0.20102608, -0.088473186, 0.0053063286, -0.32017684, -0.33124527, -0.09942704, -0.26075193, 0.11488592, -0.087964, 0.033446886, 0.12680435, 0.08017318, -0.036468785, 0.075457886, 0.012766898, 0.16573608, -0.14034443, -0.08724165, 0.08193588, -0.14883758, -0.09441899, 0.04110791, -0.12326031, 0.12406521, 0.13150042, 0.25727627, -0.23725198, 0.18714374, 0.05879954, 0.35398585, -0.12014596, 0.26423687, -0.0567955, 0.09211847, -0.02161759, 0.08680206, -0.13110834, 0.073816, -0.072657876, 0.43137357, 0.5413859, -0.24376953, 0.078052215, 0.10176556, 0.21846196, 0.25239086, -0.28934112, 0.11517767, -0.21987216, 0.016057309, -0.043246366, 0.1172044, -0.004622128, -0.01774188, 0.39592344, 0.027104195, -0.2665313, -0.1533112, -0.35679907, -0.23223086, -0.14818792, -0.31652886, 0.2801446, 0.37130296, -0.16788101, -0.26294, -0.05281482, -0.06680123, 0.021434285, -0.048567425, -0.040173702, 0.28489614, 0.13797551, -0.10692687, 0.39514306, 0.38822004, 0.05045262, 0.3250535, 0.12021916, -0.0618544, -0.1193705, -0.19660231, -0.030448299, -0.15075198, -0.15300888, -0.036212754, 0.40326625, 0.20460263, 0.13395189, -0.14582378, 0.18881756, 0.0075288117, -0.049275942, -0.029345598, -0.1688287, 0.061092556, -0.025868658, 0.4654165, -0.11827119, -0.034639835, 0.003137881, 0.048722506, 0.046509355, 0.22118767, -0.08142513, 0.2112112, -0.14979774, -0.07247779, -0.12263116, -0.38161883, 0.08512753, 0.18307096, -0.049859047, 0.24882841, 0.34858203, 0.25769216, -0.08284369, 0.21125741, -0.028757067, -0.08853032, 0.22088474, 0.18626224, 0.119971395, 0.02726178, 0.14548214, -0.10389732, -0.031245518, 0.7623292, 0.01575476, -0.059330747, -0.009911145, 0.3637601, -0.051175572, 0.25899056, 0.29680318, 0.2038406, -0.17120025, 0.024934925, 0.08094647, -0.0018832907, -0.13476585, -0.18360864, -0.31540778, 0.35057428, 0.0077694654, 0.09561014, 0.13016742, -0.46850115, -0.08912462, 0.049819656, 0.07084142, 0.15353312, 0.16323037, 0.015065452, 0.30177277, -0.27810198, -0.17934051, -0.10483512, -0.1870297, 0.16995281, 0.0094944555, 0.18012396, -0.04911873, 0.04482848]}, "content": "Yeah, it's so incredible to just change out the text vectorizer and point it to one of these Sparse Zoo models and just see how fast it can turn text into vectors, turn images into vectors. And also these other upstream things like, as you mentioned, question answering, classification. So could we kick this off by describing what is neural magic? How is this faster model prediction achieved? ", "podNum": 27, "speaker": "Connor Shorten"}, {"_additional": {"id": "d30dd631-00c6-4b57-bf47-6ff5716cd130", "vector": [-0.043377355, -0.1497543, -0.06638969, -0.11969148, 0.024512403, -0.0613385, 0.043744802, -0.13219602, 0.07960822, -0.009607343, 0.017831901, 0.026132874, -0.019138796, 0.029523918, 0.29472333, -0.13357025, 0.037511244, -0.15204428, -0.30509946, 0.059703458, 0.018282687, -0.03941252, -0.012886059, -0.043277178, -0.008311969, 0.03297057, 0.041903853, 0.014770739, -0.14033212, -0.16519035, -0.00045630583, 0.09543139, 0.0056336075, -0.11634561, -0.04578382, 0.069082595, 0.07720402, 0.13351126, 0.0022305276, 0.008254639, -0.0674491, -0.11359173, -0.016015634, 0.20603912, 0.058511764, 0.06688019, 0.0036852632, 0.034461107, -0.024367424, 0.087967776, -0.001324698, -0.03593794, -0.03797979, -0.07411427, -0.044286028, 0.23494516, 0.11254155, 0.002682219, 0.055066597, -0.026453696, 0.0043863156, -0.055338115, -0.15860458, 0.32330146, 0.19478779, -0.11338762, -0.030886576, -0.060504347, -0.15598677, 0.1561249, 0.024285099, -0.055308044, -0.015546317, -0.006660382, -0.14955102, -0.0027954925, 0.123881936, -0.0010796264, 0.13522036, -0.012205504, -0.011937392, -0.17853695, 0.032960102, 0.06872111, 0.039908577, 0.027067238, 0.04595731, 0.17509113, -0.071865916, -0.041194115, -0.26240325, -0.072287, -0.007348869, -0.0032630526, -0.05521034, 0.19520581, -0.066631414, -0.18405241, 0.036644757, 0.19808482, -0.18025452, -0.014084205, -0.1310279, -0.35795546, 0.018069444, -0.28832486, -0.033399094, 0.1413027, 0.111709744, -0.11884921, -0.07586771, 0.018530928, 0.005192324, -0.018259192, -0.031224787, -0.08756167, -0.095576905, 0.01439402, 0.20260327, -0.18912, 0.14405137, -0.011508465, 0.084274314, 0.014398594, -0.033255603, -0.04655947, 0.08397771, 0.25774726, 0.022429155, -0.0094052255, 0.10985246, -0.051943287, 0.06940476, 0.16085927, -0.0091134235, -0.07537659, 0.02428486, 0.029468626, 0.056467157, 0.13680202, -0.01663929, 0.20203684, 0.19676797, -0.08188909, -0.22705026, 0.17140257, -0.024888972, -0.055334855, -0.006571185, -0.124933265, -0.059389126, -0.059298635, 0.24124639, -0.11033547, 0.10161158, -0.100899525, -0.06220944, 0.066975415, -0.0481236, 0.11595901, -0.19714291, 0.066511035, -0.07676664, -0.080194056, -0.036371093, -0.06660847, -0.01919002, -0.096519016, 0.14989074, 0.045272797, -0.011537999, -0.011721144, 0.13432522, 0.012532852, 0.06680676, 0.03228883, -0.29936126, 0.10418653, 0.06927932, 0.16423473, 0.09019066, -0.053369716, 0.018441968, 0.1435399, -0.017485153, -0.03205123, 0.008712839, 0.031235592, -0.10775199, -0.12220335, 0.03521337, -0.020406907, -0.079964794, 0.23193127, -0.029334562, -0.09010145, 0.081283055, 0.06794486, -0.099345684, 0.021577528, -0.21461816, -0.1532576, -0.026533186, -0.10776346, 0.16916358, -0.012147511, 0.260392, 0.010777491, -0.11064979, 0.12608267, 0.005771889, -0.10701656, -0.10677453, 0.107977666, 0.22943401, -0.06034598, -0.11219627, -0.118480854, -0.17393918, -0.022944672, 0.017052403, -0.16723298, 0.038465187, -0.42540994, -0.19577563, -0.190127, -0.016551634, 0.05422081, 0.14415671, 0.029476278, 0.0947885, 0.073848754, 0.0150569305, 0.22937953, -0.04685415, -0.031362385, 0.059038345, -0.058388446, -0.028493064, 0.0036324833, -0.052123275, -0.18604724, 0.059971124, 0.012297049, -0.042497873, 0.25142625, -0.11018187, 0.18519056, 0.010266294, 0.19958806, -0.16854863, -0.062249724, -0.060000747, 0.14495987, -0.28778437, -0.11436951, -0.31134105, 0.15093997, -0.06738105, 0.2082107, 0.26366785, -0.25786757, 0.0013293674, -0.14349274, -0.028568735, -0.049890246, -0.15965159, 0.26171505, -0.27323937, -0.009405977, -0.015847305, 0.17012532, 0.023327751, -0.054462675, -0.0071145496, 0.15405554, -0.06084581, -0.15476337, -0.19647877, 0.005530042, 0.046545383, -0.23061013, -0.030596891, 0.22931753, 0.047773957, -0.088041075, -0.100061096, 0.09734758, 0.16976579, -0.13019317, 0.08350012, 0.15045238, -0.26445767, -0.00060002255, 0.1383641, -0.025087148, -0.18961376, 0.116591774, 0.18645282, 0.11319816, 0.15966591, -0.011769255, -0.064567305, 0.020719795, -0.0330794, -0.052887242, 0.049186613, 0.13704905, 0.20634246, 0.030599883, -0.041362613, -0.006417141, 0.01997611, 0.18858738, -0.06987593, -0.0051303282, -0.26773003, 0.06755806, -0.037761215, -0.046491176, 0.008904169, -0.040650677, 0.07091788, 0.19210255, 0.008814176, 0.14812352, 0.13978584, 0.011269589, -0.09533387, -0.071641244, 0.04560293, -0.028915675, -0.009210393, 0.12657171, 0.21853681, 0.23740911, -0.12839183, -0.07393858, -0.2047807, 0.13080198, 0.108763315, 0.15980442, 0.13340484, 0.038278654, 0.08131656, 0.08997709, -0.00018273543, 0.21589313, -0.06662718, 0.04235645, -0.08635489, 0.25548723, -0.055585165, 0.03823586, 0.13382748, -0.060032357, -0.10004672, 0.0033766131, 0.11377635, -0.3500007, 0.019899026, 0.045577675, -0.053650916, 0.47331336, -0.118912846, 0.1537563, -0.0015594065, -0.08216205, -0.20382893, 0.07057989, 0.09173999, 0.018010529, 0.06848595, -0.03392376, 0.15037563, -0.0044285306, -0.050340045, 0.012765651, -0.1624903, 0.14684431, 0.07709097, 0.034778953, 0.26470163, -0.10002333]}, "content": "Yeah, that's great to hear, by the way. That's really nice. Yeah, so for our listeners to understand a bit sort of how we structure that internally, we have the core team itself, which basically builds Weaviate, which is kind of a lot of what we do, but by far not the only thing that we do. And then Connor is part of the research team as well. So besides like the podcast and other sort of DevRel activities, there's also the research part. And what we consider research and research that the term research, depending on what your background is, this can have very different definitions, or it can have very different meanings. But we use research in the sense that we say we've identified an opportunity somewhere, something that we will most likely want to add to Weaviate. But there is some kind of a question that we need to answer first. And this question could be something as simple as what is the best UX to integrate this into our APIs? Like how would our users want to use it? Like, do we want to give the user a lot of control? Or do we want to maybe abstract something? So this could be a question. It could be a question of how are we going to build it? So especially in... So you mentioned Rank Fusion and Score Based Fusion. And these terms, this is basically something that you know way better than I do, and something where we benefit so much from having these kind of collaborations within the company. So this sort of how do we build it? What do we need? What do we need to figure out how to be able to build it? Could be an evaluation also, something like, does this idea make sense? Like it looks good on paper, but what happens if we try it at scale? Let's try it with 10K objects, a million objects, maybe a billion objects. Does it scale? Does it fit into Weaviate in that sense? And this is something where Hybrid, I think early on, we identified that there is an opportunity. And so like, okay, let's get started. Let's see what it is. Let's see what do we need? Because Hybrid sort of in a sense, you need both the building blocks for Hybrid, both the BM25 search and the vector search. You need to have both. Vector search obviously is kind of what Weaviate is about. So we can safely assume that we have vector search covered. BM25 is something that we gradually started building. It was actually TF-IDF in sort of the simple building block for BM25. But I think from the indexing perspective, it's actually the same or it's like one or two parameters need to additionally be indexed for BM25. That is something that we actually had in mind in the very, very first prototype that we built. So we didn't have any APIs for TF-IDF or BM25, but we had the inverted index early on, I think over two years ago, we added the inverted index to Weaviate. And it already had this, and Parker, you may have come across that in the code. Whenever we put those buckets, we had like buckets for with frequency and without frequency. The word frequency is basically for all the text properties. We additionally to indexing the word, we also index the frequency. And that was in preparation for that whole TF-IDF BM25 step. So we kind of knew that it might be something that we want to add at some point. But we also have to figure out like what is the real value of it? And if I'm 100% honest, something that I don't know at this moment is, will hybrid search play a role five or 10 years from now? It could easily be the case. And I don't think anyone can confidently answer that. It could be the case that semantic search just keeps improving so much that hybrid search basically is more of a stopgap solution at the moment to bridge a gap and the gap being exact keyword match in out of domain search. Or it could be that while it still improves, hybrid search is just always going to be better because it's the combination of two things. And this is something that, yeah, I don't know. And I don't think anyone really knows. It's something that I find super exciting. And yeah, quote me on this five years from now. And let's see. Let's see how it turned out. ", "podNum": 31, "speaker": "Etienne Dilocker"}, {"_additional": {"id": "d3cc7ee7-5bb0-4ad7-8a7b-f093e290b3c2", "vector": [0.06341069, -0.09464076, -0.07192947, -0.18996271, 0.038060788, -0.17193252, 0.14976512, -0.12427786, 0.10406888, -0.00837631, -0.031460285, 0.22941542, 0.15631181, -0.023423413, 0.22792299, -0.038446106, 0.04246176, -0.072684444, -0.4078906, -0.068630844, -0.117759556, -0.07867435, -0.13320857, 0.051644545, -0.10289237, 0.051502995, 0.005181426, -0.076811224, -0.06862057, -0.0983567, 0.074737616, 0.04172896, 0.051546674, -0.08386297, 0.033569958, 0.12077032, -0.07401441, 0.086347446, -0.01815795, -0.15218413, -0.13976982, -0.05936069, -0.2347121, 0.18292771, -0.006283545, -0.15982758, -0.1651205, 0.0529186, -0.0006370594, 0.07645932, 0.03637503, -0.026045833, -0.19219892, -0.0026456416, -0.10744129, 0.1358363, 0.013695473, -0.12284847, -0.14890195, 0.053668343, 0.01342003, -0.040690705, -0.21777506, 0.371721, 0.21651813, -0.054271005, 0.056245882, -0.22084785, -0.0026216407, 0.35865533, -0.08946958, -0.028212614, -0.010843877, 0.14408877, 0.01498077, 0.007861306, 0.10067347, -0.031645164, 0.08808313, 0.046128765, -0.032096818, -0.24943127, 0.096447945, -0.13760203, 0.051610634, 0.07098508, 0.03010232, 0.090688765, 0.050008066, -0.11378683, -0.3056186, -0.1096774, 0.14526875, 0.028218575, -0.12982471, 0.06474128, 0.10042777, -0.049894553, 0.15946649, 0.30991027, -0.26096904, -0.10488768, -0.125857, -0.30183202, 0.114873014, -0.25195384, 0.08414904, 0.0057460866, 0.026356637, -0.09375459, -0.13122356, -0.008102454, 0.18558042, -0.028299889, -0.09751882, -0.01748389, -0.105757765, 0.22340213, 0.08699448, -0.18046623, 0.08547033, 0.10110205, 0.04808802, 0.052030098, 0.16205348, -0.1396944, 0.18143612, 0.120515674, 0.10566382, -0.17571677, -0.07301539, -0.03830782, 0.0699631, 0.3203793, -0.119179994, -0.10780248, 0.08988505, -0.044974204, 0.06828711, 0.069070034, -0.025340457, 0.11366843, 0.3845679, 0.1602704, -0.29456228, 0.27658966, -0.1523711, -0.115630016, 0.02481353, -0.09048564, -0.0567832, 0.24642576, 0.12534657, -0.04598271, 0.0693537, 0.047558803, 0.11965173, 0.12849146, -0.030387951, -0.097578436, -0.27180237, 0.27754602, 0.013958769, -0.09954324, 0.04578122, 0.05640258, 0.08679458, 0.08419141, -0.11503659, 0.18830582, -0.052731626, 0.0070769363, -0.083133824, -0.21103995, 0.014627929, 0.01629978, -0.12561184, 0.019402478, 0.07472584, 0.08928993, -0.042255085, 0.098891266, 0.01855211, 0.121280536, -0.0066939155, -0.1267398, -0.04038887, -0.038045507, -0.009726109, -0.15843093, -0.021018019, -0.050827485, -0.03060042, 0.134108, -0.030326614, -0.10252261, 0.08824048, 0.09474755, 0.006390542, -0.012349908, -0.23224142, -0.12817663, -0.1467964, -0.22530381, 0.2201895, -0.0059972648, 0.27297297, -0.14820006, 0.110964224, 0.056965735, -0.017607322, -0.076735795, -0.21023464, 0.09101239, 0.17782646, -0.23733515, -0.1611935, 0.03195165, -0.15696375, 0.019405164, 0.029608706, -0.14471056, -0.108964756, -0.39637572, -0.22039175, -0.1670941, 0.13316618, 0.25709465, -0.03577723, 0.058504183, 0.1382714, 0.016236944, -0.0039790403, 0.04335268, -0.13938361, 0.040033534, 0.13009477, -0.029714316, -0.13507307, 0.14446269, -0.0028011252, -0.05692052, -0.059633866, -0.007960021, -0.0050929133, 0.33691686, -0.28719595, 0.18762785, -0.07104006, 0.013165803, -0.13751863, -0.005431748, -0.10106555, 0.14543429, -0.28291214, -0.070866875, -0.30041206, 0.010238188, -0.06491056, 0.12236326, 0.309919, -0.22563052, -0.10520461, 0.0038192007, 0.009778665, -0.084400415, -0.016440697, 0.48660433, -0.07964023, -0.05104743, -0.10653223, 0.22735432, 0.05097619, -0.048321, -0.111921005, 0.13872927, 0.09754208, -0.11412471, -0.27208525, 0.1481589, -0.13108698, -0.18392813, -0.11929785, 0.112615176, 0.104529515, -0.14772688, 0.13952397, -0.019725787, 0.115111165, -0.017032567, -0.040968265, 0.2324027, -0.105689436, -0.103139125, 0.029097285, -0.025955144, -0.02013577, 0.20116352, 0.14817776, 0.06608257, -0.1306049, 0.13047545, -0.11239901, -0.0056880265, 0.015773054, -0.02246594, -0.0104386015, 0.124342814, 0.21377772, 0.0095902765, -0.09197337, -0.13445145, -0.23697141, 0.0030679454, 0.099938035, 0.018040014, -0.14730676, 0.13578215, 0.05478801, -0.007345299, 0.019553818, -0.10862052, 0.17577544, 0.24389198, 0.21280771, 0.049324367, -0.0071375286, 0.22649251, -0.042026162, -0.106538266, 0.034687504, 0.043397766, -0.16720697, 0.07642434, 0.09759721, 0.27357566, -0.16329622, 0.086741194, -0.1610147, 0.062729135, -0.03105297, 0.10852211, -0.0051631117, 0.04646902, 0.20433417, 0.0418785, 0.08943284, 0.2007962, 0.032337982, 0.08774514, -0.15016666, 0.13797978, -0.04167738, 0.07031301, 0.25895393, 0.069201194, -0.040651653, -0.101962365, 0.121066675, -0.26141217, 0.17301764, -0.067893706, -0.16036446, 0.3750996, -0.25899702, 0.030220184, 0.14097008, 0.00053469674, 0.041615866, 0.1069558, -0.099517465, -0.046144005, 0.004481191, 0.059475534, 0.17417067, -0.106959976, 0.10915615, -0.1767337, -0.20630781, 0.3564707, 0.24487932, 0.05116119, 0.2663441, -0.006482608]}, "content": "Yeah. When you think of stages, it always sounds super complex, but it can be something super simple. What I really like is that you're essentially using database technology. There are plenty of Bloom filters in Weaviate, just for the object store, which is an LSM-based store, and super cool that you were using Bloom filters there as well. So what I find super interesting about removing this in the last part, if I understood it correctly, that is essentially a post-filtering step. So, in the worst case, you could run into a situation where you would run out of candidates. If the user has listened to everything, then everything would be removed from the search. Yeah. So that's another situation where I think the pre-filtering that you can do in Weaviate would be super helpful these days, because you can just remove them before generating the candidates. ", "podNum": 25, "speaker": "Etienne Dilocker"}, {"_additional": {"id": "d3edc41e-9108-4c14-9dba-2ad67324aa1d", "vector": [0.11249496, -0.28734824, 0.11940144, -0.080359615, -0.0049089445, -0.071700186, 0.094929464, 0.09689372, 0.08187168, -0.004456062, -0.024380518, 0.07573776, 0.09987089, 0.029798608, 0.18882945, -0.065157644, -0.078967795, -0.3521102, -0.39426085, -0.06506114, -0.42836136, -0.08892112, -0.053666983, -0.08147726, -0.06346075, -0.019037813, 0.12659815, 0.17009838, -0.17972976, -0.21999559, -0.03774311, 0.122934975, 0.10040702, -0.091729656, 0.0992875, 0.20505442, -0.018626925, 0.047556087, -0.116106115, 0.054156076, -0.112856016, -0.14546563, -0.054890558, 0.18880846, 0.13156575, 0.013743764, 0.020403795, 0.0058312993, 0.19097273, -0.031574022, -0.08055139, 0.17471698, 0.1915895, -0.042351697, -0.020311568, 0.11435557, 0.036189772, 0.020062556, -0.08121921, 0.29556978, 0.14008144, -0.25174272, -0.3210936, 0.3086539, 0.19687635, -0.054869443, -0.04917222, 0.074656725, -0.3760476, 0.3169537, -0.2774998, -0.10174014, 0.019104801, 0.20245624, -0.10056722, -0.032401793, 0.06817041, 0.11153919, 0.2076605, 0.04234552, -0.11388357, -0.08575003, 0.11319197, 0.051728547, 0.10276705, 0.22709149, 0.074757904, 0.07221817, 0.23913503, -0.16794436, -0.16294788, -0.092885695, 0.15976751, 0.02062888, 0.12717608, 0.013033599, -0.0038035875, -0.5163548, -0.3716972, 0.47704715, -0.40941903, -0.023819486, -0.010832186, -0.31988224, 0.2583213, -0.34575042, -0.039806977, -0.041451827, 0.05055485, -0.24588156, -0.026141927, 0.016425911, -0.1378666, 0.13035633, 0.050589338, 0.160979, -0.28415677, 0.0481869, -0.073857665, -0.35841483, -0.0005672183, -0.17959145, -0.28766575, -0.018517718, -0.045032952, -0.29080093, 0.16040921, 0.14088562, -0.02960045, -0.09119561, -0.064635664, 0.069687545, 0.23787364, 0.19264631, -0.3395781, -0.030424498, 0.13642293, 0.08318848, 0.07623976, -0.16481183, 0.18776555, 0.30066895, 0.27127638, 0.17410046, -0.23208857, 0.27138758, -0.26599818, 0.10298374, 0.056217227, 0.0011879504, 0.030538157, 0.1554935, 0.2724924, -0.0061190333, 0.10179898, -0.09695351, 0.21143769, 0.1944649, 0.11652827, -0.19499345, -0.11803003, 0.06304711, -0.0369925, 0.13163151, 0.04413288, 0.09278572, -0.12966774, 0.0044763237, -0.03909155, -0.0141585395, -0.09315354, 0.114621334, 0.22297157, 0.017873514, 0.035908125, -0.20112862, -0.159399, 0.18775085, 0.052635066, 0.32886615, -0.078381434, 0.12761058, 0.0858286, 0.25618023, -0.24710017, -0.01354021, -0.0054044854, -0.115127794, -0.07115206, -0.23659311, -0.28559402, -0.038979474, -0.0055201836, 0.12234344, -0.06648464, -0.2047227, 0.051761016, 0.22836724, 0.0816424, 0.015305908, -0.2033809, -0.019312616, -0.029710338, -0.2897414, -0.078637175, -0.11250992, 0.16441281, -0.11302441, 0.15138568, -0.012833625, -0.040826038, 0.06608236, -0.24346265, 0.27932352, 0.23886062, 0.029850202, -0.25651166, 0.1216026, -0.11549756, 0.060286783, -0.111885965, -0.04433479, 0.019700918, -0.4894039, -0.27064288, -0.23954591, 0.032119103, -0.05802889, 0.06716639, 0.0064456016, 0.2704723, -0.029760994, -0.013763946, 0.09860453, -0.070751354, 0.0030777548, 0.023792591, 0.11567296, 0.10391703, 0.2654854, -0.34563056, 0.09027595, -0.011050841, 0.17200026, -0.24147889, 0.1232246, -0.15387926, 0.3552292, 0.019402413, 0.287181, 0.13957237, -0.07596818, -0.52809584, 0.0324526, -0.37751737, -0.028314829, -0.59921366, 0.1941427, -0.2811051, 0.018628012, 0.16274117, -0.5026536, -0.10693033, -0.23506916, 0.1832814, -0.1328704, 0.12398855, 0.54762125, -0.29483077, -0.10362527, 0.102990694, -0.0028789528, 0.077131614, 0.029101182, 0.11335577, -0.026716702, 0.2835782, -0.009799611, -0.15713295, 0.12135881, -0.14195295, -0.21572697, -0.1546849, 0.16064885, 0.049787134, -0.1715357, 0.1187398, 0.12988816, 0.068207026, -0.17415953, -0.0754585, 0.24943654, 0.093289845, 0.09884034, -0.09120728, 0.11276756, -0.027956508, 0.1845624, 0.15916023, 0.35051814, -0.21942791, -0.06454081, -0.34520972, -0.19104052, -0.17701975, -0.23118047, 0.024520706, 0.37232965, 0.10508959, -0.26842275, 0.4600969, 0.046423383, -0.07798126, 0.28941804, -0.048181184, 0.062306803, -0.32785076, -0.27892813, -0.019924603, -0.12933108, 0.052649327, -0.20566691, -0.0146885095, 0.19659907, 0.14967851, 0.36263025, 0.068120405, 0.18780187, -0.18430384, 0.08837888, 0.13873753, 0.09280385, -0.12949525, 0.021900991, 0.04254907, 0.2041565, -0.23257235, 0.27731094, -0.09947876, 0.15388602, 0.006784145, 0.031676278, 0.1305824, 0.28589383, 0.15331593, -0.01765281, 0.13261938, 0.41270408, -0.14869419, -0.06833315, 0.0077453167, 0.22518703, -0.0049943253, 0.19805524, 0.49244064, 0.026027102, -0.097511545, -0.14130309, 0.1840615, -0.48107362, -0.03402746, 0.13900055, -0.062875584, 0.40185142, -0.28757375, 0.13836855, -0.056332506, -0.20146461, 0.09474462, -0.010766907, -0.006959377, 0.008228802, 0.16379626, 0.20019859, 0.15039586, -0.058914248, -0.13407734, -0.13879941, -0.2862684, 0.31445011, 0.081639156, 0.3695782, 0.43013263, -0.013839271]}, "content": "Yeah. Who knows the very specific local name of the program that's going to help you? You just have a problem. You've got to describe that problem and get, you know, hopefully get surface the right information or program for your specific problem, that situation. ", "podNum": 30, "speaker": "Chris Dossman"}, {"_additional": {"id": "d4e0bb3c-ca47-45b5-b08a-53382e33c444", "vector": [-0.056937493, -0.08748172, -0.022925727, -0.26322857, -0.14254238, -0.11544546, 0.21162179, 0.16935575, 0.07536368, -0.05550856, -0.08937596, -0.10130231, -0.12613848, -0.004640949, -0.3480322, -0.04997228, 0.40121856, -0.2238501, -0.514171, -0.22874884, -0.19811103, 0.050480913, 0.22553524, -0.01912659, -0.12636457, -0.17774121, -0.24118733, 0.17677161, -0.09953348, -0.14480905, 0.14947984, -0.09634398, 0.20500076, -0.11639945, -0.19072019, 0.36625737, 0.10089521, 0.06828157, -0.07816218, -0.13075626, 0.015429477, -0.37570757, 0.0028482093, 0.13199976, 0.11255906, -0.23945627, -0.041858595, -0.060902644, 0.29278105, 0.12866744, 0.0046350146, -0.08722533, -0.028024454, -0.21511197, -0.11181273, 0.2551043, 0.22004907, -0.035616983, -0.0954024, -0.27995467, 0.35418478, -0.2159061, -0.31954175, 0.6721899, 0.16760075, -0.33031824, 0.10547869, -0.351876, -0.22298582, 0.27751768, -0.009375972, 0.018580187, 0.20986569, -0.116746664, 0.07664031, 0.23733649, 0.09434485, -0.22590515, -0.1249846, -0.18856779, 0.33963987, -0.22227447, 0.039121665, -0.2909064, 0.27519137, 0.04596261, -0.05671919, -0.09081454, -0.15088353, -0.10086174, -0.2652305, 0.24238165, -0.1076406, -0.047204748, -0.089934036, 0.20800567, -0.07274006, -0.27046064, -0.29788524, 0.27375388, -0.03071003, -0.024206579, 0.04541073, -0.18261194, -0.14153756, -0.106062725, -9.231568e-05, 0.13742019, 0.028622705, -0.13874583, 0.027149444, -0.16196577, 0.031223785, 0.14593716, 0.3408155, 0.16135043, -0.040909834, 0.092457846, 0.26886892, -0.26834995, -0.061686844, -0.10089351, 0.20518772, 0.120672725, -0.0074481117, -0.058042824, 0.34725916, 0.22816184, 0.27404553, 0.25581306, 0.0032948107, 0.1904721, 0.11639863, 0.4076554, -0.2832341, -0.21088028, -0.22774336, -0.05746705, 0.048478656, 0.066765964, 0.1354387, 0.15364046, 0.13993588, -0.20801607, -0.30673683, 0.17453556, -0.17377046, -0.04077812, 0.08428688, -0.05864061, -0.17341377, 0.057047427, 0.32619014, 0.054320253, 0.41175634, 0.22176561, 0.31089428, 0.22615847, -0.16275546, 0.10119202, -0.16419046, -0.047197856, 0.03511149, -0.21565978, -0.14346704, -0.31320658, 0.13060553, 0.29778486, -0.098285235, 0.2406319, -0.18549895, -0.056168735, -0.023048282, 0.11051385, 0.10834918, 0.1260968, 0.22758321, -0.07379391, 0.07991574, 0.07200545, -0.16922015, -0.027583754, 0.07810227, 0.22862072, -0.106111184, 0.19008067, 0.08199426, 0.009367461, -0.20258811, -0.09777648, 0.18881592, -0.13013677, -0.049827438, 0.072759405, 0.13832399, 0.12966153, 0.050703786, 0.043910433, -0.20163956, -0.035765536, -0.16512582, -0.43405262, 0.16388413, -0.30902487, 0.45588923, -0.22204964, 0.31469044, 0.03734793, -0.088403225, 0.18362783, -0.18281826, -0.26231128, -0.07987428, 0.023755005, 0.020491073, -0.050399363, -0.29352647, 0.040567406, -0.09806359, -0.09416436, 0.17574593, -0.20607814, -0.3413489, -0.49794903, -0.15752752, -0.21781187, -0.13318302, 0.26035434, 0.26590377, 0.10436283, -0.11874099, 0.18436512, -0.042000074, 0.09602809, -0.021516358, 0.007572496, -0.11349323, -0.33361715, -0.068448186, -0.014371224, -0.07899317, 0.047774762, 0.2633702, -0.03193868, 0.4322843, 0.55053174, -0.18034457, 0.23116112, -0.21837938, 0.19357014, -0.3584763, 0.18913814, -0.069018446, 0.05760222, -0.0041521518, 0.13575841, -0.32679445, -0.1119835, 0.070657834, 0.46727642, 0.57073504, -0.34575167, -0.20191462, -0.09072998, 0.0465455, -0.08307035, -0.22719249, 0.61991245, -0.02889821, -0.0276175, -0.24497946, 0.019910496, -0.030750072, -0.05593325, -0.14760746, 0.12849323, -0.231129, -0.09635073, -0.3128856, 0.28817338, 0.10809399, -0.034851875, 0.22682714, 0.20142765, -0.24438414, -0.15947112, -0.052604396, 0.03280474, 0.058809828, -0.02045397, 0.24133012, 0.28458697, -0.36742705, 0.26738518, 0.009501165, 0.13722572, -0.1431693, 0.37037325, 0.16545133, 0.19021955, 0.10497792, 0.084094174, -0.08827685, -0.084371105, 0.083686344, -0.13303432, -0.10428019, 0.12963127, 0.17166728, -0.21727717, 0.19934629, 0.019887546, 0.012010509, 0.37312952, 0.010005998, -0.040586982, -0.1044273, 0.1853558, 0.3110682, -0.12524098, 0.16071405, 0.18080454, -0.093268044, 0.0033644855, -0.23316517, 0.17519404, 0.046080157, 0.12330379, -0.3385258, -0.19234404, 0.15203892, -0.008185419, -0.15783842, 0.37808806, 0.58143365, 0.2875692, -0.20911422, 0.13663808, -0.1901551, -0.10671444, 0.1790636, 0.23304565, 0.15400732, -0.35350275, 0.07264565, -0.03799251, 0.13341947, 0.3148421, -0.22929475, -0.056335222, -0.017383892, 0.07855271, -0.24458489, 0.05680727, 0.1329025, 0.069233276, -0.15326142, -0.23823062, 0.0076547572, -0.4134137, 0.1676716, 0.16133109, -0.16153574, 0.4713077, -0.0786113, 0.1664004, 0.08810334, -0.1206883, -0.27438408, 0.15048501, -0.17120971, -0.13628764, 0.06852026, -0.061358213, -0.0030100779, -0.16098653, -0.05694157, -0.02479431, -0.23219936, 0.12267913, 0.4057592, -0.01265108, 0.106409326, -0.19306155]}, "content": "Yeah, awesome. Well, thank you so much, Michael. I think the technology of Neural Magic, the way it fits with Weaviate is so exciting. And sparsity, the vision to this, the sparse zoo, sparse ML, all of it is just so captivating. And thank you so much for doing the Weaviate podcast. ", "podNum": 27, "speaker": "Connor Shorten"}, {"_additional": {"id": "d52afbc9-8cf1-467b-ac13-3f9a53a97a8e", "vector": [0.0026839555, -0.12849443, -0.19881871, -0.2154469, 0.07899434, -0.18641177, -0.082439676, -0.1554411, 0.00935024, -0.03634439, -0.10883627, 0.089114204, 0.12843631, -0.008099498, 0.34393656, 0.013451973, 0.19461899, -0.01986065, -0.43107828, 0.020053234, -0.04144436, -0.027271729, 0.037441853, -0.010127115, -0.03317628, 0.028682847, 0.049790952, -0.035813976, 0.01955148, -0.16903362, -0.04672637, 0.415034, 0.04629653, -0.0016618684, -0.22401333, 0.15265225, 0.12677684, 0.34112006, 0.059069753, -0.0012270615, -0.13228616, -0.00024674833, -0.09445828, 0.20062199, 0.027106192, -0.2310117, 0.05688777, 0.012757709, -0.12108948, -0.038073115, -0.14843933, -0.020661047, -0.27976206, 0.19612539, -0.13410588, 0.09939362, 0.17884193, -0.015610653, -0.034539383, -0.10462864, -0.10499692, -0.20994313, -0.114978395, 0.42202458, 0.2718956, -0.01681517, 0.003429956, -0.014220702, -0.20703666, 0.2265635, -0.002043122, -0.113824606, 0.08830505, 0.08289401, 0.08764441, -0.014962526, -0.085216716, 0.08236958, 0.13541248, -0.105271816, -0.09672539, -0.017686447, 0.16166046, 0.09749021, -0.085420504, 0.06005133, 0.03382381, -0.07208005, -0.09022369, -0.017754395, -0.0070065022, -0.1847464, 0.34634566, 0.041341793, -0.13466474, 0.05427741, 0.020584922, -0.1946668, 0.27056646, 0.1912007, -0.24888854, -0.038951978, -0.1597447, -0.26270753, 0.13237107, -0.37379113, 0.016236478, -0.0008956745, -0.035778027, -0.12794422, -0.040622335, -0.0101751555, -0.1365474, -0.30942136, -0.08180272, -0.08123516, 0.042256117, -0.033611633, 0.21417221, -0.42730245, 0.103509545, 0.07751986, 0.041604318, 0.107769966, 0.1730233, -0.05454427, -0.09850631, 0.21310738, 0.10051797, -0.010376694, 0.12157822, 0.032220367, 0.3014673, 0.21593556, 0.0051516206, -0.20682792, 0.14527434, -0.17763637, 0.02463286, 0.26080555, 0.099036954, 0.25997752, 0.18745157, -0.053378083, -0.2055548, 0.3515247, -0.16011152, -0.05880686, -0.0059845, 0.0041994983, 0.03883736, 0.0040060906, 0.2589025, 0.04068648, 0.09114918, 0.037521504, -0.035747148, 0.046996698, -0.07191074, 0.08132078, -0.08220234, 0.15112902, -0.0766887, 0.010801956, -0.041096617, -0.058715783, 0.035719097, -0.14468285, 0.06349148, 0.05383541, 0.0004152745, -0.009274133, 0.092068754, 0.16130343, 0.054619126, 0.043510742, -0.39415985, -0.10005623, 0.07635765, 0.18264244, 0.16575798, -0.035339333, 0.032529358, -0.01089536, -0.221488, -0.13680673, -0.043730542, -0.11739741, 0.011077886, 0.05480085, -0.0039413483, 0.018826485, -0.024879243, 0.0024813593, -0.03409875, -0.013151055, 0.1894052, 0.230527, -0.28039917, 0.009751084, -0.20853898, 0.011500989, 0.057136524, -0.105615, 0.078138284, -0.09644539, 0.2278591, -0.07895757, -0.3454442, 0.2241343, 0.009451347, -0.083570555, -0.21599944, 0.018201355, 0.108120464, -0.04746618, -0.17291701, -0.026325643, -0.3797195, -0.034430932, -0.14066835, -0.19713804, 0.017974075, -0.4491128, -0.20871215, -0.051534314, -0.07181424, 0.08928236, -0.111464426, 0.0009231262, 0.1543882, -0.100864395, 0.32239822, 0.1225935, -0.4024612, -0.030038211, 0.028025454, -0.08464173, -0.12756264, -0.03915733, -0.119592525, -0.05767095, -0.06313954, -0.09392884, -0.08357664, 0.017354736, -0.17959943, 0.18961048, 0.043712955, 0.22297864, -0.21704082, -0.104365304, 0.018887527, 0.18042706, -0.37006924, -0.14679694, -0.3313428, 0.012761533, -0.07431511, 0.15179875, 0.2643772, -0.17564437, -0.100115106, 0.11803682, 0.016571578, -0.01802447, -0.16647074, 0.21679983, -0.15291247, -0.051091444, -0.11885734, 0.16912484, 0.0024437278, -0.034913793, 0.00039273873, 0.12185787, 0.048563946, -0.34988478, -0.24782567, -0.028680464, -0.015409291, -0.30416197, 0.087588266, 0.299302, -0.0350987, -0.109283075, 0.055255342, 0.024123648, 0.0949044, -0.22266987, -0.0591514, 0.09733798, -0.13804975, -0.015653703, 0.23655668, -0.0012223236, -0.088344455, 0.061705433, 0.19304973, 0.13518435, 0.26442412, -0.17308815, -0.24459651, 0.051707983, 0.1366401, -0.06323107, 0.18448198, 0.32301444, 0.105177805, 0.040731527, 0.13774657, 0.009270198, -0.05684488, 0.09082402, -0.063032985, 0.119480446, -0.15171285, 0.3428379, -0.20739853, 0.054177105, -0.016937327, -0.08945505, 0.06272857, 0.1488026, -0.05444585, 0.21636991, 0.025529057, 0.12929767, -0.16696301, -0.0029541254, 0.062431984, 0.12241495, -0.21316168, 0.0857297, 0.26614314, 0.31143677, -0.091867365, -0.009067906, -0.2692613, 0.27629942, 0.10784595, 0.19578534, -0.05152762, 0.080944985, 0.10210098, 0.0831274, -0.010819192, 0.45169654, 0.121377036, 0.10093354, 0.106984235, 0.25243455, -0.088225245, 0.08957784, 0.38177985, -0.085414484, -0.19169751, -0.06090104, 0.12999347, -0.1654519, -0.0909964, -0.14961022, -0.085564576, 0.46105394, 0.087965466, 0.004178524, -0.062009238, -0.025870353, -0.018555481, 0.024852261, -0.03565853, -0.018897654, 0.0898551, 0.068478115, 0.13146253, -0.13907047, 0.06725726, -0.036207862, -0.10861863, 0.20407486, 0.061900508, 0.0958152, 0.3795541, 0.020715643]}, "content": "A bit. Generally, topic modeling is approached as in a very explorative way of getting to understand your documents. It really helps that you understand, okay, this is my data, these are potential clusters, we can, of course, use HDBSCAN to get more to the very core of these topics, but it often throws out a lot of documents that could be useful for yeah, could be or most likely are in in the cluster. So it's rather strict from from the default settings, which is fine, because it really depends on your approach. But there are more and more packages that I've seen developed that focus on on the explorative approach of essentially BERTopic. So creating a 2d representation, and do the do the labeling yourself and see if some things make sense. So that's, that's what we're talking, for example, also gives back to you there visualizations where you can have a 2d representation of the documents and the related topics. And there are some other packages that go beyond even that, where they say, okay, now that we have those potential topics, let's see if they make sense. Let's label them ourselves. So that that human labeling becomes more and more important. ", "podNum": 28, "speaker": "Maarten Grootendorst"}, {"_additional": {"id": "d56ef32c-67bf-4da4-a9e0-c1fc00fe5f96", "vector": [0.105038926, -0.07098875, -0.092692025, -0.17594536, -0.08636647, -0.09338485, -0.027309254, 0.023901034, -0.066118315, -0.028005939, -0.10454265, 0.051810328, 0.07732477, -0.08092053, 0.062477525, 0.014248117, 0.1191389, 0.045270365, -0.27946368, -0.097004525, -0.18297382, -0.026774429, -0.060749147, 0.0052284333, -0.0038637095, 0.05319475, -0.088754274, 0.10556369, -0.052141353, -0.09059044, -0.025727155, 0.0003386736, 0.106078245, -0.028794935, -0.16566558, 0.124156475, -0.026064962, 0.112143755, -0.01724592, -0.039227277, -0.1025667, -0.01574509, -0.16815002, 0.1627394, 0.054451257, -0.012292726, -0.09775749, -0.0786496, 0.035843637, 0.020824244, -0.0001033921, 0.09567253, -0.061585378, 0.012870302, -0.14572585, 0.110846095, 0.07473795, -0.044021893, -0.15901856, 0.14450312, 0.004015957, -0.05445395, -0.10546989, 0.17714591, 0.20508018, -0.10849836, 0.034732472, 0.019878194, -0.18965559, 0.27339956, -0.13869165, -0.22858213, -0.2249034, 0.2126185, 0.048030406, 0.11587484, -0.052484643, -0.028144345, 0.13997093, -0.052210152, 0.011906805, -0.078305304, -0.05388283, 0.007239376, 0.13501501, -0.028074732, 0.1390604, 0.06012657, 0.17949504, 0.013342823, 0.00532224, -0.119881704, 0.022460738, 0.031546783, 0.12084981, -0.0009773374, 0.066805445, -0.14872523, -0.013760078, 0.1980753, -0.23759039, -0.041299995, -0.29105955, -0.28337407, 0.103219725, -0.24613006, 0.20790476, 0.054293107, 0.115549415, -0.12649532, 0.015451571, 0.01024103, 0.0019335652, -0.046895992, -0.06175587, 0.14928263, -0.14979523, 0.08916116, 0.21194157, -0.00089189137, 0.092274725, -0.024900673, -0.06833953, 0.17882049, 0.15372719, -0.1725512, 0.03034352, 0.16399838, 0.053980242, -0.07564227, 0.15766035, 0.0056248973, 0.16967866, 0.2365296, -0.20779903, -0.12629397, 0.02561527, 0.013347312, -0.079421185, 0.07632839, -0.049400378, 0.29321313, 0.21972315, 0.10612125, -0.30582616, 0.18414824, -0.17160538, 0.1775413, 0.10672197, -0.28937703, -0.018965699, 0.12870383, 0.06461839, -0.16622204, 0.1540425, -0.082384266, 0.2119633, 0.17365095, -0.17343962, -0.2763955, -0.14210494, 0.001339874, -0.058354948, 0.04374064, 0.15951619, 0.049524534, 0.053289205, 0.07530581, -0.1433105, 0.08338902, 0.028246691, -0.12661254, 0.032154616, -0.1766871, 0.18788245, -0.0634343, -0.31521776, 0.14222954, 0.051907722, 0.033031106, 0.0018057949, 0.07869181, 0.047875434, 0.19613111, -0.01638841, 0.056266025, -0.01325825, 0.083349265, -0.15169345, 0.049209677, -0.050805762, -0.004153578, -0.07543741, 0.29019487, -0.027162684, -0.1389508, 0.0135200685, 0.06667206, -0.21347596, -0.064822964, -0.21489896, -0.24215515, -0.061486796, -0.20000623, 0.06895435, -0.14307253, 0.3605209, -0.35851088, 0.008977015, 0.16458707, -0.06998301, -0.18745928, -0.06470029, 0.09051225, -0.0074827443, -0.28273404, -0.18760674, 0.085751295, -0.200195, 0.07340178, -0.10488639, -0.109619044, 0.089289345, -0.39197072, -0.38879973, -0.01563837, 0.060882043, 0.20645642, -0.108303435, 0.110595755, 0.2961643, 0.029483914, 0.0071346713, 0.16499615, -0.0093918545, -0.054729626, 0.11646597, -0.024084399, -0.058398236, -0.06932359, -0.19751753, 0.24927323, -0.05598411, -0.06385952, 0.17199934, 0.46428546, 0.03575791, 0.17119911, -0.015027631, 0.20882612, -0.38766843, 0.11520712, -0.022458479, -0.052504465, -0.21075194, 0.01061471, -0.35459948, 0.017395152, -0.11531545, 0.059617493, 0.38441998, -0.10593121, -0.09301162, 0.119294345, 0.039733738, 0.06518652, -0.050643772, 0.34746018, -0.18327525, -0.049589645, -0.21262906, -0.022638157, 0.24163055, 0.07568732, 0.055840265, 0.17957914, 0.03660057, 0.09913397, -0.17769895, -0.000119450844, 0.01701649, -0.096582785, -0.093250185, 0.24488552, -0.016711336, -0.09796681, 0.05978477, 0.021451684, 0.22985694, -0.15694581, 0.04718601, 0.087480366, -0.05043141, 0.13215746, -0.07516026, 0.058320027, -0.007287518, 0.0948006, 0.23982826, 0.04433692, -0.11993575, 0.099529594, -0.20215425, -0.039984006, -0.09835899, -0.13005674, 0.13488784, 0.13762704, 0.14066881, 0.017849116, 0.006145813, -0.09266108, -0.0741668, 0.092862666, -0.09684794, 0.08856773, -0.22734348, 0.027287822, -0.06667332, -0.030856308, -0.113012314, -0.13479872, 0.0067797084, 0.21623468, 0.024540856, 0.17930298, -0.17699194, 0.07429068, -0.051594403, -0.020489031, 0.2531409, -0.08604629, -0.35562775, 0.108691745, 0.25931272, 0.18327987, -0.07505733, 0.16257961, -0.0344994, -0.024255078, -0.10117853, 0.14082828, -0.07815474, 0.21858847, 0.268903, -0.06467675, 0.046999197, 0.3835023, -0.08248526, 0.0076657375, -0.049509257, 0.19041784, 0.018701348, 0.03520583, 0.20823431, 0.06058331, -0.07453603, -0.005125879, -0.0037325888, -0.058310993, 0.014615598, -0.08530818, -0.28880367, 0.20382673, -0.09174337, -0.041071113, 0.07087526, -0.15535249, 0.0076134093, 0.07772163, 0.117351435, -0.070458524, 0.09097509, 0.03243793, 0.10598351, -0.21022575, 0.010336228, -0.1282375, -0.15613806, 0.28231546, 0.22404385, -0.0038657, 0.17343788, 0.055325378]}, "content": "Yeah. Um, yeah. I'm super big fan of this. So Sebastian Hofstatter established this in a really cool work where he showed how you can distill knowledge from cross encoders to bi-encoders. Which maps to the margin MSE loss, which solves a lot of these is issues. So in contrastive training, you need the positive to be really positive to the query, and the negative must be really negative to the query. So you spend a lot of time cleaning and trying to get like the hardest possible negative that is still a negative and not yet a positive. But with margin MSE loss, you take the triplet query positive and some other candidates, you pass it through a cross encoder to get like estimates from the cross encoder, how close are the two candidates to the query? And then you transfer this knowledge to a bi-encoder. And this totally eliminates the issue of getting really clean data. So you can run it with like really dirty data, which is nice. You can run it with like really, really hard negative so far with. If you trained buying coders and the negative is like too hard for when bi-encoder. That extremely hurts your performance, but now you can still still run it. So I'm a big fan, so I, in most cases I moved away from contrastive training to margin MSE training. Downside here is a bit more overhead, so contrastive training there, it's like really easy to get training examples, you go on Stack Exchange, You download it, you get the question, you get like 400 million questions, the highest rank answer, so you get directly a hundred million uh, pairs you can use from contrastive training, but with margin MSE loss you have to do negative mining. You have to have good cross encoder. You have to take the cross encoder to score all Query anchor, uh, query positive negative triplets. So there's like a lot of overhead involved in that.", "podNum": 33, "speaker": "Nils Reimers"}, {"_additional": {"id": "d58212e2-56fd-48a0-a4e5-9afc464f479d", "vector": [-0.064423695, -0.17077592, -0.011102233, -0.08101091, -0.0005065915, -0.15849927, 0.056751125, -0.07104768, 0.08744317, -0.02644337, 0.03292969, 0.1689462, 0.088793114, 0.015256133, 0.25866547, -0.032008056, 0.02010607, -0.07165142, -0.35870862, 0.019533895, -0.121811435, -0.044538774, 0.037751973, -0.025367122, -0.045588728, 0.075396866, -0.05130285, 0.043018874, -0.15387598, -0.0731538, 0.014307915, 0.11629197, -0.10594069, -0.11653124, -0.04739595, 0.08802121, -0.046852127, 0.12416207, 0.0043200357, -0.059113137, -0.06823947, -0.048794217, -0.026933849, 0.19606175, 0.11271926, 0.0024602935, -0.06334466, -0.0044124997, -0.0025324263, 0.095129654, -0.032339796, 0.012249642, -0.08878815, 0.010182319, -0.06002858, 0.17384432, -0.059927095, 0.08432828, 0.017757325, 0.07674309, -0.010897716, -0.08042808, -0.10537204, 0.3404225, 0.12359902, -0.10093631, -0.055765048, -0.099331036, -0.07061889, 0.11085336, 0.036717393, -0.01359896, -0.12706392, 0.17394966, -0.018476766, -0.049617082, -0.026900362, -0.060543273, 0.04318654, -0.018081108, -0.010791406, -0.03520841, 0.11646923, 0.11450894, 0.012998195, -0.020792713, 0.15444905, 0.10840434, 0.0205856, -0.023871418, -0.13659343, -0.11502526, 0.063539, -0.022944491, -0.062325757, 0.03555184, 0.08089697, -0.07481398, -0.028828872, 0.14361615, -0.23037791, -0.006541064, -0.104478024, -0.23778704, 0.075553775, -0.22281566, 0.01893974, 0.02966605, 0.086053334, -0.07481803, -0.09657939, -0.038035102, 0.0262498, -0.042651735, -0.00717236, -0.05667072, -0.15452977, 0.039018333, 0.08987809, -0.1725948, 0.025410032, -0.02827858, -0.000502388, 0.052081134, -0.08755256, -0.09812826, 0.13150555, 0.20431808, 0.18132, -0.062116407, 0.05818145, -0.0114865815, 0.18410641, 0.18228942, -0.06589926, -0.08048678, 0.045479435, -0.068024695, -0.03758868, 0.06908247, 0.004709568, 0.1845746, 0.120921105, 0.101002246, -0.2106587, 0.16099668, -0.10021388, -0.037186317, 0.035051607, -0.1708299, -0.05641974, -0.021301027, 0.15762338, -0.018482668, 0.038268328, -0.079926826, 0.10179946, 0.10812705, 0.008537795, -0.09671321, -0.06719451, 0.040789682, -0.0132245105, 0.07165988, 0.16253656, -0.11848695, -0.07010725, -0.028630272, 0.029183708, 0.034942754, 0.0015345924, -0.030134859, -0.032353055, -0.029997379, 0.0015574042, -0.032248575, -0.31346977, 0.09236413, 0.032352537, 0.17882195, 0.091977365, 0.060441922, 0.038531303, 0.15629065, -0.057508238, 0.018537369, 0.028436255, 0.073621795, -0.0819278, -0.10610117, -0.03082785, -0.06589627, -0.008696629, 0.17592332, -0.007008247, 0.0011893986, 0.23057982, 0.02513903, -0.083965816, -0.058633327, -0.28504544, -0.16262516, 0.033279948, -0.19799292, -0.059974466, -0.073352344, 0.14423923, -0.04407627, 0.013535665, 0.054828357, -0.03584362, -0.03723555, -0.124706954, 0.078353636, 0.19214201, -0.017149786, -0.17095421, 0.043013547, -0.17443383, 0.02151363, -0.060119696, -0.2184006, -0.033397924, -0.34989935, -0.23863843, -0.21128051, -0.0144457985, 0.10262986, -0.02501288, 0.07862262, 0.17465037, 0.03887107, -0.025216825, 0.06757176, -0.059774764, 0.005904056, 0.12155795, -0.011920709, 0.03431932, 0.11405099, -0.14121413, 0.069416925, -0.052659635, 0.021943115, -0.07023123, 0.11716355, -0.0883459, 0.13018695, 0.06349652, 0.18148378, -0.06888003, -0.023236502, -0.12773792, 0.08185631, -0.12087809, -0.06521631, -0.306341, 0.14842793, -0.013706804, 0.1893098, 0.18364364, -0.21762338, -0.07633073, -0.14968522, 0.03396254, -0.08961923, 0.016313436, 0.2807693, -0.18333617, -0.0430667, -0.14497754, 0.106884055, 0.13806526, 0.07726984, 0.049942866, 0.11408564, 0.055762265, -0.13128862, -0.19516668, -0.024417514, -0.013855696, -0.21603096, 0.00069202716, 0.19096476, 0.0072433967, -0.11769327, -0.027877485, 0.056514453, 0.17558435, -0.14666559, 0.041661534, 0.061062932, -0.11499575, -0.026173174, 0.11600922, -0.03690289, 0.029133063, 0.11792327, 0.20576292, 0.10814813, 0.03637141, 0.022100925, -0.19687542, -0.032833993, -0.04007514, -0.050936677, 0.06451668, 0.054672677, 0.10135058, 0.031690452, 0.018184848, -0.01878115, -0.08026481, 0.06874682, 0.0036257952, 0.07700107, -0.1688911, 0.07212974, -0.01899845, 0.008824768, 0.0038873912, -0.096073315, 0.024142392, 0.17873651, 0.022619108, 0.1268793, 0.06903745, 0.06721264, -0.1062704, -0.059564058, 0.027687917, -0.053771377, -0.11564167, 0.05631657, 0.21908352, 0.1505805, -0.0672562, -0.09294335, -0.08103659, 0.029590052, 0.028473403, 0.108851105, 0.08981055, 0.1292321, 0.032874357, 0.100394346, 0.0354155, 0.22268921, -0.015151964, 0.015283721, -0.022471594, 0.17267711, -0.06510213, 0.09100878, 0.15476888, 0.012843837, -0.08283297, -0.11357647, 0.11590049, -0.306755, 0.050802723, -0.1135067, -0.04331838, 0.33450994, 0.0031515881, 0.14903945, 0.041231215, -0.17195173, -0.09064582, 0.04095655, -0.0030728239, -0.006652495, 0.061462186, -0.034532934, 0.1101628, -0.044405423, 0.032150272, 0.0016076267, -0.15178657, 0.23458177, 0.16221581, 0.1136199, 0.18392378, -0.048508175]}, "content": "Yeah, for sure. And I wanted to still blend also with kind of like what the value prop is in this neural frameworks and maybe as a segue to chatGPT, how chatGPT could change things. So like if we take the example of Haystack, so for example, what they allow you to do is that the query comes in, you can have a node and the way they model this is they have a DAG type of thing, right? So they have a directed acyclic graph. And so the query gets classified, let's say, with a query classifier, that's one node. And then after this query is classified, it can, depending on the class that is predicted, it can either go to dense retriever, or it can go to a keyword retriever, right? Let's say maybe it's based on length or some other features that you know work. So you have a boundary in your classifier. And then, but maybe in some cases, even it could go to both of these. And then you will have a further node that will read the results from these retrievers and will merge them and then present them in some way using, I don't know, RRF method or some reciprocal rank fusion or some other method. So and you can like play with this, you can have like different nodes do different things like one node could be, if you classified the query as a question, you could do a question answering. But if it was like a table related, like SQL table, so you classified it as a SQL compatible query, so you could go to that node and say, hey, can you also query the table? You can also do like document similarities, new documents come in. So it doesn't need always to be, that doesn't always need to be like on the retriever side. It could be as part of your backend pipeline somewhere where you need to do document similarity and then decide whether or not to even compute an embedding for this document. Maybe it didn't change or maybe it didn't change enough to warrant a new embedding. And so you might discard it and so on. But you also have this other nodes, which we talked about earlier about document extraction process. So you extract things and proceed to the embedding layer. Coming back to your question about chatGPT, I had an exposure to it, of course, I actually, well asked it, can you name my blog post? Because I was a little stuck there and I grounded it and I said, hey, I wrote another blog post about vector databases and this is how it was called, not all vector databases are made equal. Maybe you can play on those words or something. But it decided not to use the same sort of words and just gave me a neural search frameworks. I had to add comparison. I was like, oh, boom, cool. You cannot imagine, you can do the work and then it leads up to the posting and you're like, how should I name it? Then you go to your friends, your wife, and they're like, how should I name my blog post? How do I know? So in these really strange situations, you can reach out to systems like chatGPT. If I went on duckduckgo or Bing or Google or something and I asked the same question, I probably wouldn't get an answer. I would get a bunch of links and like, what should I do with these links? This distracts me more than it gives me value. But in chatGPT, I got an instant answer and I was like, I like it. I spent maybe five minutes thinking about it and I liked it and I slapped it on the title. That was fine. So I think in some sense, maybe to me, this wasn't even a search experience in this kind of basic definition or sort of the way we used to it definition that, okay, I need to type something and then I need to examine links or examine some output, go check the results and then decide myself, like, am I satisfied or not? In chatGPT, you don't have any URLs coming back to you. Not yet, at least. Maybe they will be added. Who knows? But like today, it's more like a companion that you can talk to. In some sense, I was dreaming of such a companion. Maybe, you know, when you study, you have all these books and papers and everything, but can you really quickly make sense of, or can you find an answer to that specific nagging question like you had during the lecture? It's super hard, right? So of course you can go to search engine and start typing all these queries, but here you can have kind of like a sensible discussion in a way. Of course, I know some people were even hysterically laughing at the results and so on and so forth. So maybe it's not purposed for all situations and also for all audiences. It was actually a discovery for me. There was one linguist that I was following. He said that he cannot use general web search engines because every time he types something, they don't understand what he, they don't have the data. It's not even about understanding. They don't have the data. And so he needs to go to libraries and like read books that are not indexed in this search engines and things like that. So for these very specific niche use cases, maybe chatGPT might not work. It depends on the data again. But I think it was surprisingly clever, right? If I can say so about AI. It wasn't always static and you explained it well that it takes different paths in the tree when it computes the answer. And the other question I asked, like, can you find a bug in this code that I wrote and it just leaks memory at some point. It gave some sensible suggestions. And I felt like, I know that it's kind of like a silicon there. Like I cannot maybe like, I still need to examine some caution and sort of not fully trust maybe for life sensitive situations or something like that, you know, or medicine or insurance or something like that. But like things that I know it has indexed and humans have written that, you know, and it has been sort of vetted multiple times. And so also upvoted a bunch of times on Stack Overflow if you were talking about coding. And so there is some evidence that this might be the answer. But I think it was still surprising that how it changes the perception of search, even if we can talk about search in this case, that it actually generates the answer. You know, search engines don't generate answers today, like beyond maybe, okay, you.com and Google, you.com I think is more advanced than this, but like Google has this snippets, you know, where it says, you know, probably the answer is this. And so they commingle it with URLs. But like in chatGPT, you don't have any URLs, it just talks to you and then you can continue the discussion. I don't know. It was fascinating. But I still don't know if this will make it into the necessarily search experience. Like so in search, I think it's very functional. You know, if I walk down the street and I see something on like on the shop window, I take a picture and I say, I want this. And so it finds by the image. So that is still a search experience for me. So in some sense, maybe in the future, you know, we will have control F on everything in the world. Right. So like as I walk everywhere, I can kind of mentally press that control F maybe in some device, maybe on top of me, like glasses or something. I don't know. VR. But like today, a lot of places miss this. And still, there are a lot of contexts and situations when you ask yourself, what is this? Do I know this? You know, and you have some other like subsequent questions, but there is no way to ask them because you can pull up the phone and start typing and it's freezing weather and you're like, oh my God. It's kind of like a deteriorating experience. But I think it could be so much more interactive and multimodal. And I think neural search especially enables multimodality situations, right? And experiences so that you can actually like not constrain yourself to the point that am I asking like a textual query or I just have a query. I have something on my mind, right? Or maybe I saw something. Can you tell me more about it? So I think maybe chatGPT might push us in that direction that not only it will find things but it will also reason about things and help you reason. But the creativity part, I don't think it will disappear. I don't think, at least not now, I don't see how AI can solve creativity part, like create things for you. Yeah, it did create the title, you know, but maybe a more creative person than me could actually create a better title, right? And things like that. So yeah. ", "podNum": 34, "speaker": "Dmitry"}, {"_additional": {"id": "d58a534c-eaf1-43aa-aee8-a66d8d6a2269", "vector": [-0.0782869, -0.18123521, -0.15017106, -0.35976726, 0.09307794, -0.027247304, -0.2296745, 0.0648116, 0.046726264, 0.020450395, 0.035346564, 0.1402218, 0.16440213, 0.0861153, -0.03903869, -0.07419504, 0.10301888, 0.08829077, -0.46354514, 0.1377348, -0.15465033, 0.041673124, 0.088120475, -0.09687783, 0.14410417, -0.024964675, -0.13812657, -0.30254206, 0.0065785744, -0.14934835, 0.10436805, 0.36609903, 0.30149907, 0.035141435, -0.05667951, 0.051474385, 0.07236439, 0.23241787, -0.18893513, 0.14132498, -0.0741362, -0.12348677, -0.0008544907, 0.12813243, -0.029417574, -0.21631202, -0.11375336, 0.018298265, -0.09791595, 0.32521945, -0.30876327, -0.13040257, -0.22985129, 0.008811837, -0.09101506, 0.17250435, 0.31763586, -0.37436253, -0.044294644, -0.1372731, 0.037767246, 0.002517496, 0.027965853, 0.3071317, 0.44386965, -0.016227413, 0.056694128, 0.07203359, 0.20427732, 0.006295836, 0.08889474, -0.10455712, -0.16458851, 0.3169621, -0.16827849, 0.08607628, -0.045712035, -0.0124258045, 0.104145095, -0.28937453, 0.048244555, 0.0790817, 0.19827731, -0.06736223, 0.040475838, 0.07758584, 0.08230914, 0.0925372, -0.25780895, 0.12143803, -0.055983115, -0.12276765, 0.19479497, -0.046686627, -0.10209997, 0.13993631, -0.11280028, -0.15482035, 0.46446657, 0.056525797, -0.39359227, 0.08078307, 0.12531593, -0.029035613, -0.07536451, -0.29134077, -0.0069673164, -0.011274702, -0.019214232, -0.011517762, -0.030330325, 0.07350732, -0.14012222, -0.40071422, -0.011631975, -0.47752267, 0.17373928, 0.039644804, 0.08105806, -0.21485886, 0.08441688, -0.1775533, 0.12391583, 0.114803836, 0.29942185, 0.03502948, -0.15697995, 0.28013793, 0.27939996, -0.0791918, 0.30338877, -0.017680416, 0.25276375, 0.117874786, 0.007883162, -0.30971292, 0.093821496, -0.22160311, -0.12910701, 0.362248, 0.05111084, 0.09321542, 0.1161623, 0.048557192, -0.06467036, 0.39304557, -0.2963918, -0.23219907, 0.04493164, -0.09396902, 0.16171782, -0.17056772, 0.23616366, -0.06242305, 0.054270398, -0.014064366, 0.0049927183, -0.0067958175, -0.34320766, 0.0042650998, -0.2837115, 0.08370229, -0.051074766, 0.101531364, 0.23182896, -0.1407864, -0.03829827, -0.08652903, 0.17110452, -0.00926123, 0.06353542, -0.06915314, -0.051861666, 0.0996948, 0.15664077, -0.08183014, -0.41174594, -0.22909813, 0.16375852, 0.09454116, 0.0072265035, -0.26476064, 0.059362434, 0.14219722, -0.061639655, -0.33316982, 0.1216918, 0.010760104, 0.033238493, -0.1246912, 0.2696095, -0.073128164, -0.06430815, -0.18039505, 0.0028897151, -0.30231497, 0.3328179, 0.38641837, -0.018167138, 0.07173859, -0.2195379, -0.058290113, -0.1395275, -0.034397237, 0.053944588, 0.01881865, -0.10416554, 0.21407132, -0.46126, 0.24047157, 0.04962106, 0.045415763, -0.03981671, 0.17856953, 0.17389394, 0.07419961, -0.42603606, -0.19072716, -0.2715126, 0.14372507, -0.06984474, -0.2659869, -0.10768769, -0.2833324, -0.32726622, -0.037974097, -0.16888188, 0.004258083, -0.07142361, 0.09306423, -0.038445517, 0.18892299, -0.013344532, -0.104969025, -0.2608548, 0.0024712314, -0.026916858, -0.38035163, -0.07153387, 0.021777932, -0.046618883, -0.17314127, -0.24757382, -0.15816076, -0.055831026, 0.04850055, -0.13801347, 0.27557102, 0.008671324, 0.101135895, -0.28329176, -0.24895588, 0.22564414, 0.016673546, -0.24391922, -0.3319475, -0.12514551, 0.027407225, 0.036185406, 0.18757102, 0.30436975, -0.44226456, -0.13146774, 0.051826797, 0.1548929, 0.21230683, -0.13974632, 0.053995986, -0.11211096, -0.25093573, -0.039877046, 0.29189277, 0.08713536, 0.015926735, 0.12957224, 0.10463822, -0.013107985, -0.26381245, -0.2599756, -0.11025623, 0.062163986, -0.20525059, -0.039960675, 0.36600536, -0.14974967, -0.19257651, -0.17096455, 0.23416989, -0.07172312, -0.057714187, 0.073765144, -0.22515316, -0.5318475, 0.09019731, 0.2735404, 0.018481174, 0.07998067, 0.3079447, 0.2788648, -0.046259247, 0.07236616, 0.09986095, 0.021424731, -0.045666736, 0.025868822, -0.20664065, 0.33188367, 0.40979528, 0.28303596, -0.03816116, -0.0059342785, -0.15861574, 0.00057754666, 0.09269585, 0.010566346, 0.020517513, -0.26728672, 0.48283, -0.010846662, 0.03587817, -0.0892962, -0.13233921, 0.11822573, 0.16785064, 0.015682952, 0.1854802, -0.027056564, 0.24455199, 0.0040184706, 0.097605236, 0.112283096, -0.012827997, -0.28721085, 0.16532171, 0.24852094, 0.09835391, 0.16488186, 0.23992154, -0.15962568, 0.23794588, 0.2144785, 0.3156069, 0.04664173, 0.0057500214, 0.112170294, 0.0770676, -0.07374621, 0.35340178, 0.18829353, -0.007814094, 0.027520955, 0.30999368, -0.14691283, -0.033701457, 0.13254327, 0.052932978, -0.023838561, -0.03815181, -0.24873948, -0.025119826, 0.13415429, -0.13639706, -0.04049309, 0.22416845, 0.13839293, 0.021409187, -0.08777528, -0.19951221, 0.006893466, -0.031441472, -0.07177609, -0.043403927, 0.16704434, 0.08278086, -0.08827318, -0.049739957, 0.109500766, 0.028811127, 0.15889572, 0.13168505, 0.28137314, 0.008667883, -0.021532366, 0.04100122]}, "content": "Yeah, I think that idea is super powerful, the decoupling of clustering and topic extraction slash kind of metadata analysis. Like if we have patients, we could put, say, their, you know, like images, like medical images would be a good one to vectorize or I don't know, maybe we have like clinical notes that we can vectorize. And then we'd also have the metadata like age, weight, height, pre-existing conditions. And so with also this cluster analysis, we can, you know, have these sort of like histograms, all the violin plots, all the kind of things for each of the metadata of each of the clusters as well. Do you think about that kind of thing also, like symbolic data visualization achieved through clusters of metadata on them? ", "podNum": 28, "speaker": "Connor Shorten"}, {"_additional": {"id": "d62b6746-b97b-425c-ad33-079b6530e76f", "vector": [-0.08032643, -0.1780387, -0.2174686, -0.11881687, 0.12768118, -0.096638456, -0.18812421, 0.10113663, 0.035135936, -0.01787368, -0.14289428, 0.07939096, 0.030276375, 0.24536201, 0.46196422, 0.08379962, 0.04367085, -0.007855489, -0.5528077, -0.025813371, -0.08798433, -0.0881863, 0.23189434, -0.11814664, -0.3186837, 0.07001317, -0.031342503, -0.06314652, 0.038289454, 0.046248402, -0.07611901, 0.1032077, -0.029343585, -0.13733816, -0.045541786, 0.047822744, 0.279536, 0.056198098, 0.150919, -0.05640586, -0.17382635, -0.04808132, -0.02369334, 0.19081874, -0.047270417, -0.05167797, -0.069682986, 0.013291993, -0.17939171, 0.18721022, -0.012361326, 0.09561063, -0.10693494, -0.29922637, -0.05816905, 0.25653985, -0.20664787, -0.3068145, -0.18751253, -0.19815758, -0.046881042, 0.00926485, -0.08807189, 0.38155815, 0.034916557, -0.16978355, -0.003272297, -0.23332115, 0.038220547, -0.1294237, 0.20695226, -0.035868578, -0.03485116, 0.09244367, -0.07668079, -0.043843176, -0.037149403, -0.07550001, -0.014797242, -0.1452696, -0.17480731, -0.022528777, 0.28757817, 0.051568355, 0.12716539, -0.12540574, 0.104767494, -0.029349515, 0.072968386, 0.020735694, -0.19863614, -0.27678654, 0.049235888, 0.044478815, -0.18971114, 0.28832135, 0.026100224, -0.16356374, -0.018174829, 0.011017746, -0.34199673, 0.10521547, -0.001015629, -0.49202767, 0.21192513, -0.0021617967, -0.08659252, 0.09025747, 0.22309472, -0.17905375, 0.11885189, 0.10937972, -0.15804012, -0.02076471, -0.039128553, 0.05774759, 0.015294166, -0.076242276, 0.20213683, -0.09565862, -0.010528004, -0.11019806, -0.024678735, -0.039699726, 0.013856313, -0.07936499, 0.21799938, 0.3090178, 0.34213018, -0.088932715, 0.08925425, -0.069981955, 0.35862684, 0.31607026, 0.019129934, -0.32612586, -0.12595995, -0.18051724, -0.16375525, 0.25491104, 0.03896, 0.02041577, 0.05250147, 0.10603283, -0.43523842, 0.26738068, -0.18858378, 0.05359033, 0.033742674, -0.11454834, 0.18705823, 0.18083194, 0.2677832, 0.06449996, 0.13342668, 0.09353281, 0.15475963, 0.05659553, -0.061276503, -0.0117208855, -0.14440846, 0.104197316, 0.020245241, -0.1828272, 0.34159923, -0.26484987, -0.0595575, 0.07087251, 0.12393346, 0.05008608, 0.018462092, -0.11229567, -0.28169987, -0.12950143, 0.020929309, 0.105849326, -0.23766606, -0.045284577, 0.008800613, 0.24933903, 0.084506445, 0.035085376, 0.13117565, 0.151706, -0.15644741, 0.14308082, 0.12632635, 0.059889104, 0.07471044, -0.022862969, 0.38776335, -0.07943149, 0.112936266, -0.06951166, -0.105727114, -0.2066655, 0.20862424, -0.04021552, -0.1392469, -0.026819305, -0.032379217, -0.3817027, -0.13573332, -0.046729367, 0.16584548, -0.0321575, 0.3804361, 0.113099314, 0.12982123, 0.021797227, 0.12550603, -0.010923586, -0.35614115, 0.21948531, 0.056344748, -0.12737933, -0.194295, -0.05286291, -0.082631454, -0.020469602, -0.2110496, -0.3696533, -0.14463158, -0.3594739, -0.3312773, -0.19221564, 0.078822024, 0.19126533, 0.013048897, -0.050242048, 0.20374082, 0.06878496, 0.020590305, -0.042299747, 0.09044365, -0.1214763, -0.05980528, -0.070193365, 0.25565076, -0.14579485, -0.08907994, 0.16074221, 0.100117795, -0.0475021, 0.16668402, 0.30333403, -0.14386714, 0.14211573, -0.068459146, -0.110632144, -0.32722542, -0.22136363, -0.2108062, -0.10588324, 0.04207224, 0.13716173, -0.29261753, -0.03971466, 0.1582589, 0.114746355, 0.43385082, -0.35081118, 0.083774514, 0.0318503, 0.14885436, -0.110714965, -0.0134990355, 0.21585624, -0.21408747, -0.062478, -0.33881778, 0.3115435, 0.16571227, 0.058540992, 0.19760016, 0.22880684, -0.17781408, -0.3383051, -0.25453776, 0.010011783, 0.079649635, -0.23143528, 0.0039048563, 0.2142875, -0.17194404, -0.32353988, -0.057949476, 0.20871468, 0.23530221, 0.011254011, -0.05720539, -0.02279737, -0.20986165, -0.10907881, 0.055281255, -0.19851127, 0.2306587, 0.2715742, 0.30912662, 0.010985917, -0.039928764, -0.16692363, 0.08309803, 0.046865087, 0.059748996, -0.28892392, 0.13445233, 0.14056173, 0.19987784, 0.025082218, -0.028658986, -0.19799832, -0.07543915, 0.07580165, -0.12820747, 0.06527604, -0.17424597, 0.2505414, 0.21565576, 0.008634354, -0.20469765, -0.050744977, 0.053237796, 0.2348633, 0.09661972, 0.35576382, -0.06237414, 0.17225865, -0.0063585066, 0.03285638, 0.048785917, -0.004748021, -0.3086634, 0.07680209, 0.35143214, 0.11273966, -0.13059139, -0.057030935, -0.0104667675, 0.19065431, 0.253148, 0.09398155, 0.25189647, 0.022353286, 0.028519016, 0.0841174, 0.26217395, 0.56722885, 0.003856337, 0.04448737, -0.10897678, 0.10928614, -0.031649835, 0.09744846, 0.20622244, -0.036441263, -0.13677795, -0.21502002, -0.15083449, -0.23176178, 0.09562643, 0.12250783, -0.19645222, 0.5209466, 0.032402676, 0.19625099, -0.08537675, 0.0736766, -0.110682204, 0.011625628, -0.34140077, -0.083740175, 0.06089426, -0.116729096, -0.025916796, -0.11107779, -0.007900479, -0.09642879, -0.036252107, 0.29322723, 0.41612726, 0.041506916, 0.072772026, 0.0059462255]}, "content": "Yeah, super interesting. And I'm really excited to come back to that kind of the prompting it to ground its results where you say like these little subtle details of like when you template it, like please based on the search results or tell us if you don't know, cite which search results are the most relevant. But one other investigation is template thing that I thought was so interesting is that it can kind of read the JSON keys. Like when you have a JSON dictionary that you hand off from Weaviate to ChatGPT, usually the semantic keys are pretty good compared but then you also with the template, you have these like little language biases like again, like speaker said content on date like that little said and on provide like a little more semantic clues and key value naming. Maybe we could talk a little more about that. Just ability to read JSON data. And I think you also touched on it, but the ability to output JSON data like that. ", "podNum": 35, "speaker": "Connor Shorten"}, {"_additional": {"id": "d63f80fe-36b2-4502-9a33-18de27da8445", "vector": [-0.15168604, -0.08962815, 0.037403934, -0.11157931, 0.06110857, -0.1176496, 0.094552174, -0.115269825, 0.0070556793, -0.0045646755, 0.13519727, -0.08754124, -0.07800131, 0.17689416, -0.020072758, -0.2522879, 0.13898794, 0.117924884, -0.24430381, -0.07689308, -0.16832866, -0.040351793, 0.03210389, 0.02976021, -0.034661144, -0.039504454, -0.14436862, -0.08971986, 0.08263591, -0.33308128, -0.044353757, 0.104472525, 0.090702094, -0.23231429, -0.1552345, 0.13447848, 0.027315935, 0.07804375, 0.08073787, 0.16653974, -0.29089034, 0.01546085, 0.08289039, 0.32272547, -0.012977417, -0.11681575, -0.11860634, 0.07024361, 0.082787715, -0.080473214, -0.080953635, -0.06698626, -0.3622783, -0.2517321, -0.054083202, 0.199197, 0.07941324, -0.17658053, -0.070400886, -0.205062, 0.0854353, -0.14840835, -0.15252347, 0.37428957, 0.3991423, -0.14722973, 0.0005366085, 0.026538236, 0.0068955193, -0.012287524, -0.12132793, 0.05782857, -0.09408661, 0.2516554, 0.012148183, -0.044407852, 0.19184658, 0.09501199, 0.15568699, 0.0017880438, -0.017841414, -0.077603035, -0.1305393, -0.07318686, 0.08606986, 0.080181725, 0.051112756, 0.03695805, -0.10098241, -0.15843193, -0.03318285, 0.0023274994, -0.3716688, 0.041914083, -0.1428338, 0.22592007, 0.091931514, -0.17381662, 0.1225438, 0.34551334, -0.16850987, -0.088869855, 0.28019866, -0.18777426, -0.083331615, -0.22321571, -0.05279884, -0.025559533, 0.24231264, 0.014002501, -0.058230303, 0.0055885683, -0.045501374, 0.025761751, -0.08374885, -0.23608597, 0.12837586, -0.039361384, 0.22317451, -0.06960788, 0.04441636, -0.039241653, 0.1400429, 0.117067896, 0.09841642, -0.01832576, -0.074073724, 0.1535056, 0.24762568, 0.005691049, 0.2257374, -0.044031244, -0.00905006, 0.20307367, -0.10964518, -0.16468261, -0.078673325, -0.03939273, -0.18545166, 0.14660147, -0.20694773, 0.16902333, 0.04278453, -0.2067526, -0.18545812, 0.286787, -0.110914394, 0.032397307, -0.11791256, 0.07501202, -0.09968657, -0.16123782, 0.3435391, -0.04384252, 0.059403613, -0.14554751, -0.09841246, 0.23164615, 0.097098365, -0.08513203, -0.20514537, 0.14235337, -0.09334494, -0.258613, 0.102200955, -0.11017887, 0.07385927, -0.057484463, 0.018553067, 0.016551932, -0.028688984, -0.06943732, 0.031480376, 0.08633021, 0.31275782, -0.07289745, -0.2652147, -0.08766587, 0.13524626, 0.09015347, -0.00963927, -0.039869793, 0.0049321605, 0.27482632, 0.03072535, -0.009034032, 0.0056732, 0.10547618, -0.18195173, -0.010719166, 0.0045590494, -0.12840584, 0.23709449, 0.1876341, 0.024866935, 0.04438067, 0.24571012, 0.097148895, -0.14787568, 0.054788582, -0.19465232, -0.29575822, 0.17302264, -0.13741207, 0.2217926, -0.1846621, 0.2354738, -0.0145289, -0.26186487, 0.35533184, -0.12019031, -0.1725799, -0.38034827, 0.15081577, 0.21088465, 0.06435871, -0.08395395, -0.06425267, -0.11966452, 0.020202728, -0.0044420063, -0.16374373, 0.086790964, -0.3526533, -0.24168794, -0.31144518, -0.06338751, -0.015791414, -0.08867384, -0.0016513559, 0.18315881, 0.21108232, -0.06196962, 0.10805584, -0.049909536, 0.06373303, 0.0012120467, -0.124155864, 0.11970907, 0.12102635, 0.0033973088, 0.04400531, -0.033518706, 0.103462294, 0.12441171, 0.38452768, -0.17025079, 0.100854725, -0.18241756, 0.2925146, -0.3576064, 0.12193643, -0.088118434, 0.061462067, -0.070091225, -0.115313806, -0.33655697, -0.003403439, -0.090694115, 0.25978324, 0.25153083, -0.30411917, -0.10894113, -0.023639156, -0.043412946, -0.1142584, -0.15839241, 0.35352913, -0.025579218, -0.021693133, 0.024795204, 0.0723784, -0.0068767047, -0.05245401, 0.044382114, 0.16501373, -0.18009517, -0.22908854, -0.18615808, -7.9350975e-05, -0.030759413, -0.07945876, 0.14344238, 0.32945412, -0.054646857, -0.113758445, -0.26040283, 0.13560174, 0.12365113, -0.15878461, -0.009072487, 0.2574679, -0.25618955, 0.02519814, 0.094751686, 0.16371942, -0.08212103, -0.06046331, 0.22927897, 0.09002434, 0.25581172, 0.08610836, -0.16041534, 0.06768848, -0.06869351, 0.02444859, 0.24637696, 0.08046425, 0.20451777, 0.08833758, -0.05722622, 0.038366694, 0.042400744, 0.13949236, -0.17616501, 0.024367865, -0.121929646, 0.18125108, 0.06315045, -0.051029988, 0.048478007, 0.009372015, 0.14643449, 0.10744111, -0.11596604, 0.019078828, -0.10361213, 0.18758236, -0.12236987, -0.06765682, -0.17420395, -0.17955469, -0.21858047, 0.146725, 0.49021655, 0.43783763, -0.10216241, 0.12628612, -0.16408679, 0.07695087, -0.057934087, 0.20093419, 0.14991039, -0.0005923773, 0.07933621, -0.056617677, 0.03422173, 0.26118252, 0.05933541, 0.057063874, -0.02880359, 0.19013229, -0.11592715, 0.06258784, 0.25317308, 0.21740589, -0.21973142, -0.12252516, 0.08956142, -0.26483718, 0.037603226, -0.13021834, -0.012543205, 0.381753, -0.1056091, 0.17283776, 0.045816626, -0.28810027, -0.009711637, -0.0014539247, 0.09558271, -0.09934855, -0.02417432, -0.006273386, 0.058189385, -0.07216788, -0.029151766, -0.08916227, -0.06150915, 0.21051994, 0.1156819, 0.06739395, 0.040849384, 0.09428625]}, "content": "Yeah, and I want to like firstly congratulate you all on having this like science and product. It's so interesting. The BERT surgeon, this prune once for all, if I'm getting the name right. It's so cool seeing the science and the product together. And and so so I really want to get into the sparse zoo and how these models come to be the difference. I'm starting from the sparse transfer learning. I find that to be absolutely super interesting the way that, say, you sparsify a language model. And then, you know, we do in vector search a lot as we train with contrastive learning. We have maybe triplet losses or we have this multiple negatives ranking loss. So we can take a sparse model and then fine tune it with our kind of contrastive learning objectives to produce vectors. So what is the state of this sparse zoo? How do we sparse transfer learn, get new sparse models on the zoo? What does that all look like? ", "podNum": 27, "speaker": "Connor Shorten"}, {"_additional": {"id": "d6aee46e-c5a1-453c-8ca6-97e8e149c0c4", "vector": [0.03549119, -0.22366272, -0.0744862, -0.023294328, -0.14285761, -0.04906546, 0.10725877, -0.08733378, 0.087312005, 0.027283207, -0.13452134, 0.004556041, -0.1894129, 0.07663368, 0.3041761, 0.014743395, 0.1301077, -0.16277963, -0.27481055, 0.023652487, -0.1045942, -0.26987773, 0.18312216, -0.11041955, 0.1499125, -0.20502305, 0.18200013, 0.18944621, -0.24287823, -0.0065034404, -0.23358041, 0.09865272, 0.014722824, -0.16600892, -0.17182618, 0.2272439, 0.038864847, 0.06648783, 0.0020102262, 0.3330258, -0.15777025, -0.31973094, -0.0747084, 0.13654664, -0.0071941093, -0.08875217, -0.15385082, -0.13480264, -0.30989495, 0.12114315, -0.14663357, -0.11637711, -0.016555134, -0.026798015, 0.08259552, 0.42940003, 0.26364717, -0.3784273, 0.03953643, -0.114745334, 0.007671222, -0.11818444, -0.26250505, 0.50073713, 0.13365841, -0.29743862, -0.072232366, 0.031633787, -0.025905702, -0.04166482, 0.07485063, -0.20238474, 0.1048366, 0.06207193, -0.06671308, -0.15868077, 0.31741142, -0.12579548, -0.020122781, -0.017983321, 0.14045957, -0.44861555, -0.062200807, 0.10759015, 0.18167916, -0.020499483, -0.07952643, -0.12830931, -0.1334297, 0.120678954, -0.21183443, -0.278045, 0.031530425, 0.04046557, 0.22247197, 0.53454995, -0.0742961, -0.29266995, 0.045574408, 0.14540978, -0.2763797, 0.068689436, 0.2912829, -0.21038777, 0.060706332, -0.30324942, -0.153462, -0.074360766, 0.027594294, -0.29301658, 0.030861221, -0.008408238, 0.11767551, 0.16586313, 0.05022011, -0.01354444, -0.1671184, 0.25279328, 0.18282273, -0.04395041, 0.12614426, -0.15514028, 0.44513884, -0.059853725, 0.03628826, -0.39969212, -0.32153374, 0.21584705, 0.18991119, -0.08471984, 0.33944663, 0.016466968, 0.3034017, 0.2266381, -0.21782115, -0.08019497, 0.22640494, 0.2350738, -0.43932003, 0.37691662, 0.09964832, 0.22893226, 0.19773202, -0.08356059, -0.4850363, 0.33206838, -0.20443699, 0.11917519, 0.08389979, -0.16254409, -0.16399783, 0.07282577, 0.3565777, -0.26515135, 0.4030292, -0.08046034, -0.27629125, 0.25712177, -0.08990811, -0.062480427, -0.14293972, 0.10428772, -0.18232806, -0.037165817, 0.13320717, -0.1265693, 0.0352398, -0.028918765, 0.27207363, -0.09745233, 0.0693779, -0.013963029, -0.097180635, 0.10171755, 0.20940343, 0.028101541, -0.3420354, 0.17699799, 0.023558713, 0.185153, 0.2760316, -0.12427321, 0.4347184, 0.11210734, 0.061541475, -0.02089212, 0.12533444, 0.053411204, -0.11061795, -0.021891344, -0.13381198, 0.12504743, -0.068371765, 0.34099036, 0.1806548, -0.1821935, 0.30008525, 0.1104319, -0.01410117, -0.026764102, -0.49712476, -0.15569365, 0.10950883, -0.06958151, 0.093667194, -0.26700863, 0.47895396, -0.26399684, -0.012792762, 0.11886409, -0.15650956, -0.0074578226, -0.2562354, 0.321144, 0.011656128, 0.01029228, 0.03517075, 0.19661051, 0.0264588, -0.12520179, -0.063394666, -0.04265032, -0.14761762, -0.4754815, -0.32632858, -0.070083246, 0.01940171, -0.037595123, 0.32252502, 0.06433595, 0.33788776, -0.0021175519, -0.28253484, 0.02258858, -0.053072773, -0.10638763, 0.05460192, 0.100431465, 0.26770467, -0.090110034, -0.10663517, -0.084403396, -0.11644913, 0.09317545, 0.30829158, 0.25682345, -0.31014457, 0.1059192, 0.19509621, 0.238855, -0.31375125, -0.075925805, -0.17267668, 0.13286287, -0.33194715, -0.20287985, -0.11131864, 0.104442626, 0.06817553, 0.17337672, 0.38642263, -0.40313637, 0.013724908, -0.32536107, -0.08438206, -0.1252312, -0.014202639, 0.52720535, -0.42123884, -0.012268402, -0.16859269, 0.13931546, -0.27171773, -0.24724913, -0.40150687, 0.3039557, 0.030846167, 0.032119848, -0.3761707, -0.010919005, 0.02785827, -0.06177399, -0.119911134, 0.2302832, 0.25878888, -0.18106985, 0.14104502, 0.25897056, 0.14287749, -0.33645666, 0.13365135, -0.110966474, -0.32949802, 0.10081996, 0.1525006, 0.13017592, -0.07743023, 0.11150383, 0.28391898, 0.08274013, 0.21230434, 0.15265372, -0.0020223446, -0.15124561, -0.1320668, -0.26822734, 0.1734087, 0.28862837, -0.009806577, 0.06191538, 0.10409558, 0.014424607, -0.13153669, 0.1954393, 0.09342362, -0.15921378, -0.37471175, 0.008050829, -0.053377844, -0.10739227, 0.026708141, 0.07383724, 0.13403128, 0.18844673, -0.017267898, 0.00030058622, 0.081417195, 0.15314506, -0.2756667, 0.13337716, 0.27705383, 0.05328398, 0.22466049, 0.22520187, 0.4171672, 0.3365925, -0.17637953, 0.13401893, -0.11601905, 0.1593593, 0.21356863, 0.24680066, 0.19116676, 0.24328172, 0.00038689002, -0.1097124, -0.028809283, 0.39483905, 0.10000016, 0.033255596, -0.033470593, 0.3837984, -0.09741268, 0.13685054, 0.31146085, 0.09090225, -0.14148162, -0.16282505, 0.074895985, -0.6441779, 0.0020234794, -0.23699167, -0.25776827, 0.3933289, 0.03354942, 0.036175944, 0.007587973, -0.18769518, -0.24906603, 0.070450395, -0.098029025, -0.16799599, -0.14909562, -0.33051145, 0.15607911, -0.14614965, -0.12048578, 0.043365374, -0.2996048, 0.2923197, 0.35063738, -0.009471446, 0.043281533, -0.05207152]}, "content": "Yeah, that's interesting. That answer makes me think, if we're thinking about it as a ladder, are you training individual models at each rung of the ladder, or is it more of an ensemble where you have the lower rungs that are informing the models at the upper end?", "podNum": 32, "speaker": "Zain Hasan"}, {"_additional": {"id": "d6f71a5d-6821-4241-88c5-96dc1673a5ad", "vector": [-0.08508496, -0.23368075, -0.09064172, -0.5323974, 0.16597262, -0.076248124, 0.039112728, 0.21368589, 0.17364317, -0.089942545, -0.043167815, -0.0124479495, -0.18892246, 0.06271167, -0.26838997, -0.22831398, -0.016432513, -0.2961921, -0.06887908, -0.072196305, -0.29514393, 0.21605137, 0.2673893, -0.054101404, 0.018285204, -0.14740783, -0.08889185, -0.24542743, -0.01409516, -0.06578853, 0.20764756, -0.1930951, 0.2905081, -0.17182598, -0.22697392, 0.35547408, 0.06495775, -0.20970461, -0.14121456, 0.1299263, 0.02539051, -0.17820805, -0.15398553, -0.031938512, -0.0045834444, -0.41187686, -0.29430547, -0.29641882, 0.091220826, 0.39537087, -0.2287623, -0.076316476, -0.05409515, -0.07360913, 0.11015573, -0.04812118, 0.21461496, 0.38043582, 0.045187764, -0.117148176, 0.23139378, -0.15561052, -0.21894284, 0.3809072, 0.28854227, -0.3074058, 0.06824963, -0.3291531, -0.02760061, 0.04880075, -0.1595317, -0.095969975, 0.1481137, 0.074599184, -0.046067566, -0.0005695373, 0.09193416, -0.13857159, 0.08797658, -0.13015823, 0.2789892, -0.07553928, 0.2536599, -0.36328554, 0.15235859, 0.12785818, -0.0065619904, -0.0095211975, 0.111807376, -0.2121384, -0.28623098, -0.00048886985, 0.31986797, 0.0082623195, -0.23875457, 0.11605382, 0.14824188, 0.1740987, -0.4007913, 0.058587417, 0.11297039, -0.122063145, 0.10101015, -0.407556, -0.13564159, -0.04676584, 0.15287574, -0.011626291, 0.06422404, 0.09563194, -0.22622126, 0.004703436, 0.23410232, 0.03781721, 0.5258945, -0.08010812, 0.056469113, 0.13874051, 0.09624891, -0.036945775, -0.024138108, -0.020323498, 0.2633959, 0.11317482, -0.048234686, 0.0142833665, 0.1287708, 0.2730498, 0.37513632, 0.21507354, -0.057562873, 0.11652093, -0.10429676, 0.4266098, -0.17990582, 0.052028727, -0.15854011, -0.21205296, 0.02131927, 0.19560185, -0.2849196, -0.082697935, -0.13688788, -0.10951285, -0.18617925, 0.29245722, -0.046734057, 0.05116196, -0.012598575, -0.041908827, -0.16083969, 0.103078425, 0.32161507, 0.12288903, 0.29841557, 0.0718688, 0.294893, 0.2207132, -0.23159064, -0.25916213, -0.19196807, -0.22479977, -0.10372825, -0.105041765, -0.14960617, -0.17208879, -0.1262461, 0.24190006, -0.12547359, -0.005024031, -0.16104785, -0.22713953, -0.19867522, 0.05127811, 0.2238422, -0.048301715, 0.3444689, -0.14151366, 0.060708683, 0.19598626, -0.37132487, 0.15667933, 0.20543933, 0.30916125, 0.06626272, 0.011800602, 0.0036311168, 0.07414099, -0.16756585, -0.069268994, 0.19980335, -0.23780857, -0.12647884, -0.046830617, 0.07229053, -0.007450238, 0.08397135, 0.054025438, -0.072386116, -0.15625681, 0.14359301, -0.06193724, -0.02661632, -0.16258271, 0.06591185, -0.061710127, 0.18270247, 0.059795655, -0.120136306, 0.07358803, 0.11781485, -0.24100651, -0.16366725, 0.05175349, 0.05187878, -0.13805111, -0.27876526, 0.15024538, 0.029432416, 0.015983477, 0.016240956, 0.052404977, -0.03287007, -0.28500172, -0.29301614, -0.29318044, -0.19286233, -0.08502208, 0.10522528, 0.09681383, -0.023470711, 0.22885418, -0.09397976, -0.10377457, 0.19747208, -0.041740067, 0.099884, -0.11213335, 0.09026683, -0.05599856, 0.27884638, 0.20959845, 0.028938606, 0.017149009, 0.15106453, 0.30296233, -0.28004152, 0.24434896, -0.19255027, 0.06788643, 0.35557008, 0.06570223, -0.1702731, 0.08798009, 0.19783512, 0.021883333, -0.44668502, 0.08740039, 0.2500741, 0.5218556, 0.22598185, -0.090090245, -0.30571705, 0.008150253, -0.072339535, 0.048388116, -0.017327249, 0.3129307, 0.18112469, 0.044173367, -0.28134742, 0.040172294, -0.050801087, -0.13525325, -0.14220485, 0.13668236, 0.057811603, -0.2357716, -0.2527287, 0.43521804, -0.18189773, 0.2566347, 0.3756924, -0.07762773, -0.12187191, -0.14923021, -0.05508905, -0.16197409, -0.14862248, -0.08295813, 0.14656667, 0.17256737, 0.00048537925, 0.19091624, 0.16216418, -0.054996677, -0.011477824, 0.40262133, 0.16051191, 0.23488891, 0.21382028, 0.096400574, 0.22312734, -0.21938679, 0.10803822, 0.07793617, -0.17960829, -0.042590663, 0.19258226, 0.19720003, 0.25994664, -0.003564559, -0.19358933, 0.12771177, 0.21518576, -0.050662182, -0.20760211, -0.00461643, 0.4471272, -0.15534559, 0.26843625, -0.034279138, -0.06099213, 0.0089305155, 0.19851643, -0.043476798, -0.28951135, -0.04420476, -0.35708737, 0.1914063, 0.06878817, 0.028667234, -0.28051755, 0.40549898, 0.28498697, 0.311661, 0.042076662, 0.20382655, -0.25554693, -0.16581945, 0.27165103, 0.059493437, 0.1847822, -0.38376784, -0.047349483, 0.16494757, 0.28432783, 0.22928303, 0.0657394, -0.07292324, -0.14355038, 0.10782251, -0.713569, -0.18533194, 0.15313774, 0.2225866, -0.0058042035, -0.26518852, -0.014969388, 0.03993751, 0.17313765, 0.1390597, 0.104358494, 0.29311398, -0.1838886, 0.10516056, 0.12519318, -0.010185317, 0.1051993, -0.12562445, -0.42655724, -0.39979213, -0.088258594, -0.033543315, 0.10459013, -0.15673609, -0.14252509, -0.07633434, -0.15473264, 0.020883862, 0.27884313, -0.038331293, 0.0013342891, -0.1322673]}, "content": "Hey, everyone, thank you so much for checking out the Weaviate podcast. I'm beyond excited for this episode. We have Dmitry Kan, one of the most influential speakers in search technology. Dmitry is the host of the Vector podcast, he's a senior product manager at TomTom, and he's recently given this incredible keynote at the Haystack European Conference 2022. So firstly, Dmitry, thank you so much for joining the Weaviate podcast!", "podNum": 34, "speaker": "Connor"}, {"_additional": {"id": "d8897f89-0ca1-4357-9ded-ceb689c40518", "vector": [-0.18348947, -0.24026036, -0.11555934, -0.31712025, 0.15983884, -0.18784061, 0.09034692, -0.10155128, 0.22169466, 0.014294459, -0.014129443, 0.157743, 0.06934655, 0.0004701346, 0.22044268, -0.18598782, 0.16760507, -0.041510545, -0.27703574, 0.036467444, -0.110202216, -0.19952261, 0.04623951, -0.094465196, -0.12924272, 0.09108758, 0.043876804, -0.080376476, -0.13419732, -0.09522694, 0.10187379, 0.07091614, 0.07077121, -0.06830184, -0.20004015, -0.001948759, -0.081759825, 0.056916226, -0.20134878, -0.06613563, -0.18665819, -0.018606214, -0.08660744, 0.12796125, 0.09157643, -0.15747043, -0.10943983, 0.021811353, 0.06732786, 0.15310268, 0.053395845, 0.05809517, -0.13818891, -0.029016167, -0.047894754, 0.18326178, 0.14050248, 0.20216504, -0.030137697, 0.03252361, 0.02020954, -0.15802988, -0.14128181, 0.328325, 0.2198252, 0.04613483, -0.04190183, -0.15417263, -0.26771393, -0.009537103, -0.24719977, -0.14438605, -0.041357026, 0.04351998, 0.017798122, -0.1544816, 0.05415281, -0.042028468, -0.027919378, -0.09696142, 0.09743272, -0.009280384, 0.05507061, -0.051267117, 0.13748033, 0.03693652, 0.022775497, 0.20146362, 0.014998563, -0.113415435, -0.29183757, 0.0071033076, 0.16285717, -0.040376652, -0.031582404, 0.08753, 0.023264363, -0.23110056, -0.043693848, 0.18715887, -0.16267729, -0.0806389, -0.07966843, -0.11565564, 0.014501748, -0.366001, 0.12631336, 0.050525732, -0.047731422, -0.056504786, -0.144536, 0.10677022, -0.028765898, -0.023453526, 0.077150136, -0.032325625, -0.3031835, 0.11359223, 0.21743993, -0.3101501, 0.19505791, -0.071714774, 0.019877493, -0.001770512, 0.06916018, -0.21830519, 0.2169215, 0.204089, -0.089876816, 0.025715685, 0.06371162, -0.006612861, 0.25250444, 0.08197273, 0.06864014, -0.029678255, -0.05036698, -0.09004618, -0.0013634264, 0.087859154, -0.007956988, 0.41932917, 0.07944795, -0.047779925, -0.17297256, 0.29789528, -0.16612436, 0.059807815, 0.038617454, -0.106513456, 0.032503113, -0.052517127, 0.2356625, 0.086221516, 0.068767294, 0.12973353, 0.16289893, 0.11968901, -0.028027052, -0.083035134, -0.18069692, 0.08822169, 0.06664635, -0.11325921, 0.028202709, -0.081403375, -0.029739987, 0.053198792, -0.03259708, 0.13651504, -0.064713135, -0.0483968, 0.041847087, -0.0023752875, 0.07117051, 0.08210297, -0.1935374, 0.06745644, 0.0071744784, 0.08242903, -0.07239576, -0.020638783, -0.009432768, 0.025130838, -0.094355, 0.05244928, 0.08761783, 0.051363863, -0.16343588, -0.09606245, -0.11846032, 0.023044515, -0.018109048, 0.19572684, -0.011342573, -0.08581756, 0.12873009, 0.09040795, -0.1437613, 0.029057737, -0.18627793, -0.009127912, 0.023286555, -0.16900176, 0.044432543, 0.029443383, 0.090024725, 0.087252095, -0.096742496, 0.16603273, 0.0073795905, -0.24856015, -0.108931795, 0.234832, 0.23824851, -0.07911178, -0.22429433, 0.060373873, -0.11607007, 0.054662663, -0.04326468, -0.14417143, 0.12205895, -0.406305, -0.18964078, -0.1346288, -0.0852523, 0.0442526, -0.028101895, 0.036905285, 0.23579124, 0.08522779, 0.01958521, 0.10145229, -0.05708114, 0.05408243, -0.007926893, -0.0070998175, 0.028058028, 0.1003078, 0.040809453, -0.15254864, -0.10539863, -0.005468675, -0.026416397, 0.2785936, -0.04534418, 0.06394476, 0.03801573, 0.17600009, -0.11538865, 0.07635772, -0.0073631466, 0.0949431, -0.13296679, -0.11026581, -0.29938018, 0.13957885, -0.01817095, 0.2578742, 0.32013556, -0.1833447, -0.08950842, -0.018524077, 0.052307963, -0.06803845, -0.22364512, 0.25290185, -0.1462101, -0.043090835, -0.2607278, 0.09499748, 0.008614317, 0.0003912583, -0.024392758, 0.08477228, 0.2830097, -0.31816927, -0.20292309, 0.13033222, 0.11830874, -0.18192062, 0.2047054, 0.08756216, 0.20379929, -0.26949808, 0.010862027, -0.14598809, 0.03694685, -0.06329373, 0.008228344, 0.12929843, -0.15385026, 0.07660335, -0.010433624, -0.071005, 0.048518207, 0.024030691, 0.15067458, 0.103211544, 0.04712931, 0.017979544, -0.1034328, -0.11357401, 0.16593167, -0.19470239, 0.10606305, 0.10900696, 0.2055798, 0.022911247, -0.03446259, 0.11721732, -0.07552935, -0.00878752, -0.078197345, 0.081476025, -0.21760292, 0.18566015, 0.017191857, -0.0258754, 0.0009824217, -0.20545562, 0.18580626, 0.03358894, -0.13060412, 0.1455985, -0.17542168, 0.0020349983, -0.060840715, -0.16630508, 0.03464318, -0.13452728, 0.016958926, 0.1738762, 0.21075162, 0.29818246, 0.027490467, -0.034516387, -0.12887421, 0.018112015, 0.10934142, 0.08871975, 0.0210117, -0.015016904, 0.08163278, 0.17259033, 0.097554244, 0.29535675, 0.06383123, -0.07522873, -0.11438211, 0.07279301, -0.11738386, 0.010652584, 0.15616594, 0.0313401, -0.0711769, -0.13851896, 0.24960133, -0.3040963, 0.13633671, -0.0873358, -0.1332748, 0.3876678, -0.015362251, 0.24785443, 0.014469999, -0.24727616, -0.12359893, 0.10889363, -0.09078945, 0.10473838, 0.12828015, 0.13543636, 0.2059091, 0.068069056, 0.17603803, -0.14300895, -0.08800248, 0.40801316, 0.14385498, 0.22084317, 0.23759043, -0.19864583]}, "content": "Yeah. I think, I think we don't even realize how smart we can be also. And kind of on this user interface is one thing I kind of want to bring up this multimodal idea. And I saw this one demo from Anthropic or Adept. I always mix up the companies and I'm sorry, but what it is, is it's like recording your screen. So you say to GPT, like, I'm trying to import 1 million data objects to Weaviate and then it'll watch my screen. It'll watch me like get go in my terminal, download the document, it'll watch me interacting with the web. And then it would like suggest things on the side. So it's, it's kind of like a different interface compared to where you talk about the data visualization and you imagine like, okay, I got this matplotlib error. So now I need to copy and paste everything, give it to the chat window compared to something that's like always watching you doing your task. ", "podNum": 30, "speaker": "Connor Shorten"}, {"_additional": {"id": "d9903398-ef29-4a70-ae74-e9b58cbe87c7", "vector": [-0.033964764, 0.02240622, 0.27989456, -0.11000572, -0.10095998, -0.17281505, 0.15316364, 0.07909065, -0.010836535, 0.01551895, -0.073577054, -0.04409495, 0.004366483, -0.019140342, -0.0120409895, 0.043467604, 0.17114218, -0.07883335, -0.2713293, -0.30423164, -0.46656558, -0.002752608, 0.18703043, 0.06794955, -0.13419653, 0.07129231, -0.07668667, 0.115315504, -0.21554293, -0.06995682, -0.07327641, -0.040679518, 0.14457658, -0.11032709, -0.22572483, 0.33276775, 0.0069647604, 0.0006740051, -0.2059331, -0.08704918, 0.015983494, -0.27409998, 0.17498423, 0.14150377, 0.14760397, -0.13023399, 0.0039142286, -0.031860344, 0.20545901, 0.30822662, 0.13335298, 0.03302979, 0.112933636, 0.057403486, -0.026662173, 0.26237768, 0.03841698, 0.0836637, -0.019362396, -0.018444022, 0.1536597, -0.21238944, -0.24018423, 0.51942587, 0.06505291, -0.21816386, -0.12436444, -0.114834145, -0.24041335, 0.3763275, -0.099232115, 0.042972576, 0.06502627, 0.081708305, 0.12201186, -0.006541594, 0.15955317, -0.24681433, -0.15387376, -0.11380463, 0.15101872, -0.074938245, 0.121620856, -0.20534226, 0.10576109, -0.017161751, 0.019161602, 0.018285826, 0.07349463, -0.12118636, -0.22053374, 0.40746322, 0.030530421, -0.16081072, -0.091277964, -0.02060147, -0.0049166465, -0.12072102, -0.18995054, 0.18923739, 0.00053318695, -0.038867466, 0.19894052, -0.22814715, -0.10897603, -0.18395042, 0.017615382, 0.19903922, 0.012872951, -0.08955334, 0.0002023599, -0.06003782, -0.009469976, -0.053492423, 0.15460484, 0.16931316, -0.18006507, 0.07362052, 0.44379902, -0.14979683, 0.019023323, -0.010247164, 0.015474623, -0.055678897, -0.3893587, -0.33802727, 0.2290699, 0.24197581, 0.1321864, 0.0032761693, 0.090549596, 0.15486945, 0.10393535, 0.26852697, -0.27071372, -0.1783334, -0.13086146, -0.06970829, 0.20146103, 0.18824889, 0.13781145, 0.22260658, 0.061403457, -0.18598711, 0.026253525, 0.16527116, -0.043894235, -0.02689133, 0.11866418, -0.18382609, -0.15481628, 0.21707785, 0.4174025, -0.08445137, 0.3228777, 0.14818358, 0.3394157, 0.03252786, 0.064455844, -0.12992509, -0.1437285, -0.11154349, 0.058506615, -0.21494868, -0.036880814, -0.19905937, 0.040965308, 0.1209198, -0.14797418, 0.14752392, -0.035117563, -0.025127366, 0.0067526144, 0.031077148, 0.0097663505, 0.07470845, 0.15765832, -0.036695473, 0.038246606, 0.21802528, -0.10861002, -0.047183298, -0.14411327, 0.14053626, -0.06022736, 0.019900518, -0.11370116, -0.055151638, 0.01908133, -0.2508991, -0.07510464, -0.2654245, -0.21270911, 0.1925666, 0.23391132, 0.15040398, 0.24104193, -0.07444741, -0.19127198, 0.027907733, -0.23295586, -0.24599591, 0.31276116, -0.1993094, 0.20017345, -0.12878893, 0.2997249, 0.12243414, 0.12605432, 0.17177984, -0.1825465, -0.15178402, 0.21847017, 0.13053393, 0.03605886, -0.09679099, -0.23647968, 0.2542116, -0.01823582, -0.0070997262, 0.086432576, -0.06241147, -0.17814542, -0.46293756, -0.11922507, -0.11619066, -0.03826769, 0.026491368, 0.20234115, 0.03843852, 0.14859888, -0.018655922, 0.01625979, 0.024546565, 0.19284774, -0.028590424, 0.009857314, -0.24343988, 0.011884476, 0.06552052, -0.12166668, 0.113810815, 0.02302499, 0.0065810033, 0.16368425, 0.4427189, -0.08430086, 0.13579158, -0.23214106, 0.2797438, -0.31295133, -0.08345331, -0.24620713, 0.09340356, -0.07122035, 0.17393772, -0.6674868, -0.07010036, 0.0205735, 0.17299046, 0.1626865, -0.28776616, -0.04399208, -0.12142998, -0.0052693463, -0.16202052, -0.033318628, 0.39506474, -0.17622693, -0.00042638075, -0.3929258, 0.037059117, -0.010049386, -0.040893395, -0.1937022, 0.019899094, -0.12193183, -0.18626611, -0.10649129, 0.19051565, 0.047291916, 0.031544622, 0.16247885, 0.13252048, -0.20433639, -0.1148508, 0.24777253, 0.1272666, 0.23526028, 0.020375475, 0.19535473, 0.16538323, -0.1746606, 0.024848476, -0.25740647, -0.0015075147, -0.1887233, 0.42471394, -0.021037962, -0.19509867, 0.08329568, -0.19823585, -0.10796976, -0.055031564, 0.014032415, -0.15743232, -0.027647365, 0.2538056, -0.046671152, -0.13016877, 0.075567506, 0.13862218, 0.0048165536, 0.28390527, 0.15068544, -0.02818756, -0.23229972, 0.14413759, 0.050622147, -0.18184994, -0.019447299, -0.0329676, -0.14930728, -0.0012707412, -0.0015084743, 0.21079612, 0.16201393, -0.0795022, -0.091294125, -0.1099689, 0.15888058, -0.0036616412, -0.09779497, 0.08924339, 0.3662293, 0.1961021, -0.0010917634, -0.023705129, -0.12108276, 0.0021575263, 0.09725808, 0.15087089, -0.057072155, 0.0666901, -0.024319012, 0.05834139, 0.18600819, 0.31157824, -0.03764189, -0.15319191, 0.054454498, 0.12414128, -0.24294381, -0.03375662, -0.030114213, -0.05701271, 0.055537842, -0.3414218, 0.19145243, -0.3388157, 0.27696112, 0.06374032, -0.016413454, 0.35054827, -0.29756784, 0.14812168, -0.080399856, 0.11543578, -0.29860058, 0.185445, -0.1441482, 0.025873011, 0.11858595, 0.0884578, 0.030162552, -0.1417848, 0.0027549628, -0.03332129, 0.045794655, 0.15027717, 0.29145747, -0.047693737, 0.12536478, -0.18153083]}, "content": "No, thank you guys for having me. And yeah, just, I don't know if people listening to this realize, but like Weaviate and you in particular, Connor reached out super early on in the LangChain journey. Like, I don't, like it was, it was, yeah, like I, yeah, that was a while ago and it's been awesome to kind of like work with you guys and kind of like, I think we both see the world in like similar ways and there's a lot, like I think vector stores are like for a lot of applications are like a critical enabling piece. And so it's been awesome to work with you guys and chat about stuff. And so, yeah, thanks for it. Thanks for having me on. Always, always happy to do it. ", "podNum": 36, "speaker": "Harrison Chase"}, {"_additional": {"id": "d9cc8be5-02ac-4189-ab26-82c6029a83a2", "vector": [0.35063374, 0.08519714, 0.48235524, 0.022217713, -0.38346273, -0.3557475, 0.33124766, -0.12171393, 0.08974177, 0.3040973, -0.0972902, -0.5032426, 0.1548156, 0.15389311, 0.36729878, -0.063879095, 0.24443763, -0.3577151, -0.4301313, -0.23642161, -0.5690923, -0.00282453, 0.04783278, -0.11800767, 0.02665701, -0.21538946, -0.023801278, 0.256662, 0.0849204, -0.3447744, -0.124022976, -0.29995215, 0.017506968, -0.05952533, 0.12690784, 0.44191515, 0.17578804, -0.1672438, -0.08089474, 0.13660347, -0.13265158, -0.35082603, -0.15083715, 0.048425928, 0.06166806, -0.15190905, 0.16790369, -0.0006526485, 0.5328058, 0.2929561, 0.12269896, 0.09458283, -0.08780667, 0.14190169, -0.10005936, 0.24714728, -0.043850504, -0.14740108, -0.23687664, 0.093133576, 0.3225516, -0.09957628, -0.46842402, 0.6878164, 0.0009853467, -0.14195204, -0.23858228, -0.06666717, -0.7898683, 0.28135082, -0.14480382, 0.10257402, 0.22453621, 0.06682358, 0.09026748, -0.37830406, 0.26724762, -0.10482858, -0.16315702, 0.035830542, 0.19275789, 0.11109327, -0.122235715, -0.15151817, -0.12240662, -0.5174765, -0.15826203, 0.37101713, -0.15085587, -0.13415608, -0.4467874, 0.4614987, -0.07477026, -0.18872727, 0.036052626, -0.22036625, 0.12898667, -0.14667365, -0.36418614, 0.6781696, -0.08340541, 0.2024215, -0.14682505, -0.45598704, -0.020210497, 0.13592413, -0.23611794, 0.022705302, 0.08762196, -0.14664185, -0.26566517, -0.3313254, -0.11022262, 0.16829714, 0.20542327, 0.3872177, -0.3061429, 0.27041438, 0.31247962, -0.56894433, -0.08568287, 0.18611975, 0.0006111264, -0.24869253, -0.3687365, -0.9534198, 0.7288353, 0.2575962, -0.13439, 0.3724173, -0.0048973784, 0.12693802, 0.3712618, 0.47772792, -0.45598555, -0.17846803, -0.21333635, -0.300794, 0.14315414, -0.7021271, -0.11001943, -0.29977092, 0.23289669, -0.072635904, 0.086146615, 0.06741657, -0.1876195, 0.20144498, -0.029192023, 0.038597174, -0.15262018, 0.2877141, 0.2009846, -0.0856504, 0.3811156, 0.04843, 0.6868851, -0.053579833, -0.07742405, 0.004593078, -0.12743817, 0.022159576, 0.042511906, 0.06839831, -0.3491544, -0.14607099, 0.02700667, 0.27798578, -0.2575198, 0.25860962, -0.13314119, 0.24248597, 0.28169343, 0.321952, 0.18590015, -0.26771292, 0.19076145, 0.24855644, -0.2204179, 0.07665798, -0.009548277, -0.10051499, 0.042283013, 0.15607081, -0.22758023, 0.1286912, -0.2601647, -0.32092804, -0.014621116, -0.52448285, -0.15084028, -0.3278156, -0.49867064, 0.20269075, 0.0057843532, 0.089092195, 0.49894643, 0.058920473, -0.06087564, -0.097598545, -0.55411834, -0.5231109, 0.42164797, -0.31365833, 0.2590132, -0.24963465, 0.94200575, 0.14163403, 0.26859137, 0.24805257, -0.27221036, -0.09837347, 0.23224027, 0.24879414, 0.23217152, -0.20262758, -0.07894221, 0.71216106, -0.37208652, 0.12983568, 0.24435425, -0.06639848, -0.3807106, -0.69550896, 0.20272276, -0.096507594, -0.2263358, 0.32199717, 0.21273363, 0.055896, 0.19471192, -0.025914775, -0.5652975, 0.25440723, 0.06941235, 0.0027886182, 0.122747645, -0.025916029, -0.5214443, 0.06896804, 0.11300513, 0.28348136, -0.2391346, 0.19300227, 0.10969947, 0.64085716, -0.062255796, 0.672987, -0.470406, 0.7733245, 0.0351317, -0.20512652, -0.23343359, 0.04601553, -0.49335822, -0.023223393, -0.37741363, -0.15158927, -0.014662323, 0.5237174, 0.50669646, -0.39318618, -0.45057347, -0.08868461, 0.121121615, -0.3717155, -0.12777627, 0.8665017, -0.28244466, -0.046322204, -0.12697735, -0.010075107, 0.1182779, 0.034598842, -0.6905328, -0.20953101, -0.14434174, -0.14729127, 0.1623264, 0.08779695, -0.39130783, -0.16021623, 0.08245079, 0.017022975, -0.35035267, -0.050826877, 0.5043498, 0.21371916, 0.09501798, 0.12263484, 0.057032064, 0.46555546, -0.2804287, 0.0070520286, -0.3100473, -0.2843572, 0.1324412, 0.21877393, 0.41132224, 0.15736453, 0.0835087, -0.04321122, -0.1089874, -0.3409954, 0.049491398, -0.031347945, -0.27941433, 0.37751073, 0.2789266, -0.32059008, 0.36098215, -0.17514797, -0.08751643, 0.15994142, 0.21879445, 0.0040276498, -0.23418567, -0.18131271, 0.23024938, -0.32388043, -0.08309712, -0.052263316, -0.09032793, -0.033618614, 0.058157433, 0.3560032, 0.34629345, -0.32410362, -0.14442292, -0.05877965, 0.07311573, -0.06819686, 0.11065034, 0.038727466, 0.36379886, 0.42888784, -0.017038886, 0.06755734, -0.1609696, -0.027897589, -0.0578031, 0.3416912, 0.13378842, 0.601958, 0.31627858, -0.09686964, -0.081730716, 0.09026398, -0.08339826, 0.12615988, 0.003678888, 0.29402196, -0.3259506, -0.04787921, 0.39056757, -0.40286332, 0.10850713, -0.3410645, 0.29181212, -0.6381316, 0.2923509, 0.51975536, 0.077930436, 0.30018562, -0.19910458, 0.15854454, 0.45487458, 0.2482335, -0.348427, 0.13942717, -0.15551223, 0.008361742, 0.40546608, 0.09172566, 0.2330774, -0.085064, 0.12030291, 0.21342424, -0.32630083, 0.2936505, 0.6492865, -0.20534316, 0.35575056, -0.11394632]}, "content": "Yes. Pleasure to be here.", "podNum": 33, "speaker": "Nils Reimers"}, {"_additional": {"id": "d9d95a64-b9a1-441a-9dfd-d2b60aeccb81", "vector": [0.215671, -0.20382957, 0.38997, -0.17155474, -0.2606883, -0.04516095, 0.063519634, -0.47392315, 0.30901518, 0.1262058, 0.0055714254, 0.3281755, 0.15434468, -0.104995176, 0.55085075, 0.23585209, -0.08315772, 0.27510446, -0.66004133, -0.20953037, -0.4377551, -0.1202396, -0.35688555, 0.1302118, 0.0064508263, 0.19716088, -0.14898491, 0.08138656, -0.1873976, -0.22404292, 0.268005, 0.4997822, -0.10883787, -0.0022021122, -0.07623201, 0.09520357, -0.19692272, 0.46141043, 0.008685589, 0.11199485, -0.030176118, 0.03205131, -0.23415285, 0.03850031, 0.16406341, -0.2495454, -0.25607568, 0.14502919, 0.013489366, 0.16124265, -0.32534263, 0.05410836, -0.40298262, 0.34653354, -0.16934097, 0.60075176, 0.0022500306, 0.122590244, 0.11275378, 0.130851, -0.054224845, 0.05142325, -0.23709285, 0.8165542, -0.16602163, -0.18261583, -0.13804308, 0.12548862, -0.2711962, 0.5289325, 0.04601392, -0.19723842, -0.11608122, -0.060764045, -0.09636087, 0.24386528, 0.022114508, 0.11202645, 0.23352149, -0.14582074, -0.074361116, -0.028702103, 0.11924019, -0.22299239, -0.026989814, 0.2853747, -0.17821619, 0.015130326, 0.005724876, -0.3203712, -0.14802456, -0.21040913, 0.6853903, 0.09663473, -0.21970375, -0.20626166, 0.048624188, -0.64787745, 0.21470743, 0.033018246, -0.4663238, 0.048499014, -0.117863454, -0.5933256, -0.24657992, -0.459607, 0.17566627, 0.036191005, -0.041447535, -0.06214332, -0.07645911, -0.07614052, -0.0742438, -0.3935988, -0.1549115, 0.37565827, -0.20762718, 0.029118644, 0.1485532, -0.032509755, 0.34452543, 0.050523706, -0.16553295, 0.15387903, 0.10201049, -0.15202194, 0.18371898, -0.015988914, -0.045771215, 0.17395087, -0.0694783, 0.24712476, 0.3964889, 0.1629674, -0.16171853, -0.17662925, 0.0050625578, 0.0072517097, 0.31491584, 0.16506891, 0.24224123, 0.11692755, 0.014501033, -0.1750575, 0.049616568, 0.29660875, -0.2574342, -0.14095652, 0.10246487, -0.15749831, -0.4728441, 0.23940432, 0.270246, -0.26158392, 0.20953153, -0.07345456, 0.28439736, -0.106916815, -0.1457764, 0.07397762, -0.4415444, 0.19854033, -0.011821772, -0.038739346, -0.07291858, -0.007822514, 0.3482498, 0.13023226, 0.045026973, -0.18381716, -0.17037515, -0.15293403, 0.0021816464, 0.15404917, -0.032651626, 0.27167428, 0.0039346027, -0.14382704, 0.23728243, 0.05311375, -0.089249566, 0.21477291, 0.14661412, -0.03009975, 0.08293016, -0.047778264, -0.21255296, 0.079653546, 0.21488196, -0.026373522, -0.09630154, -0.20671558, -0.14885989, 0.15696819, -0.1381269, 0.109865226, 0.19783556, -0.06589669, -0.26943666, -0.23145407, -0.22271264, -0.19897917, -0.15307274, -0.327457, 0.0017461926, 0.09826417, 0.20821999, -0.1369574, -0.30727047, 0.17771691, -0.07598241, -0.11601611, 0.13694614, 0.15729997, 0.14999339, -0.08239774, 0.080644555, -0.16471802, -0.4710336, -0.2428516, 0.35967913, -0.19314858, 0.17754337, -0.34656683, -0.24453636, -0.04917941, -0.042054676, 0.109443456, -0.18367103, -0.13438872, 0.2242508, -0.12557417, -0.09681487, 0.112688676, -0.13348015, -0.17033885, 0.4263519, -0.019169599, -0.1412222, 0.42718497, -0.05751823, 0.2824641, -0.07079618, 0.21836326, -0.29485074, -0.055954017, -0.3730651, 0.27880773, 0.27744323, -0.16011879, 0.17193973, -0.07373082, -0.05519542, 0.2246605, -0.281564, -0.26427683, -0.3169683, -0.1748886, -0.07719904, 0.19049904, 0.29853737, -0.2566781, -0.082337394, -0.0042160945, 0.12048381, -0.3079883, 0.21112083, 0.5877195, -0.1757267, -0.025448151, -0.37242272, 0.32880682, -0.25902903, 0.20433989, -0.1392724, -0.16577908, -0.12255569, -0.31399703, -0.04703577, 0.3716455, -0.02389817, -0.17665601, -0.06865832, 0.09225017, -0.1581405, -0.2545905, 0.22599816, 0.07751897, 0.23870164, -0.10995078, -0.06637334, 0.29659748, -0.44299245, 0.11191893, -0.29187068, 0.14722313, 0.1256735, -0.027151385, 0.1645473, -0.086580716, 0.15357557, -0.31532887, -0.23113196, -0.3124994, -0.07877648, 0.02202464, 0.01671166, 0.25080723, -0.0005032681, 0.05902736, 0.36566898, 0.105268836, 0.013515256, -0.21321814, -0.37699416, -0.0551003, 0.40296102, 0.10161008, -0.069320805, 0.19002882, -0.13452597, 0.019275114, 0.3531704, 0.03580679, 0.03838712, 0.42593193, 0.20494647, 0.23784919, 0.05230187, -0.095234364, -0.046791036, 0.04492593, 0.2801574, 0.19564505, 0.040128544, -0.093280435, -0.006750798, 0.046660557, -0.09571914, 0.043140028, 0.012407728, 0.027040698, -0.02741555, 0.53313994, 0.026327848, 0.025608927, 0.17367363, 0.24689037, -0.2816425, 0.17432469, -0.20162244, 0.23749234, -0.09923893, 0.28187814, 0.32056206, -0.115483455, 0.18005878, 0.15223476, 0.1930449, -0.15858933, 0.028794229, -0.003518974, -0.107917294, 0.21917269, -0.2222853, -0.019126363, -0.054004617, -0.41896862, 0.035155535, 0.15109947, 0.08208518, 0.08026453, 0.25698864, -0.027507022, 0.2768079, -0.24488142, 0.09300788, 0.035217796, -0.077812724, 0.2645343, 0.0051172674, 0.12442762, 0.026756197, -0.23569283]}, "content": "Could we step one... So the way the topics are merged, do you mind... Sorry, I'm not... The way that it's merged, just one more time. How do you... Yeah, yeah, yeah. ", "podNum": 28, "speaker": "Connor Shorten"}, {"_additional": {"id": "da5b6d74-6c1d-4931-8e98-c91c875c0d2f", "vector": [-0.3777154, 0.051952105, -0.20493658, 0.06874503, 0.14005601, -0.04357011, 0.13088955, 0.11655815, 0.059949722, 0.008456323, -0.0010084109, 0.17484118, 0.15025273, -0.0069665024, 0.2008716, 0.03947283, 0.14279118, 0.0003168173, -0.11698829, -0.024841197, 0.0129429735, -0.011439034, 0.121369496, -0.0070056245, -0.10618937, -0.076361045, 0.13075799, 0.017923122, -0.07991141, -0.05856719, 0.06506731, 0.13549565, 0.01839669, -0.10655872, -0.04146989, -0.0035258583, -0.07324267, 0.03291166, 0.06310648, 0.17896669, -0.12009963, -0.22359815, 0.0034519325, 0.10195718, -0.18738505, 0.057238724, 0.044450685, -0.03486742, -0.10259058, -0.02979444, -0.039682686, -0.07734394, -0.031448614, -0.061244994, -0.082819164, 0.022981878, 0.15645233, -0.3009715, 0.032807313, -0.21900067, 0.28064013, -0.081315145, -0.06689205, 0.17877299, 0.18446682, 0.0103635695, -0.036886074, 0.18864635, 0.039021805, 0.18314315, 0.12973559, 0.100778386, -0.05463684, 0.123477586, -0.22373654, -0.03252062, 0.012691496, 0.11108469, -0.026673784, 0.09776907, 0.015887516, -0.25156188, -0.16766006, -0.067761526, 0.03550286, 0.036754422, 0.07818128, 0.220783, 0.08802377, 0.0791267, 0.0030451529, 0.15469675, 0.22176819, 0.048805982, 0.029917851, 0.3228018, 0.13928063, -0.22401474, -0.22349426, -0.008070352, -0.027809985, 0.12714179, -0.04668451, -0.30183232, 0.10545396, -0.14610128, -0.08940303, 0.023611749, 0.24702692, -0.2539754, -0.07374225, -0.13575411, 0.0017107613, -0.004833432, -0.2327132, 0.06986305, 0.07074119, 0.05406519, 0.14493379, -0.3429942, 0.102305256, -0.10417851, 0.07650653, 0.17836377, 0.08962013, -0.18453604, -0.22689018, 0.20218833, 0.15029876, 0.06876888, 0.12861076, -0.13879912, 0.047621526, -0.032807548, -0.10590745, -0.20026068, 0.0108685065, 0.005075321, -0.1303285, 0.15672916, 0.04631061, 0.2221828, 0.06908989, 0.031065395, -0.35903478, 0.23678392, -0.04482, 0.07227552, 0.08088737, -0.2855219, 0.060920782, 0.032737054, 0.14116594, 0.03918107, 0.121034615, -0.08867654, 0.028666284, 0.10039441, 0.20241858, 0.050701566, -0.056599207, 0.23189783, -0.0433404, 0.060161304, -0.03964065, -0.082674675, 0.029421676, -0.061739206, 0.15832622, -0.010623436, 0.053435378, 0.00059307134, 0.21932615, 0.06713069, -0.219263, -0.06741896, -0.35138878, -0.0062947106, -0.03508626, 0.29652482, -0.050232455, 0.019312957, 0.10710587, 0.22692409, -0.058487162, 0.14286137, 0.07114289, -0.057934996, -0.067778334, 0.056596115, 0.07452672, -0.008353453, -0.15888323, 0.12670662, -0.18426728, -0.17475094, 0.2382503, 0.0136851575, -0.12807746, 0.012421408, -0.027995374, -0.1643537, -0.005118355, -0.07118376, -0.04357346, -0.08335567, 0.18186657, -0.0085109295, -0.28287885, -0.09186302, 0.06058825, -0.0063904235, -0.24372879, 0.13537018, 0.009985068, -0.059422344, -0.11633036, -0.012493061, 0.010148115, 0.054991852, 0.051728345, -0.09236957, 0.16621752, -0.3773901, -0.111739025, -0.28524792, 0.03661707, 0.024374157, 0.08359306, 0.09985456, -0.017140226, -0.3307172, 0.15039802, 0.09555042, -0.03471305, 0.017693376, 0.001658739, -0.09448079, 0.24307951, 0.07646355, -0.03453069, -0.12318855, -0.08198317, 0.14858723, -0.005553266, -0.043365173, -0.075192064, 0.31194967, -0.014779773, 0.10215506, -0.15936679, -0.43726543, 0.17072736, 0.095341355, -0.3651032, 0.0096461605, -0.23314938, 0.1527079, -0.28197306, 0.08685651, 0.282904, -0.39111143, -0.02599464, -0.027021656, 0.07924815, 0.08276701, -0.10195498, -0.03490961, -0.15031601, -0.1090573, -0.08321105, 0.111035444, 0.018535178, -0.12113903, 0.36225143, 0.028182477, 0.067173034, -0.2588459, -0.0593203, -0.20014663, 0.1409179, -0.16639256, 0.09218431, 0.15264085, 0.16941138, 0.042917464, 0.093268454, 0.08182396, -0.11873779, -0.14155993, -0.10462078, 0.09010889, -0.047129866, -0.042953197, 0.2539076, 0.05903045, -0.12136532, 0.13006157, 0.17844759, 0.1711171, 0.0782138, -0.12920393, -0.25249815, -0.066659905, -0.11659667, 0.17386153, 0.14345798, 0.14364426, 0.07227258, -0.12275018, -0.1272117, -0.04714577, -0.026752, 0.079722054, -0.17962416, 0.015146711, -0.23196945, 0.22061776, 0.072353415, -0.08212335, 0.0078012464, -0.12757567, 0.09148259, 0.094981946, -0.19164266, 0.050968368, -0.012193499, -0.11083974, 0.07827443, -0.21225254, 0.1010102, -0.06774778, 0.024479723, 0.18930274, 0.0102073, 0.19704573, -0.042767543, -0.022618225, -0.109957464, 0.26760283, 0.024662884, 0.2576857, 0.020404229, 0.063139245, 0.071324974, 0.1723783, 0.12105339, 0.15026961, -0.07798344, 0.026626755, -0.21568632, 0.21755242, 0.023505587, 0.030599639, 0.36910078, 0.079425074, -0.033440072, -0.16873969, -0.15624493, -0.3045601, -0.115890875, -0.007491109, -0.20322287, 0.14306472, -0.05209592, 0.00922304, -0.047646984, -0.2229032, 0.03262543, 0.1379178, -0.012534967, -0.2239749, 0.095431924, -0.21184088, 0.11464604, 0.19201344, 0.12607381, -0.11916929, -0.1668821, -0.012572809, 0.3381226, 0.1573814, 0.20883153, 0.24634548]}, "content": "Yeah, so in the BEIR benchmark we have one data set, which is really interesting. It's called ArguAna. When you want to find counter-arguments, so you have an argument, say, nuclear energy is super safe, and then you want to have retrieval to find counter-arguments to say, okay no, nuclear energy is not safe. Obviously, out of the box models, if I search for, nuclear energy is safe, it finds like different arguments that also mentioned nuclear energy is one of the safest energy sources, so there are the questions like, how can I tell the model of my intent that I don't want to have arguments that are similar, but arguments that are opposing? And the paper you mentioned, use this in terms of kind of like instruct style. Say, okay, find a counter argument, nuclear energy is safe, or find a similar argument, or find evidence. I think it's a nice idea, especially if people want to build this into their product. So if you have like a search engine and you wanna find some arguments with supporting and opposing evidences and different perspective, so I think it's an easy way for machine learning engineers and search engine engineers just to prepare the prefix and say, okay, now I wanna search for opposing documents or, supporting evidence or opposing evidence for this.", "podNum": 33, "speaker": "Nils Reimers"}, {"_additional": {"id": "db290152-fd75-4ce8-920d-2c8ff30e835d", "vector": [-0.0026192565, -0.25883916, -0.15438062, -0.40530887, -0.37830427, -0.26357087, 0.60112363, -0.034419004, 0.13473223, -0.075805955, -0.09289529, 0.28275946, 0.08483249, 0.043700006, 0.28872362, -0.09451235, -0.112412214, 0.1876841, -0.58042294, 0.28097704, -0.3781902, -0.27654085, 0.07293729, -0.052826554, -0.18539602, 0.16337246, 0.20278789, 0.24806398, -0.30702126, 0.16054623, 0.06433933, 0.14746226, -0.07972297, -0.14775075, -0.3024304, 0.2551223, -0.26678076, 0.077037685, -0.16629304, 0.1990648, -0.029258737, -0.15361445, 0.04207178, 0.20578992, 0.042375416, -0.02988409, -0.1873238, 0.0015307566, 0.05924219, 0.16992092, -0.17686714, -0.24808995, -0.18923672, -0.26616523, -0.004406795, 0.27243972, 0.46861354, -0.019294918, 0.14130916, -0.115384795, 0.058864046, -0.15008245, 0.18155271, 0.33937252, 0.0751174, 0.022508308, -0.23974903, -0.2911164, -0.14504038, 0.09389333, -0.05627912, 0.13124959, -0.14066492, 0.017045164, 0.070956804, -0.2623651, 0.14429808, -0.046922136, -0.032924637, -0.2313145, 0.012933501, -0.4212165, 0.016583353, 0.32970238, -0.090332426, 0.07072388, 0.019483248, 0.17718077, 0.28952196, -0.0050840676, -0.438809, 0.04802096, -0.040305045, -0.4864789, 0.090861626, 0.5097983, -0.14230737, -0.20267816, -0.08189776, 0.030573474, -0.30322245, 0.15789919, -0.14368917, -0.36808142, 0.39354953, -0.3368453, -0.14488545, 0.02099675, 0.2813162, -0.27104, -0.01273936, -0.096206695, 0.4842721, 0.031374175, -0.08095679, -0.0004875064, -0.0034295123, 0.07238556, 0.2760571, -0.13676818, 0.13243337, -0.03370504, 0.15225567, 0.09148864, -0.1791303, -0.2762966, 0.27333584, 0.2193247, -0.12536237, 0.069709636, 0.41191304, -0.13884091, -0.026073286, 0.12876396, -0.3075172, -0.15186782, 0.05062552, 0.112504125, -0.5170323, -0.109217525, 0.028137974, 0.35277626, 0.06439952, -0.14551768, -0.35808644, 0.30519775, -0.2734243, 0.15288031, 0.1774981, -0.1671678, -0.0080388235, 0.07971197, 0.16180478, -0.1672831, 0.07355303, 0.09450937, 0.055687565, 0.22774507, -0.31188682, 0.01244129, -0.3668228, 0.094315864, -0.11017271, -0.17009939, 0.559889, 0.05287671, -0.14857878, 0.02239593, 0.014417808, 0.048194576, -0.097824, 0.05243404, -0.3596245, 0.010290757, 0.1348134, 0.08443955, -0.1569575, -0.05495503, 0.021120558, 0.2708085, 0.20484418, -0.13595267, 0.17462496, -0.038448036, -0.13419916, 0.10392792, 0.013933827, 0.1267733, -0.06503566, -0.10552081, 0.091414176, 0.085067354, -0.23858051, 0.123091854, -0.06705248, -0.16076167, 0.29960644, 0.25662294, 0.2862576, 0.0821934, -0.5313026, -0.44678402, -0.19624776, -0.3826829, 0.04318775, -0.02678299, 0.3141589, -0.33608428, 0.3872632, 0.12249899, 0.14872271, -0.110417716, -0.09929056, 0.10886091, 0.15113826, -0.20790827, -0.32278296, 0.082689986, -0.16173352, 0.10648615, -0.17864323, -0.18244714, -0.27058664, -0.47470093, -0.5021194, -0.30755255, -0.069860324, 0.05902468, -0.0060181567, 0.023762846, 0.06541765, -0.14001496, 0.002703319, -0.05603528, 0.018788107, -0.041734945, 0.091182105, -0.051206023, 0.24697554, -0.23480232, 0.09246654, 0.026266025, -0.057717074, -0.16433229, 0.040301394, -0.09618314, -0.19109838, 0.35681772, 0.07900653, 0.045378197, 0.17358099, -0.23342466, 0.014780887, -0.054322172, -0.31115356, -0.22640097, -0.10392328, 0.1842364, 0.06512775, 0.06981865, 0.25277412, -0.2218588, -0.22942293, -0.19315846, 0.31535825, -0.13740134, -0.23919536, 0.33327731, -0.275148, 0.14406253, -0.062518105, 0.40697727, 0.09766773, 0.07642684, -0.08212873, 0.094977, 0.11316541, -0.15839256, -0.57146806, 0.105172254, 0.27000892, -0.2045898, 0.097217895, 0.3342608, 0.020483673, -0.42683378, 0.31180915, 0.12306276, 0.03452472, -0.28171185, -0.21992362, -0.008398503, -0.20233178, 0.115654536, 0.2762145, -0.0052790963, 0.021628452, 0.20043944, 0.3249732, 0.15186791, -0.00046191612, -0.101027735, -0.15118112, -0.20272392, -0.24153574, -0.065658726, 0.20154817, 0.57339126, 0.031999063, -0.016728362, -0.14005049, -0.06395001, -0.12567304, 0.3830181, 0.051153675, 0.29089823, -0.29755083, 0.26266062, -0.32698578, 0.06347887, -0.13069987, -0.2411084, 0.24743114, 0.31252775, -0.09723172, 0.047932696, 0.20639645, -0.14360598, -0.11455706, 0.020684449, -0.0027234454, 0.06470899, 0.1353994, 0.19811495, 0.21978532, 0.3449746, 0.19025816, 0.07343846, -0.096417956, 0.2747802, 0.13694842, 0.25829318, 0.12730525, 0.10006052, 0.13786125, 0.09050903, 0.05540316, 0.705139, 0.16276179, 0.08167911, -0.0009315436, 0.4014975, -0.106750764, 0.2200522, 0.23761861, 0.24260183, 0.048545297, 0.15394725, 0.17210816, -0.5330642, -0.09706423, -0.1189119, -0.2947942, 0.37969866, -0.0020399864, 0.116898604, 0.19459026, -0.4102249, -0.06525562, 0.014817397, -0.23002648, 0.23736449, -0.039251607, -0.15963744, 0.38378716, -0.13727868, 0.036116958, 0.014983346, -0.26972613, 0.28503427, 0.212713, 0.31741968, -0.05476143, 0.09270516]}, "content": "Yeah, is that human in the loop? I've seen ideas use like a GPT-3 to try to guess. Do you like that idea? ", "podNum": 28, "speaker": "Connor Shorten"}, {"_additional": {"id": "db39cc9e-1a8d-4dec-b443-8ab80158f63e", "vector": [-0.32166928, -0.19385026, -0.4240114, -0.35047364, -0.21195853, -0.13963307, 0.059918225, -0.09066787, -0.07868041, 0.122946724, -0.17426583, -0.020646565, 0.09999166, 0.110287376, 0.22923458, -0.0060722395, 0.19942695, 0.07435621, -0.32052463, -0.19634706, -0.2835194, -0.14445135, 0.1422838, -0.062174194, 0.065579854, 0.038114205, 0.07542894, -0.09871917, -0.1467599, -0.031110853, 0.1438874, 0.24161056, 0.06377774, 0.029900819, -0.45337775, 0.061759647, 0.044534586, 0.21095407, -0.11698679, 0.031159043, -0.10679737, -0.15758975, -0.04505281, 0.21998662, 0.104926355, -0.25377375, -0.08035715, 0.064812936, -0.113839604, 0.12397688, 0.15528928, -0.2564396, -0.16766563, -0.09114488, -0.023332093, 0.16355829, 0.1944882, -0.23949558, -0.22580916, 0.015130367, -0.07369446, -0.20383325, 0.042921245, 0.37027872, -0.03525541, -0.10741695, 0.10869269, 0.04595945, 0.16228312, -0.14963233, -0.12734118, -0.045055754, -0.08786598, 0.11090454, 0.02366615, -0.14170998, 0.007172891, -0.036266815, 0.014971882, 0.07073728, 0.21287888, 0.114384025, 0.1834633, -0.13101211, 0.11785457, 0.16980541, 0.0050411765, -0.06998038, 0.046217747, 0.0047059115, -0.19779435, 0.30560917, 0.09536426, -0.2009961, 0.022737995, 0.12510473, 0.19074664, -0.058447417, 0.013314174, 0.036393046, -0.34143957, -0.12290586, -0.0724662, -0.29477113, 0.1776726, -0.12392305, 0.012965441, 0.06646605, 0.18921977, -0.32294688, 0.040507667, 0.26217574, -0.04351351, -0.16885903, -0.064509585, -0.095925376, -0.14107788, -0.045833685, 0.15718435, 0.207705, 0.07922828, -0.025282, -0.016457938, -0.08774713, 0.1641987, -0.043206766, -0.20129673, 0.25257173, -0.01752773, 0.30242485, 0.25292498, 0.16781214, 0.2750127, 0.36271858, -0.0505761, -0.27415773, -0.038812514, 0.083589785, -0.36437577, 0.16587153, -0.23672749, 0.41912663, 0.25018233, -0.113101184, -0.4575604, 0.1944867, -0.042215124, 0.06783023, 0.11731014, -0.08831554, 0.05377668, 0.122629784, 0.23814829, -0.0493462, 0.24121049, 0.16718903, 0.030884366, 0.10846756, -0.1062635, -0.4375712, -0.07171856, -0.0016819984, -0.2046543, 0.106430896, 0.13257208, -0.19149238, 0.064636946, 0.043611743, -0.06583458, 0.09167062, 0.0069305543, 0.038023844, -0.23168278, 0.13594049, 0.2607857, -0.0116326865, -0.14652702, -0.27751744, -0.10574084, 0.07111104, 0.058714755, 0.02269965, 0.27619654, 0.026431993, -0.16904044, 0.05953736, 0.12808767, 0.01603654, -0.16365501, -0.18001193, -0.09971951, 0.05878959, -0.09832364, 0.13213485, 0.11696127, -0.22005668, 0.36213472, -0.041186664, 0.019602627, 0.10384161, -0.22940876, -0.44297075, -0.074388646, 0.07161428, 0.028579168, -0.01231011, 0.32465494, 0.07509054, -0.02566865, 0.028158069, -0.07037429, 0.052528713, 0.0071027055, 0.23274216, -0.0274548, -0.13737576, -0.1654064, -0.066047534, -0.068700306, -0.038754843, 0.41087806, -0.16305259, 0.113853276, -0.44729435, -0.32656246, -0.0719405, -0.11008552, 0.037730858, 0.00067001954, 0.032702792, 0.18391597, -0.106313735, -0.2206018, -0.045928895, -0.031063877, 0.20447001, 0.3067523, -0.12747501, -0.09719671, -0.1821153, -0.048454814, 0.15787074, 4.2628497e-05, -0.066517346, 0.035152033, 0.23033828, -0.3240927, 0.19143182, 0.08628526, 0.15588674, -0.3045654, -0.32454807, 0.09319616, 0.13182065, -0.25620228, -0.01797197, -0.21758725, -0.069093615, -0.019117475, 0.37996823, 0.37881106, -0.19652495, 0.06921305, 0.090070605, -0.08894082, 0.04888861, -0.26748806, 0.10394367, -0.45279652, 0.1634373, -0.34729278, 0.26012838, -0.15347767, 0.0026402995, -0.04454676, 0.15667024, 0.070464164, -0.40704694, -0.16057166, -0.027443357, 0.010602858, -0.09944196, 0.39442948, 0.36314595, -0.010726944, -0.15555254, -0.053955764, 0.11901349, 0.12135905, -0.12979855, 0.17980438, -0.094156496, -0.3047384, -0.012202874, 0.16069765, -0.3571275, -0.03348121, 0.15617916, 0.38393283, 0.088091776, 0.10097413, 0.14051273, -0.13603093, -0.040816225, 0.043609407, -0.18594559, 0.18669853, 0.06833706, 0.32831377, 0.18485095, -0.009967968, -0.04689904, -0.14447972, 0.20944816, -0.072461635, 0.07646368, -0.50804436, 0.2766839, 0.09021451, -0.15753728, -0.03528201, -0.14068185, -0.005899772, -0.019477703, -0.096790984, 0.20064618, -0.24662156, 0.1296477, 0.033766232, 0.012787029, 0.17713484, -0.07692008, -0.0056064203, 0.27293116, 0.21766403, 0.38639235, -0.025124487, 0.147292, 0.041393667, 0.0546611, 0.03363666, 0.25910595, 0.10401712, 0.06388761, 0.02807647, -0.038660105, -0.08772458, 0.45354426, 0.19940093, 0.13605842, -0.17392963, 0.22290745, -0.17429446, 0.10538346, 0.22552158, 0.11031214, -0.15410738, -0.15558344, 0.03563629, -0.15291281, 0.1141601, 0.016661592, -0.0853945, 0.17326207, -0.023071049, 0.113325685, 0.115414076, -0.23951697, 0.0043048114, 0.11065123, 0.06577881, -0.108419344, 0.055360634, 0.13382632, 0.14348343, -0.010260132, -0.01561668, 0.030135121, 0.20539749, 0.3242877, 0.16392331, -0.018288366, 0.027400438, -0.19412503]}, "content": "Yeah, I think like this natural language layer on top of like, whether it's whether it's a vector database or a structured SQL database or a Mongo database, any of that, I think that's really powerful and really interesting because it allows like people who don't know SQL or don't know how to write GraphQL to interact with these databases. And so, yeah, I'm really excited to see this kind of like unlock a lot of, you know, new people using using this stuff across a variety. ", "podNum": 36, "speaker": "Harrison Chase"}, {"_additional": {"id": "db70ba5a-ae80-41bf-b70f-fcaf2237fd1f", "vector": [0.17757846, -0.30981526, 0.07559569, -0.11683431, -0.026485058, -0.0810042, -0.13235097, -0.024117798, 0.23748043, -0.05770973, -0.112216905, 0.02559277, -0.035297904, 0.053950075, 0.3662818, -0.28124577, 0.0128159635, -0.22782768, -0.2954356, 0.10289534, -0.33887893, -0.12889859, 0.11923351, -0.07096836, 0.08184487, 0.07411733, 0.09248209, 0.13268107, -0.37856686, -0.040188894, -0.088480555, 0.038280513, -0.065953426, -0.067478955, -0.096519336, 0.15987295, 0.17355657, 0.114276975, 0.02235438, 0.019805029, -0.080377616, -0.17940286, -0.029229997, 0.1150838, 0.23195437, -0.0008239979, 0.10587863, -0.02171648, 0.0050344914, 0.09986551, -0.039290063, -0.08575302, 0.13619626, -0.024448093, -0.10002583, 0.1544915, 0.022583846, -0.13097256, 0.1815713, 0.06711681, -0.08112419, -0.10789973, -0.064272, 0.20983547, -0.08030771, -0.06013419, 0.05684826, -0.050290026, -0.024068914, -0.077143736, -0.0219348, -0.10830488, 0.17953935, -0.039481685, -0.10671409, -0.09233218, 0.2282338, -0.014905766, 0.0076515614, -0.07515223, 0.01582774, -0.2937032, 0.090768024, 0.0884458, 0.10717732, 0.027062217, 0.13475311, 0.10673218, 0.009511394, -0.010040564, -0.33091992, -0.05770155, -0.07750619, -0.096237004, -0.21265678, 0.2456232, 0.075840116, -0.17018996, 0.02826216, -0.0476171, -0.2035948, 0.07214709, 0.20306596, -0.24723913, 0.32910264, -0.09819153, -0.10157776, -0.044670533, 0.09947306, -0.26495647, 0.038072683, 0.026432056, -0.002386455, -0.063100934, -0.011970735, 0.083890304, -0.09297499, 0.02208775, 0.29797632, -0.21459903, 0.016435336, 0.10806446, -0.0023981407, -0.035449564, 0.060610227, -0.16234246, 0.053102955, 0.24975887, 0.07977955, -0.037915185, 0.093406476, -0.064621754, 0.13590415, 0.22016978, -0.09838925, -0.16829075, 0.118981555, -0.03124634, -0.15904379, -0.16181655, 0.07286267, 0.23836985, -0.03588882, 0.127225, -0.36676455, 0.08512639, -0.10933866, 0.05140478, -0.04892899, -0.04869908, -0.007967312, -0.021686338, 0.2221618, -0.12307653, 0.08394165, -0.085299976, -0.124063976, 0.095106184, 0.03776574, 0.029639583, -0.050276328, 0.106174394, -0.12304826, -0.10271093, 0.15986645, 0.11224993, -0.060166415, 0.15686615, 0.05636991, -0.026208466, 0.0007086564, 0.17750987, -0.04917907, 0.014808686, 0.03707986, -0.0043783598, -0.17979339, 0.035382006, 0.013136204, 0.1155015, 0.045418385, 0.04454626, 0.086556174, 0.11250925, -0.09882351, -0.20151296, 0.034287933, -0.07356165, -0.06925249, -0.11382163, 0.034400024, -0.11163954, -0.065322176, 0.19920856, 0.0057620294, 0.053821206, 0.08249855, 0.11161298, 0.1020813, -0.056101993, -0.2716415, -0.20684227, 0.0032085904, -0.047472358, 0.079113215, -0.16181153, 0.38916606, 0.17202294, 0.21811736, 0.10537041, 0.06758605, -0.0042198226, 0.050577387, 0.115576394, 0.19386387, 0.027222803, -0.26002532, 0.018048815, -0.09079948, -0.078011036, 0.037026413, -0.2676071, -0.032344624, -0.321838, -0.13609448, -0.21772495, -0.017548457, 0.019622462, 0.12057102, -0.03902588, 0.21822703, 0.2642108, -0.13963541, 0.15415311, -0.119300775, -0.098267674, 0.17690162, 0.0614498, -0.081169724, 0.03750237, -0.079957925, 0.0069380514, 0.12535876, -0.17765085, -0.075783245, 0.17629954, 0.021580398, 0.24818894, -0.047217444, 0.09772413, 0.14941578, -0.038933188, -0.16824293, 0.022220172, -0.25733793, 0.06208857, -0.43255833, 0.17925695, 0.057196498, 0.2741915, 0.023900997, -0.30631807, -0.06815041, -0.2900988, 0.026998881, -0.13679871, -0.047253594, 0.3526868, -0.30847377, 0.048114315, -0.18668915, 0.48573297, 0.03111047, 0.00055046193, -0.1042697, 0.20960587, -0.09387368, -0.16944079, -0.20376337, 0.11358514, -0.06379586, -0.15072992, -0.08974582, 0.11636317, 0.08176101, -0.19891876, 0.15545285, 0.14389364, 0.08116232, -0.058270603, 0.026162028, 0.06828511, -0.16046768, 0.05075941, 0.1499937, -0.1816581, -0.25502646, 0.16035159, 0.28918093, 0.18161406, 0.121052936, 0.050187957, -0.1258396, -0.06720133, 0.025948346, -0.07262623, 0.041960202, 0.3018216, -0.031192698, 0.061329916, 0.011493623, -0.14569922, -0.058037937, 0.07856692, 0.0015981458, 0.08834074, -0.29427445, -0.08726948, -0.028129028, -0.12884513, 0.07905697, 0.11038989, 0.20771852, 0.31590948, -0.049463734, 0.095599234, 0.14619309, 0.12391667, -0.18846661, 0.0825365, 0.096583605, -0.012923114, 0.119652115, -0.07949457, 0.23932767, 0.26652423, -0.09817356, -0.07094336, -0.075405315, 0.10754774, 0.019091262, 0.28429213, 0.19630702, 0.19262418, 0.13227025, 0.10089907, -0.085739, 0.24537086, -0.019494079, 0.0868944, -0.0519953, 0.081887126, -0.23334901, 0.1242692, -0.0049231974, -0.20924056, -0.10418381, -0.17309976, 0.1735573, -0.6691937, 0.047121026, -0.077577755, 0.01947805, 0.3919148, -0.066553906, -0.09430979, 0.20782524, -0.16078177, -0.07475619, 0.0728842, -0.06842462, 0.035812635, -0.011298021, -0.093854636, 0.099287786, -0.058290213, -0.26684952, 0.08399181, -0.2701008, 0.14718418, 0.25335693, 0.074503586, 0.061952487, -0.1582109]}, "content": "Yeah. And what I find interesting, and that is just a and I saw somebody tweeted this, but I forgot I forgot who sent out this tweet. But the thing is, like, we're spending so much time, right? So we're making these podcasts to talk about it. We have or we have the academic research, we have the blogs, we have like, and everybody's doing that stuff, throwing it into the outside world. And then it just takes an input, you know, an input box on a website where people can just type it in. And I find that fascinating goes for you guys as well. I remember that you had the first tweet. I think there was also a tweet where it's like, you know, people can try it out and you have like the link and you can could ask a few questions. And I was like, super exciting to see and people are actually trying it out and testing it. So I was like, oh, this is it's just sometimes it's so interesting. So sometimes something is like in the air and people go like, you know, kind of get it, but not completely. And then it's just an input box. And it doesn't matter if it's you guys doing it or OpenAI doing it just that people can type something in and that they just get a response back. And I was and I thought that was like, I had to laugh about it because we're spending so much time making content and explaining to be able to this is what's happening on the route and those kind of things. And then it just took an input box for people to fill something like, oh, now I get it. Yes, yes, yes. Yeah, yeah, that's actually I like that. So it's like it's it would be the same as like, like if you see like, you know, an image issue who would start off by, you know, telling how, how he or she is going to make an elephant disappear, right? You just you don't care. You just want to see it happening, basically. Yeah, interesting. So so I'm curious. I'm curious to hear what kind of what you guys think that you might see happening, because what I what's very interesting for somebody like like myself, I'd say the in our case, we're like an infrastructure database provider that helps, you know, in this stack and these types of applications, your building is like amazing, because that brings it really into the hands of, you know, like literally everybody, right. So just to the the non software folks, if you will. And I'm just I'm just curious where you think. If you just dream a little bit about like what you think that will be happening in the in the near future, what if you had to guess what do you think that they will see in the coming year? ", "podNum": 30, "speaker": "Bob van Luijt"}, {"_additional": {"id": "db73409b-920b-492b-89bd-213645b5f58c", "vector": [-0.17889734, -0.20873362, -0.21437751, -0.054080773, -0.12062413, -0.166989, -0.049704924, 0.016229676, 0.1962623, -0.11971287, -0.09550951, 0.05240564, 0.0065713376, -0.043956958, -0.06640249, -0.06998238, 0.06303664, -0.14500767, -0.46211672, -0.095781095, -0.1355109, -0.015869152, -0.03637173, -0.0036044982, 0.12149905, 0.0672034, -0.084422916, 0.042781495, -0.027105032, -0.15009868, 0.062136326, 0.09152813, 0.17461282, -0.012334745, -0.0667967, 0.10886119, -0.045959115, 0.17489642, 0.114253126, 0.050218627, 0.014085538, -0.12660967, 0.0026546253, 0.26297766, 0.18336783, 0.012634214, -0.1690375, 0.045088008, 0.091062166, 0.072691545, -0.09564671, 0.09674626, -0.20703116, -0.06086083, -0.04992301, 0.075858146, 0.17906958, -0.1049927, -0.052203707, -0.06537192, 0.059530035, -0.20557879, -0.13677451, 0.22890326, 0.1461258, -0.16616713, 0.18564497, -0.013965119, -0.135235, 0.25525963, -0.07879896, 0.012741928, 0.07187268, -0.060624223, 0.0074568745, -0.06343721, -0.030560289, -0.105430335, -0.088573515, -0.06623698, 0.116210304, -0.14414653, 0.06907971, 0.006625169, 0.15284795, 0.15319532, 0.21972959, 0.093386926, -0.059781745, -0.10257434, -0.14328697, 0.07994515, -0.100232355, 0.018794771, -0.040274523, 0.12468687, -0.0076446887, -0.21016163, 0.007918916, 0.08562656, -0.2060141, -0.018415656, -0.042059116, -0.35581368, 0.027279653, -0.27894014, -0.010067529, 0.19589895, -0.025607608, -0.08658322, 0.0505664, 0.0049250894, -0.13038303, -0.06441275, -0.0094205765, -0.12988323, -0.16794978, 0.091750994, 0.16594172, 0.0905251, 0.04001879, 0.05482542, -0.0035598138, -0.021274865, 0.0050274283, -0.1413073, 0.1777788, 0.13236244, 0.10620048, -0.1729969, 0.1880537, -0.068193, 0.1068773, 0.17936929, -0.13288724, -0.12466514, 0.22161485, -0.011905805, -0.1629685, 0.29039505, -0.04701921, 0.20537364, 0.18516065, -0.19608846, -0.28438398, 0.31333438, -0.16562337, -0.06496743, 0.09743276, -0.18419412, -0.11438099, -0.06788317, 0.14233004, -0.05027449, 0.0568785, -0.027593195, 0.034086034, 0.19883777, -0.08406308, -0.0039375606, -0.14339238, 0.16177674, -0.056977436, 0.0392445, 0.15615344, -0.11370027, 0.24307013, 0.04609246, 0.011406519, 0.19694997, -0.11907872, -0.06703847, -0.13361895, 0.010841659, 0.05742028, 0.073326156, -0.28650233, -0.08519121, 0.031869043, 0.19007061, 0.1333764, 0.10494458, 0.2681364, 0.025734138, 0.032424502, 0.008207438, 0.056232095, 0.13254648, -0.15668017, 0.013471252, -0.017419148, -0.041181836, -0.08268213, 0.17554058, -0.07758615, 0.11475718, 0.07721603, 0.2898742, -0.11599306, 0.068041116, -0.34379295, -0.33501208, 0.08070967, -0.16638869, 0.2673902, -0.08512887, 0.06680371, 0.06867065, -0.0783075, 0.12561767, -0.112226635, -0.18579748, -0.0703225, 0.14366826, 0.07718246, -0.0011794535, -0.18672124, -0.06824656, -0.06540827, -0.019203901, 0.13638166, -0.28832036, -0.09472189, -0.39907515, -0.28068367, -0.089718096, 0.035430092, 0.17379737, 0.06696535, -0.054555625, 0.15435083, 0.21744312, -0.053205118, 0.048753843, -0.05598024, 0.08105355, -0.029180113, -0.09712369, -0.054236423, 0.0035927163, 0.06172108, -0.05736788, 0.20447904, -0.1921083, 0.1837065, 0.17536339, -0.0036786299, 0.20191035, 0.10441485, 0.27492896, -0.2334918, -0.05385007, -0.061427098, 0.019336695, -0.20603926, -0.055130076, -0.21838473, 0.11966595, -0.16458665, 0.13590056, 0.37385294, -0.054822043, 0.016974999, -0.21357259, 0.12558103, -0.06397479, -0.14865683, 0.35043988, -0.18910956, -0.035174858, -0.092449136, 0.07897806, -0.09675694, -0.055085782, 0.026131948, 0.19249207, -0.17251144, -0.124325395, -0.3865101, 0.048964474, 0.081508346, -0.16193344, 0.07564204, 0.19253649, -0.01595748, -0.22294098, 0.01390403, 0.1109634, 0.16757658, -0.12809315, 0.11794542, 0.15083094, -0.17703658, 0.08515783, 0.0006648455, 0.13430253, -0.093722016, 0.19056076, 0.03588435, 0.042275302, -0.06922448, 0.032768153, -0.0636281, -0.058000904, -0.06918767, -0.09375502, 0.18036659, 0.15809347, 0.16510054, 0.07599166, 0.21528438, -0.017710157, -0.04617366, 0.22062132, -0.104734115, 0.044624016, -0.20740926, 0.28767452, 0.020521628, -0.14422756, 0.08116171, 0.021524314, -0.014443357, 0.22361456, 0.0386081, 0.046005294, -0.03624639, 0.29434285, -0.058510646, -0.04903292, 0.25964087, -0.03066813, -0.1082264, 0.20039313, 0.36894104, 0.3819604, -0.16655518, -0.07746858, -0.055919025, -0.025280612, 0.030665593, 0.23508215, 0.11059559, -0.11029681, 0.086908706, -0.009649287, -0.0994973, 0.47463533, -0.047158938, -0.17015354, -0.08079966, 0.087892845, -0.056827918, -0.004086008, 0.073921345, 0.04409546, -0.3073831, -0.016722867, 0.031295665, -0.36803177, -0.026889725, -0.10057791, -0.17064875, 0.4782586, -0.093585685, 0.011588481, -0.03753305, 0.0038920972, -0.16846916, 0.116451316, 0.10136482, 0.059349827, 0.069128394, -0.03714131, 0.20133631, -0.10895642, -0.18505198, -0.06754332, -0.1898973, 0.1744141, 0.12785755, 0.06453599, 0.26013875, 0.008282088]}, "content": "Yeah, that's incredible. And I think there's a lot in that to unpack. I love this argument around, say, the CPU, the commodity computers and how, you know, having the GPU is this bottleneck compared to how you package software applications. Hearing about the pruning and getting into the science that we're definitely going to unpack that a little more as well. But we also hit a little more about this, just kind of like these numbers and some of these claims that I came across in Neural Magic. I saw these images where it's like BERT large, distill BERT and this BERT large running, a sparse BERT large running just as fast as distill BERT. And now that I've plugged this into Weaviate, I've seen it myself firsthand. And so can you tell me about just like these numbers that you've all been able to produce? Because I think these just jump out to people when you're scrolling through LinkedIn and you see one of these bar charts, it's like five seconds on CPU, six seconds on A100 and say 13 seconds on T4. ", "podNum": 27, "speaker": "Connor Shorten"}, {"_additional": {"id": "db8aac4d-7627-4f2e-bccd-a32310c4f686", "vector": [-0.029496768, -0.0015029311, -0.040074587, -0.158258, 0.026575407, 0.034446564, -0.10773223, -0.24066956, -0.08425916, -0.04100952, 0.01625003, 0.29500887, 0.061852798, 0.21882516, 0.19010933, 0.01779169, -0.026267195, 0.21222462, -0.31644943, 0.029822856, 0.027293772, 0.034899265, -0.044396818, -0.0921028, 0.06860845, -0.07749324, -0.18858309, -0.14320518, 0.043036964, 0.04037728, 0.14109969, 0.04856725, 0.19877453, -0.029260466, -0.047607243, -0.100761026, -0.083142035, 0.32563847, 0.10838128, 0.061725218, -0.03644526, 0.0017610366, -0.21487908, 0.2305867, -0.13518411, -0.05368026, -0.1759978, 0.12187632, -0.057461996, 0.016829705, -0.18113418, -0.03907414, -0.2515054, 0.011951505, -0.13078338, 0.09659728, -0.030590026, -0.17953974, -0.038965307, -0.060917005, -0.052290957, 0.053145308, -0.20682882, 0.25940707, 0.21336173, 0.038329918, -0.03168869, -0.06910372, -0.10779054, 0.29131088, 0.12212056, -0.001402876, -0.02479173, 0.15941696, -0.072895266, 0.09663508, -0.00786399, 0.16264656, 0.06449405, -0.042772334, 0.04888, 0.068400465, 0.026801506, 0.20751955, -0.05716835, -0.060430575, -0.0368541, 6.817902e-05, -0.01610552, -0.26530412, -0.23634982, -0.34468922, 0.19884808, -0.09187392, -0.22675216, 0.030157909, -0.035873026, -0.07294891, 0.47663006, 0.008625981, -0.37469223, -0.020070301, 0.035108652, -0.5748232, -0.037600905, -0.18749791, 0.0038683626, 0.024902062, 0.15118034, -0.06523407, -0.07164787, 0.10526022, 0.066974916, -0.07184465, -0.007370457, -0.08597359, 0.011976272, 0.016594803, 0.08764414, -0.10419247, -0.006967602, -0.03072694, 0.13285254, 0.024018696, 0.09555101, 0.16803758, -0.02614584, 0.25194505, 0.39944413, -0.22702087, -0.0007524292, -0.033023283, 0.2800667, 0.13719954, -0.11287447, -0.27915668, 0.124277435, -0.058553576, 0.07296029, 0.2669003, -0.04083344, 0.3267266, 0.1961415, 0.085823774, -0.20796506, 0.24719787, -0.053597275, -0.22385545, -0.0063824463, -0.2558965, 0.008657708, -0.03222078, 0.26200017, -0.013959152, 0.0049668415, -0.16901053, 0.12573685, 0.06665572, -0.15607673, 0.02708069, -0.21736531, 0.031792358, 0.024140479, -0.007902411, 0.14975236, -0.028503893, -0.010199678, -0.045435876, 0.20324862, 0.055399816, 0.1091611, -0.09240382, -0.19069116, 0.0236589, -0.16003282, -0.102142654, -0.18880874, 0.09553244, 0.2848518, 0.08865062, -0.18693894, -0.11356581, 0.10165546, 0.09973662, 0.05955346, -0.03612919, 0.03124626, 0.16413204, -0.034422345, -0.172825, 0.03845908, 0.074837826, -0.044651195, 0.0138483895, 0.0006980275, 0.08777145, 0.1250766, 0.16144563, -0.01281136, -0.13523893, -0.17917384, -0.12890533, -0.1309054, -0.108069025, 0.015637817, -0.0850899, 0.08475399, -0.15782635, -0.16834748, 0.053960267, 0.12233608, -0.13737108, -0.25139922, 0.022137301, 0.46404132, 0.17431402, -0.024120368, -0.16375592, -0.4140139, 0.05598454, -0.14637068, -0.030880915, -0.2470113, -0.23418792, -0.35285366, -0.38492236, -0.04557514, 0.008038104, -0.07654001, 0.073060505, -0.05149658, 0.16899626, -0.14890172, -0.038556848, -0.01233988, -0.022513576, 0.1286351, 0.029866738, -0.15320943, 0.21726297, -0.0747437, 0.029067123, -0.23684876, 0.24347498, -0.23662741, 0.14833057, -0.095710665, 0.20804863, -0.008303434, -0.093263604, -0.103804134, -0.03631489, 0.17012276, 0.112863846, -0.30173287, -0.19488184, -0.29524133, 0.0029978987, 0.06883501, 0.28248623, 0.34611294, -0.42852703, -0.031033529, -0.016764028, 0.015728755, -0.1197995, 0.056503672, 0.16432612, 0.06436739, 0.019260852, -0.2876735, 0.25433093, -0.1085346, 0.082046546, 0.024970511, 0.1467632, -0.21793199, -0.07845461, -0.25988987, 0.12678282, -0.12181178, -0.16646661, 0.029688872, 0.10945177, -0.21764344, -0.09724478, -0.073202856, 0.1627974, 0.075524166, -0.1549717, 0.004614666, 0.055082787, -0.19693027, 0.07638384, 0.09959921, 0.06718353, 0.08812221, 0.2857559, 0.0924701, 0.020752216, 0.22635996, 0.07156204, -0.14172193, -0.040536217, -0.14858593, 0.035304185, 0.17174323, 0.03458155, -0.014061414, 0.0822903, -0.037844002, -0.1457064, -0.05520019, 0.16251622, -0.0029329855, -0.16509388, 0.032928213, 0.16581772, -0.08602434, 0.046967912, 0.105125844, 0.2253231, 0.099113524, 0.24991636, 0.08219685, 0.16407235, 0.20634185, 0.22930019, 0.05062516, 0.0566393, 0.1206908, -0.09284493, -0.38799253, 0.06953222, -0.04653724, 0.03318013, -0.029432684, 0.0700174, 0.030164847, 0.17146921, 0.21390206, 0.3699906, 0.037350927, 0.08721048, 0.1550714, 0.008285971, -0.16573153, 0.0944365, 0.012403474, 0.10913045, -0.20977463, 0.26324657, -0.15258224, -0.06550262, 0.18481718, 0.21522968, -0.040684126, -0.074399136, -0.097677015, -0.19548027, 0.18346344, -0.01883162, -0.09561715, 0.21545255, 0.24201988, 0.025330523, -0.11231396, -0.1913728, 0.1923926, -0.0042220503, -0.16044499, -0.10977975, 0.124572724, -0.24793679, 0.13666563, -0.04637006, -0.011681269, -0.18910722, -0.006700795, 0.06499802, 0.12381066, 0.10348621, 0.01684539, 0.16661067]}, "content": "Yeah, it's really, I think maybe the idea is like with the few-shot learning, we could give it a few examples and maybe that would work. But really, I find this idea of labeling the clusters so interesting with, say, the way that we search through Wikipedia articles, we vectorize each of the paragraphs and then we still have the title of the article as like a symbolic filter. So, you could ask, say, what year did Barack Obama become president? And you can filter that by having article Barack Obama as the title. And then that helps reduce the search space a lot. So, do you see maybe labeling these clusters with the summarization of the keyword list, I guess, as being a way to similarly kind of say, just search through this cluster and unsupervised? ", "podNum": 28, "speaker": "Connor Shorten"}, {"_additional": {"id": "dc16aaa4-da65-4672-85e9-3684fb2fc705", "vector": [0.07228309, -0.16415143, 0.020747406, -0.19193935, 0.05130605, -0.3560544, -0.071080364, 0.16048117, -0.090821326, 0.10279136, -0.030129343, 0.0006972067, -0.09020195, 0.10603765, 0.15279318, 0.10976219, -0.07218335, 0.111637115, -0.50298065, -0.03123419, -0.20715012, -0.080316596, -0.076407395, 0.0021253095, 0.00050108385, 0.09172839, 0.13997293, 0.123334326, 0.07480232, -0.3508037, -0.14767158, -0.007436953, 0.18342574, -0.09991121, -0.33240288, 0.24584013, 0.037052218, 0.29352948, 0.037769314, -0.0038509015, -0.0715636, -0.13706785, -0.012584378, 0.22564948, 0.013584897, -0.060251493, 0.15975162, 0.1365637, 0.0231447, 0.052997757, -0.07494866, -0.06956977, -0.21896096, -0.15900475, -0.00058738264, 0.34429452, 0.15462889, -0.25610092, 0.058398824, -0.31379244, 0.11679285, -0.16465165, -0.22210328, 0.5537961, 0.12112153, -0.20233183, -0.04129427, 0.2107534, -0.37146613, 0.4162073, 0.11247876, -0.07716674, 0.01890558, 0.14112009, 0.01596407, 0.104105495, 0.13309574, 0.050292555, 0.19936055, 0.04262839, 0.06053521, 0.08851705, -0.06817176, -0.19958173, 0.19443436, 0.087076865, 0.09612874, 0.016891956, 0.20807874, -0.100895666, -0.010428998, 0.080532394, 0.11987272, 0.08160546, -0.15210423, 0.29615068, -0.023974776, -0.40895784, -0.021622568, 0.38726225, -0.093442775, -0.08044417, -0.070379056, -0.13174398, -0.0033250332, -0.1538912, -0.102104984, 0.09956029, 0.12515815, 0.036967266, 0.08274727, 0.06612294, -0.24913637, -0.010839681, -0.14664741, -0.030940479, -0.2594336, -0.019900698, 0.28114718, -0.17983125, -0.0070151202, -0.19793957, 0.04313113, 0.10001675, 0.07624226, -0.19243114, -0.06408021, 0.22684163, -0.0903754, 0.067641936, 0.19011086, 0.02452329, 0.013587312, 0.21607496, -0.16556074, -0.20417236, -0.09732989, -0.15826838, -0.16002907, 0.19959779, 0.005668203, 0.39660725, 0.21413189, -0.2715685, 0.0022186537, 0.3026183, -0.14318122, -0.250996, -0.21343364, 0.05726097, -0.18418042, 0.054294754, 0.19171147, -0.10942361, 0.24856351, 0.048151776, 0.07989911, 0.057093594, -0.059583098, -0.1601214, -0.32456088, 0.22715986, 0.02336102, -0.09198413, -0.044103693, -0.17161924, 0.12046801, -0.070377745, -0.027389742, 0.11708007, -0.17951484, 0.039198387, -0.06329263, 0.03298079, 0.14950518, 0.026629575, -0.39804807, -0.04836373, -0.0058495197, 0.23386331, 0.09738511, -0.0034614962, 0.22239353, 0.14370944, -0.008515019, -0.009670568, -0.063249834, -0.14128922, -0.32610112, -0.053823262, -0.09558252, -0.13601904, -0.070569634, 0.17273158, 0.050032545, -0.0004934743, 0.18852341, 0.08639135, -0.108803265, -0.057737663, -0.254701, -0.1592396, 0.12439167, -0.24039997, 0.045889635, -0.041624468, 0.30632517, -0.07837455, -0.42315826, 0.43854558, -0.21955042, -0.18926333, -0.03690092, 0.030678028, -0.052220806, -0.11470745, -0.044758584, 0.21857685, -0.22395222, -0.06425068, 0.14242117, 0.18355818, -0.13224702, -0.49750432, -0.31973168, -0.17214556, 0.16035472, 0.37388134, -0.0461054, 0.053522993, 0.1540666, -0.19887577, 0.015081684, 0.06585256, -0.3390518, 0.11420647, 0.0588278, -0.13551913, -0.050932247, -0.10858893, -0.014515709, 0.15349801, -0.07623618, -0.18354683, 0.15516673, 0.41372547, -0.19293077, 0.19700019, -0.15329048, 0.342351, -0.36495602, -0.12104648, -0.21845686, 0.21641745, -0.27226877, -0.16389482, -0.34018168, -0.19716774, -0.030699397, 0.13339996, 0.33982107, -0.44381142, -0.13141009, -0.0075090392, 0.016099209, -0.08548846, 0.1162999, 0.35590795, -0.31087807, -0.16745424, -0.11764377, 0.26174304, 0.18288068, -0.13762483, -0.18343382, -0.071261175, -0.1322984, -0.21892534, -0.17910874, -0.11194083, 0.21908511, -0.061265048, 0.14496706, 0.37085602, -0.1714729, -0.23561586, 0.023561217, 0.08869287, 0.11162991, -0.033606738, -0.06908823, 0.12982762, -0.148242, -0.025748657, -0.0792603, 0.19163084, -0.104974896, 0.33449614, 0.05452625, -0.07139934, 0.24669941, -0.05122726, -0.061385423, -0.0958316, 0.005098503, -0.10175338, 0.09951633, 0.39755854, 0.031269234, -0.051241387, 0.026049437, -0.12556742, 0.15012373, 0.1853249, 0.035150282, 0.09496584, -0.1012617, 0.37637034, 0.19406861, -0.18235503, 0.036885075, 0.1400081, 0.25540024, 0.12397459, -0.096339345, 0.3232432, -0.033593502, 0.05597831, -0.2935436, -0.08981752, 0.24146383, 0.058518898, 0.06782966, 0.26070896, 0.36929783, 0.091180496, -0.08516692, 0.05323686, -0.18847786, 0.12777203, 0.10058432, 0.29440898, -0.055730168, 0.11975301, 0.081302606, -0.12233613, 0.14947955, 0.49739623, 0.10628704, -0.023665661, 0.04451722, 0.42538357, -0.09254942, 0.07211063, 0.40925458, -0.13752039, -0.19677098, -0.12294521, 0.106667064, -0.23168284, -0.041309167, 0.25905284, -0.08492184, 0.3644851, -0.11352713, 0.096363224, 0.03610747, -0.066628404, -0.27331012, 0.07750381, 0.030699104, 0.07404559, 0.31357744, 0.06159122, 0.13519745, -0.35993794, -0.09703236, 0.0076030022, -0.17445928, 0.28323588, 0.24863313, -0.0500077, 0.08140152, -0.059020787]}, "content": "Great. Thanks. So I guess the other thing is really the design choice when you're using Weaviate to bring your own vectors or to use one of the modules that are pre-existing to create vectors. And probably when you're at large scale, you want to have more control. So you're leaning more towards creating your own vectors. Do you have any insight around how you're approaching creating vectorizing at You.com?", "podNum": 32, "speaker": "John Trengrove"}, {"_additional": {"id": "dc456b5a-0472-400b-85e4-a3e2cb70579d", "vector": [-0.027256792, 0.20110632, 0.48052442, -0.10299929, 0.010630433, -0.09721128, 0.18596308, 0.052217565, 0.096620105, 0.14487343, -0.17057134, -0.26214573, -0.19535783, 0.04852595, -0.05395568, 0.111204945, 0.30307025, -0.025723564, -0.37041423, -0.3085903, -0.45527738, 0.2493878, 0.39372832, 0.1280747, -0.2709453, -0.08874597, -0.16632754, 0.028218575, -0.20593359, -0.013991937, -0.020214662, -0.108568214, 0.27769923, -0.12591048, -0.17384265, 0.43651515, 0.030198097, -0.07100037, -0.0769751, -0.07980361, 0.18088725, -0.20937082, 0.36132577, 0.051250122, 0.11173835, -0.23686056, -0.055985026, -0.017894559, 0.36513966, 0.25772128, 0.16503726, 0.11117865, 0.13506629, 0.28983533, 0.13128217, -0.028417232, 0.024462122, 0.3380986, -0.1503441, -0.04153773, 0.18809986, -0.3220101, -0.24987224, 0.54417926, -0.15338759, -0.22024322, -0.116072014, 0.2471628, -0.41165233, 0.3822603, -0.33715206, 0.10844615, 0.19437307, 0.29595208, 0.15255287, -0.16850121, 0.0075197406, -0.17650087, 0.026440522, 0.07592447, 0.34149742, 0.19795398, 0.02878586, -0.38803512, -0.06988976, -0.11241072, 0.19895458, 0.03855759, 0.14147525, -0.16528583, -0.23545533, 0.4772698, 0.20057026, -0.011504779, -0.14502487, -0.09152983, 0.01285666, -0.10401282, -0.42630163, 0.17800437, 0.21013027, 0.013062261, 0.25349167, -0.23520625, -0.36028925, -0.09447609, -0.30725864, 0.3110811, -0.18751436, 0.1302079, -0.07792847, -0.02844176, 0.03236525, 0.029600956, 0.20812383, 0.4776705, -0.12547022, 0.05356571, 0.6206393, -0.23687923, -0.04478109, -0.03687769, -0.13329297, -0.07929167, -0.63278383, -0.4884051, -0.065684326, 0.28456676, 0.036339305, 0.24212405, 0.0977394, 0.1513349, 0.09502129, 0.24662662, -0.3630808, -0.060066797, -0.41811737, -0.3446302, 0.346744, 0.2517642, 0.27690017, 0.04867812, -0.20098358, -0.3474284, 0.0816997, 0.29785082, 0.033780728, 0.0448341, -0.019620009, -0.28754446, -0.1906788, 0.42165786, 0.51820445, 0.054988906, 0.48539007, 0.09096427, 0.56860644, 0.076803856, 0.057183065, -0.15499997, 0.099980175, -0.38591546, 0.25368845, -0.28798765, -0.23352881, -0.27778763, 0.04105653, 0.030863844, -0.21117744, -0.008502558, -0.15469886, 0.09429652, 0.03523583, 0.095889434, 0.35322517, -0.07433191, 0.0800047, -0.078074545, 0.055843234, 0.11289811, -0.26975337, 0.09539428, -0.18456964, 0.06073183, -0.0020449683, 0.013321087, -0.089941844, -0.21661855, 0.08505466, -0.20528504, -0.11051968, -0.1061755, 0.0038134828, -0.1683893, 0.19689888, 0.35870725, 0.24372134, -0.055789787, -0.45065126, 0.14881715, -0.24961013, -0.14342538, 0.21656159, -0.008139402, 0.36983457, -0.1204401, 0.315814, 0.24081585, 0.08917441, 0.13770255, -0.14941937, -0.1814192, 0.267593, -0.019218609, 0.008312473, 0.08246561, -0.16718315, 0.40928137, -0.07349653, 0.0057604127, 0.011229452, 0.03652948, -0.08526692, -0.41466498, -0.07044774, -0.012766194, -0.26211292, -0.093824275, 0.2483513, -0.03771328, 0.066242576, 0.18959606, 0.1072295, 0.1625077, 0.18713468, -0.08745852, -0.07799093, -0.14805976, 0.11894146, -0.06621665, -0.023229022, 0.07972915, -0.1443425, 0.041875936, 0.13477737, 0.9078204, -0.18946882, -0.08368899, -0.44567594, 0.54275113, -0.14394926, -0.23295662, -0.34386814, 0.15970725, -0.061267726, 0.08425296, -0.92311287, 0.014760405, 0.02636414, 0.33883995, 0.29244635, -0.27426273, -0.11477142, -0.12829491, -0.19726838, -0.16831642, -0.05296667, -0.0066948645, -0.13137212, -0.08210342, -0.4191507, -0.22280481, 0.04972615, 0.07293802, -0.34360543, -0.006104052, 0.035266258, -0.2124395, 0.11295023, 0.15690754, 0.09612232, 0.14480059, 0.28823864, 0.23328285, -0.37236416, -0.087238126, 0.101164564, -0.04605919, 0.2064445, -0.13713196, 0.1727854, 0.2151275, -0.17191888, -0.096628845, -0.5542875, 0.23938322, -0.18889701, 0.58462465, -0.1310037, -0.280288, 0.13162442, -0.26796645, -0.16820115, -0.18181765, 0.0038674548, -0.089693844, -0.13753818, 0.02678453, -0.013631776, -0.0026312843, 0.2920928, 0.25265917, -0.015347276, 0.16285479, 0.06784599, -0.19686511, -0.351741, -0.04382143, 0.16317455, -0.32024443, 0.0908105, -0.11293635, -0.10436597, -0.0947871, -0.00024108961, 0.018888269, -0.21331553, -0.04605741, -0.15087533, -0.06267214, -0.01446441, -0.23978008, -0.10780364, 0.26293093, 0.24073598, 0.07086284, 0.07503949, -0.16335225, -0.08827959, -0.050828405, 0.199866, 0.2071541, -0.14907902, -0.0264998, -0.12901767, 0.13449447, 0.3395146, 0.21282655, 0.10039082, -0.3128437, 0.16899218, 0.26682132, -0.46774662, -0.030073714, -0.06888887, -0.18045397, -0.01688157, -0.5995332, 0.049645733, -0.28945354, 0.38645607, 0.09626776, 0.24152368, 0.64887047, -0.19778661, 0.28111765, -0.03899255, 0.04059811, -0.36161107, 0.20168495, -0.24399182, -0.054675695, 0.2389881, 0.29027808, 0.052256946, 0.07493822, 0.07419707, 0.15015818, 0.11899108, 0.2135236, 0.2601686, -0.03845767, -0.18405266, -0.18562818]}, "content": "Thank you so much for having me. It's always a pleasure to get to talk to you and I can't wait to talk about this new project. ", "podNum": 26, "speaker": "Jonathan Frankle"}, {"_additional": {"id": "dc7414fe-3c5f-49c5-aabe-830042fc72a1", "vector": [0.070347905, -0.22248706, -0.050241657, -0.13881244, -0.028470129, -0.13365416, -0.014361924, 0.013994346, 0.007697448, -0.08047487, -0.022868982, -0.0341387, 0.028229926, -0.008378295, 0.20718382, -0.012163083, 0.024227645, -0.16122136, -0.21825635, 0.013184498, -0.29398933, -0.00020648752, -0.045563657, -0.002955722, 0.007192616, -0.001054121, -0.023878293, 0.13903919, -0.124070026, -0.1222397, 0.09887358, 0.21375631, -0.103703246, 0.04928541, 0.045123603, -0.069868475, -0.02503659, 0.19496433, -0.10142819, 0.11684759, -0.12500888, -0.21404782, -0.12428013, 0.27853557, 0.11686939, -0.124267705, -0.035837583, 0.038177185, -0.029224029, 0.3005379, -0.070474446, 0.015982669, -0.27006227, 0.2312216, -0.15287863, 0.1038382, 0.0028525996, -0.035997815, -0.08657246, 0.027514467, 0.21519378, -0.13159128, -0.20958345, 0.56253463, 0.15681668, -0.16895626, -0.018164184, -0.23542976, -0.17207703, 0.22247158, 0.058856424, -0.08406679, 0.0111036915, 0.1531638, -0.14713803, -0.04387437, 0.022313714, 0.10527591, 0.020261228, -0.18399656, -0.11308809, -0.11639496, 0.041564934, -0.0798747, 0.09046718, -0.15216061, 0.002386887, 0.0029218346, -0.20394813, -0.04794846, -0.14178543, 0.17589799, 0.15241149, 0.27721092, -0.25463334, 0.14926608, 0.15846959, 0.014730663, 0.21275905, 0.473841, -0.2760109, -0.074744225, -0.10479925, -0.17320524, 0.044194203, -0.23747437, -0.10633409, 0.05357993, 0.10355728, -0.20397587, -0.052525215, 0.044453204, -0.18641062, -0.087367654, -0.07952229, -0.2585746, -0.20780046, 0.19084588, -0.014670683, -0.19499369, 0.022924399, -0.037357237, -0.094824836, -0.092591055, 0.10737314, -0.16519268, 0.13428578, 0.099927105, 0.04247841, -0.07014768, 0.07457747, -0.045183502, 0.1243406, 0.19686583, -0.16930893, -0.02904621, -0.15978214, -0.051271882, -0.20884943, 0.11439209, -0.0901485, 0.013044781, 0.2567712, 0.113763906, -0.19678356, 0.26978913, -0.20573916, -0.12060736, -0.044009946, -0.018530535, -0.00045605568, 0.056998603, 0.2711919, -0.050762884, 0.15374517, -0.10930091, 0.19036083, 0.10460807, 0.19671902, -0.12849848, -0.25618082, 0.15250656, -0.08189286, -0.09400882, -0.07662843, -0.10733659, 0.00942802, 0.10596799, 0.04439113, 0.13175924, 0.07453625, -0.03267706, 0.04359499, -0.015452451, -0.19187741, 0.101581015, -0.020057276, 0.06229437, 0.09496675, 0.06776403, 0.007307853, 0.12914829, 0.17498435, 0.13009512, -0.14465633, -0.14962257, -0.002214668, 0.06193169, -0.06710266, -0.12873657, 0.049909435, -0.11122433, -0.05298398, 0.20503971, 0.088681296, -0.15588105, 0.30080685, 0.1420018, 0.15401648, -0.05558234, -0.33220735, -0.07097258, 0.060217466, -0.26460192, 0.25840038, -0.050036192, 0.2670997, -0.13689736, -0.12762527, 0.18278004, -0.14741187, -0.00083334104, -0.2728049, 0.15903616, 0.12888157, -0.17440048, 0.08150465, -0.04988099, -0.3847693, 0.049287032, -0.113647036, -0.23577023, -0.022605535, -0.4701843, -0.18773139, -0.1785939, -0.003924951, 0.26596844, -0.0033308268, 0.052300867, 0.17841099, -0.072054885, -0.054940663, -0.005773425, -0.12796736, 0.01856229, 0.1783407, -0.24358416, -0.18515038, 0.22384755, -0.18431614, 0.05504921, -0.09321076, -0.039285116, -0.11319392, 0.014147133, -0.09097256, 0.42251554, -0.061393924, 0.14087285, -0.4397176, -0.016337674, -0.21126625, 0.08249207, -0.1278595, -0.15577409, -0.18771349, -0.066522606, -0.15532504, 0.16246603, 0.4653813, -0.4242328, -0.0457337, 0.06871105, 0.0074275914, -0.115907535, -0.011304349, 0.65022725, -0.18620582, -0.035230372, -0.1763717, 0.277478, 0.092181526, -0.04903353, -0.047628038, 0.18554048, -0.012910941, 0.044017408, -0.22217919, 0.104405716, -0.14239047, -0.04365129, -0.2934406, 0.18347749, 0.18812075, -0.026251325, 0.098815754, 0.029419865, 0.027532091, -0.046737384, 0.026606834, 0.0035128722, -0.3012506, -0.029314538, -0.00600839, -0.11348253, 0.17102651, 0.2214287, 0.20769925, 0.060969274, 0.016056266, 0.025383221, -0.11246092, 0.145822, -0.08855822, -0.095920734, 0.078298226, 0.22919238, 0.22638927, 0.007641807, 0.07853424, -0.07977945, -0.15146598, 0.062528536, 0.14481612, 0.046347644, -0.13134162, 0.12457512, 0.24464086, -0.04905311, -0.02507756, -0.02383548, 0.14656593, 0.13083895, -0.016519086, 0.0850473, 0.096936174, 0.28402734, 0.04459927, -0.06640829, 0.14624032, -0.06586524, -0.0749952, 0.064982735, 0.1488318, 0.17050274, -0.12080969, 0.091230035, -0.17120063, 0.22277679, -0.0010723344, 0.14287305, -0.001922965, 0.061860215, 0.114562735, -0.027034065, 0.012005208, 0.38991785, -0.012072643, -0.041356035, 0.09016722, 0.19927321, 0.062654026, -0.12076141, 0.42471355, 0.07100637, 0.052982744, -0.015477283, 0.11725398, -0.3239503, 0.06881768, -0.06629753, -0.090151176, 0.18799844, -0.023783203, 0.086067155, 0.07839118, 0.0028868956, 0.10873515, 0.14751986, -0.009836452, -0.069332965, 0.13696608, -0.041780595, 0.013510151, -0.11661545, 0.03968462, 0.045196045, -0.09972953, 0.22180726, 0.33629724, -0.24425492, 0.37185863, -0.016205424]}, "content": " No, it's another dataset format. Yeah. So, it is similar in some way to... One difference is you can have multiple datasets in one HDF5 file, but in other ways, it is quite similar to Parquet. Yeah. It is similar, but I guess the large-scale big data use case is more lean towards using Parquet or can sort of file formats like that. So, one last question I had is just around... So, using Spark... When using Spark with a search engine, I immediately think I'm using PageRank, the PageRank feature in Spark for generating features or potentially generating other sort of metrics that you're using as kind of ranking inputs. So, you're looking to store those in Weaviate as well?", "podNum": 32, "speaker": "John Trengrove"}, {"_additional": {"id": "ddb56ba1-86d2-4024-bba7-0c173f36d077", "vector": [-0.27411634, -0.18569691, -0.14245598, -0.21983199, -0.0991453, -0.13637762, -0.10603347, -0.005124624, 0.086666025, -0.045612495, 0.08871482, 0.09331693, 0.038508285, -0.055395216, 0.07853161, -0.051594697, 0.057402205, 0.031406175, -0.3816128, -0.02977098, -0.14771788, -0.05719043, -0.026450593, 0.060745012, 0.07232079, 0.03233573, -0.07852753, -0.038056828, -0.06506052, -0.17851812, -0.039115243, 0.18117297, 0.13512197, -0.043344416, -0.0011225522, 0.20861955, -0.03610161, 0.18635331, 0.02273122, -0.08730278, -0.19213486, -0.046390854, -0.027432602, 0.20402832, 0.12788118, -0.1312309, -0.06404459, -0.019895177, -0.013273409, 0.102205634, -0.03873573, -0.10240142, -0.121844254, 0.06045583, -0.060127176, 0.05659721, 0.08596394, -0.03628087, 0.035891574, -0.012679609, 0.079615645, -0.009758278, -0.20023866, 0.3414197, 0.2888723, -0.06351391, 0.05089304, 0.05454616, -0.07853247, 0.19220218, -0.06851242, -0.07513234, -0.27875933, 0.35750213, 0.07055873, 0.015626898, -0.047558893, -0.063442245, 0.11475513, -0.025794566, 0.12650123, -0.12050883, -0.0520276, 0.021291886, 0.033260804, 0.09596598, 0.22221534, 0.014592645, 0.07696777, -0.12986317, -0.102857254, -0.09181248, -0.06734605, 0.18259881, -0.19765338, 0.10921423, 0.11265059, -0.073932305, 0.002201052, 0.2933138, -0.1913124, -0.04552127, 0.00085344317, -0.099985525, 0.042759936, -0.2445863, 0.12929909, 0.06396319, 0.122797966, -0.09481205, 0.017441591, -0.0763824, 0.010697628, -0.14677897, 0.09927783, -0.13083406, -0.036680333, 0.066374816, 0.0806977, 0.06453726, 0.002613832, 0.046230555, -0.021817591, 0.0731517, 0.0914629, -0.024821918, -0.0661346, 0.13857225, 0.07868437, 0.03557989, 0.108551145, 0.052510053, 0.13027284, 0.12684417, 0.035134606, -0.102408126, 0.012340182, 0.058804303, -0.0817784, 0.209783, -0.24372327, 0.21888945, 0.19939283, -0.080532685, -0.16739537, 0.33217058, -0.19766176, 0.025229234, 0.05047842, -0.12188201, -0.07936555, -0.19228798, 0.17597821, -0.1585226, 0.13005267, -0.04216167, 0.056844473, 0.20152588, -0.09716514, -0.10075857, -0.16487403, 0.022212097, -0.05080601, -0.007817909, 0.16419698, -0.13201039, -0.033333696, -0.016278768, -0.028443012, 0.1287273, 0.04981575, 0.005366355, -0.028717816, 0.0615831, 0.21777925, -0.041287385, -0.17149282, -0.06080698, 0.00045056193, 0.17340894, -0.0002442658, 0.106625736, 0.18930629, 0.13864085, -0.064502195, -0.05030319, 0.27006924, 0.040163048, -0.21070358, -0.0044659795, -0.11351206, 0.0366243, 0.06859917, 0.09778982, -0.12340411, -0.11032732, 0.12933698, 0.0041891397, -0.1627262, -0.16915447, -0.29518345, -0.21937075, 0.036237963, -0.155292, 0.123014115, -0.01648955, 0.11211888, -0.04236639, -0.25993618, 0.04584738, -0.18665455, -0.08693229, -0.103356086, 0.099067576, 0.08102785, -0.089693405, -0.06672174, -0.18725607, -0.23405766, 0.02385563, -0.033673488, -0.15560554, 0.032976057, -0.34783065, -0.29582983, -0.26570866, -0.116424404, 0.1760164, -0.02851994, 0.1604363, 0.06807512, 0.06537689, 0.13115369, 0.07131199, -0.16878249, 0.023477893, 0.048026927, -0.075198926, 0.029349262, -0.04820224, -0.07447068, 0.07538386, 0.01266559, 0.097238556, 0.049541216, 0.118515536, -0.26438075, 0.19110453, 0.07746644, 0.28871986, -0.29773402, 0.021770086, -0.05288914, 0.19675803, -0.12966296, -0.14840344, -0.30644882, -0.008445424, -0.15165225, 0.100191236, 0.2519559, -0.12276419, -0.10669036, -0.05484859, -0.021395242, 0.08286788, -0.11872051, 0.09283866, -0.2299814, -0.08011937, -0.18721476, 0.040331207, 0.1736486, -0.014081146, 0.11134596, 0.06519623, 0.12210576, -0.14631572, -0.20173833, -0.10981395, -0.11056604, -0.20429978, 0.01056513, 0.2239993, -0.103307866, -0.0875776, 0.028521514, 0.09373715, 0.11243077, -0.16863565, 0.036988325, 0.023608316, -0.15386835, -0.01041385, 0.021740332, 0.08927579, -0.079200536, 0.21791396, 0.20666638, -0.14308167, 0.11835313, 0.055917025, -0.15630838, 0.04325472, -0.025846507, -0.009601089, 0.070521474, 0.16588145, 0.22451751, -0.036702316, -0.015499219, 0.093306795, 0.00081294106, 0.20143323, 0.054559708, 0.2356834, -0.065605596, 0.15022269, -0.003058374, -0.06933609, -0.06890492, 0.07901203, 0.15314491, -0.020999525, -0.08734828, 0.104252934, -0.12141986, 0.11661486, -0.045549978, -0.11499131, 0.16132683, -0.019250121, -0.21155195, 0.14499615, 0.097160056, 0.2323585, 0.013787326, 0.056965668, -0.112674095, 0.04984211, 0.02001577, 0.25682813, 0.00014766007, -0.17660971, 0.09611591, 0.0490359, -0.008041302, 0.2637877, -0.111786924, 0.07894472, -0.08365683, 0.2845299, -0.02044481, 0.14894274, 0.28149113, 0.16366723, -0.0135842385, -0.03837357, -0.0772209, 0.045184564, 0.08237715, -0.13850583, -0.1762392, 0.2257458, 0.014491007, 0.019419637, 0.023329403, -0.2610866, -0.01493943, 0.053787906, 0.14563003, -0.0062427493, 0.07509666, 0.15553737, 0.035688587, -0.023836745, -0.07778736, 0.06058409, -0.089090094, 0.27841872, 0.18368502, -0.07773732, 0.17104654, -0.024938393]}, "content": "I like the SPLADE model. I'm a big fan of it. I really like it because it's really close to masked language modeling. So the issue with dense embedding models is, if you train BERT MLM, it gives you really bad dense embedding models out of the box, weaker than averaging word2vec. But this MLM objective in SPLADE is really close between like SPLADE and MLM. You can take a word, you'll see, okay, what are possible synonyms here? And then you put all these possible synonyms for every token into a sparse vector. So here you have a really close match between fine-tuning and pre-training, which is extremely nice. Also they have shown really strong results on out-of-domain. So a big challenge for dense embedding model is new words. So people create new things like, I dunno, ChatGPT. Pre-trained dense embedding models have no idea what it is, but like sparse models, they just project it to new dimensions. You can search for it. So as soon as you search for it, you find it, which solves a lot of issues. Topics which I'm really interested in, which they sadly also don't solve is like long document encoding. So SPLADE works on a paragraph level, so maybe up to a few hundred, but in most cases you have like really long documents, like thousands, tens of thousands of words. I dunno. In some industry manufacturing setting, you have PDF documents of 10,000 pages, how to repair some machine. And their the question how do you, can you encode these long documents? And sadly it doesn't work with SPLADE and also doesn't in principle work with sparse vectors.", "podNum": 33, "speaker": "Nils Reimers"}, {"_additional": {"id": "dddeb45d-f1e4-44ae-9579-e6b309a69d28", "vector": [-0.17705125, -0.26215577, -0.15155832, -0.21756178, -0.099102676, -0.15106581, 0.09107544, -0.07729891, 0.002875097, 0.045843378, -0.11055436, 0.19527462, 0.18825902, 0.023783026, 0.23902218, -0.1676352, 0.14452061, 0.02098713, -0.33800942, -0.053995337, -0.15063715, -0.09403013, -0.097032845, -0.040158108, 0.0101883905, 0.15535638, 0.0971964, 0.052941673, -0.07558228, -0.101489484, -0.08117278, 0.13499576, -0.045136817, 0.051391393, -0.2183855, 0.12259961, -0.068692684, 0.20249194, -0.051472284, -0.11101273, -0.23035009, -0.123373, -0.029243855, 0.122214735, 0.082764894, -0.19664145, -0.076397195, 0.049490336, 0.054974467, 0.035991598, -0.17356434, 0.07565953, -0.12463093, 0.028091162, -0.0368607, 0.25047088, 0.1436435, 0.028992806, -0.0892001, -0.056076627, -0.11445454, -0.06467316, -0.027082354, 0.30973047, 0.14099702, -0.036330786, -0.030910842, 0.06213807, 0.061787494, 0.1395655, -0.07457899, -0.001418761, -0.13589445, 0.33190554, 0.03448692, -0.070037186, 0.013553195, -0.024157368, 0.14520094, 0.08304614, -0.06907298, 0.04318737, 0.069328666, 0.17540339, 0.095003136, 0.06953504, 0.11665887, 0.042595662, 0.22846779, -0.08757806, 0.016056824, -0.055610083, 0.037141655, -0.087139, 0.053508062, 0.14901547, 0.15361688, -0.02666878, 0.048161335, 0.17922382, -0.26707375, -0.0014477633, 0.02064908, -0.23639396, 0.16574228, -0.26965752, 0.12590137, -0.12129169, 0.17508858, -0.20526761, -0.026093557, 0.06431909, -0.04978759, -0.22461748, -0.15242375, 0.012552287, -0.12464881, -0.22693098, 0.06223551, -0.07683259, 0.077548936, 0.1031083, -0.027451303, 0.14046839, 0.03462166, -0.041437432, 0.045794256, 0.13699663, -0.11071403, -0.13283452, 0.21206176, -0.11143126, 0.20473522, 0.13307446, 0.06812922, -0.0928898, 0.119901724, 0.03581792, -0.066766135, 0.03738942, -0.06072184, 0.19012222, 0.1820549, 0.018781725, -0.1682435, 0.23753236, -0.17775114, -0.006811805, 0.12377699, -0.15634039, 0.098245196, 0.15437666, 0.048886113, -0.029345844, -0.0027035996, 0.058901034, 0.06976237, 0.049160093, 0.013486321, -0.20316629, -0.2258797, 0.11050653, -0.14912629, 0.005547094, 0.19486251, -0.023943879, 0.058166176, 0.030165948, -0.20240793, 0.13386601, 0.08308631, 0.04962828, 0.02230873, -0.042122215, 0.008172742, 0.11175434, -0.20129412, -0.048448246, 0.0075718854, 0.1101294, 0.25230563, 0.08232956, 0.118087664, 0.17968315, -0.009571459, 0.019357279, 0.0782203, 0.06818445, -0.036341473, -0.106111616, -0.11087132, 0.020225061, -0.06652569, 0.18947001, -0.11346632, -0.13261735, 0.379815, -0.13802685, 0.020299051, -0.08883576, -0.3810699, -0.09292631, -0.045527637, -0.1068698, 0.06293926, -0.15753046, 0.24921553, -0.17987794, 0.0012244787, 0.02490234, -0.064110056, 0.059141006, 0.0043898714, 0.06558314, 0.16438223, -0.064031616, -0.10499664, 0.025437813, -0.15224072, -0.03153787, -0.13385408, -0.12666476, 0.21026817, -0.40257117, -0.22970568, -0.11545192, -0.111897536, 0.08838638, -0.04090639, -0.06053088, 0.18346304, -0.23004168, 0.07612254, -0.038470436, -0.09943423, 0.069840506, 0.08112237, -0.12131269, -0.03243585, 0.061769363, -0.07285354, 0.032613177, -0.05111286, 0.094666585, -0.058056485, 0.19867815, -0.20515236, 0.22695905, -0.066455185, 0.061936274, -0.22117126, -0.11406406, -0.065702185, 0.12988333, -0.21495181, -0.090607144, -0.20305714, 0.06756456, -0.1457366, 0.095062174, 0.29745796, -0.20862272, 0.02462155, 0.0037758006, 0.14616472, -0.052565776, -0.04391329, 0.19109575, -0.18870798, 0.022997957, -0.16194898, 0.19968113, 0.12288597, -0.13600513, 0.034754984, -0.091510564, 0.09900695, -0.08695647, -0.21115181, -0.011124413, -0.07634857, -0.1799599, -0.081477344, 0.27283463, 0.004699401, -0.05635928, 0.10952325, 0.16633385, 0.12931237, -0.10918467, -0.091238484, -0.09078576, -0.04879462, -0.090990365, 0.051574122, -0.07574312, 0.10501622, 0.1134896, 0.21209532, 0.11692025, -0.048176296, 0.02805091, -0.13513552, -0.04504327, 0.06384134, -0.115572914, 0.10867685, 0.11459938, 0.044786297, -0.14577678, 0.067470014, 0.01856453, -0.17954431, 0.21290585, 0.03746211, 0.104052275, -0.2655873, 0.2599788, -0.10171102, 1.5485799e-05, -0.10538509, -0.1750535, 0.06748144, 0.002446659, -0.060505047, 0.06080813, 0.010839151, -0.012139674, -0.042210363, -0.21850513, -0.017808108, 0.10956173, -0.127655, 0.0011516195, 0.07179074, 0.14375956, -0.0009219069, 0.11749961, -0.12978059, 0.11460942, 0.08670779, 0.11734496, -0.12950051, 0.092523165, 0.15215471, 0.0050176047, 0.021750432, 0.3676389, 0.021339774, 0.008391816, -0.017025921, 0.21368021, 0.09641297, 0.14573623, 0.2701481, -0.004557641, -0.022779793, -0.077839464, 0.05089337, -0.3635801, -0.008559319, -0.18095708, -0.23959711, 0.07000853, -0.056090143, 0.15542975, -0.13720852, -0.023411887, 0.15002963, -0.07880566, -0.007269174, -0.019233055, 0.0044294763, -0.011667968, 0.1594281, 0.06025763, 0.077148736, 0.03514957, 0.17067063, 0.17835096, 0.14296588, 0.19152603, 0.4402253, 0.06335026]}, "content": "Yeah, I think I'll maybe start with just a SQL database example, because I think that's maybe one that most people are familiar with it. But the ideas are common across other types of databases, whether structured or unstructured or vector or anything like that. And I'll start with like a simple example, but I think we'll see pretty quickly that it starts to get pretty complex. Okay. So at the most like simple example, the pipeline is basically you take in a natural language query, you then generate relevant SQL, and I'll come back to that in a little bit, but you generate relevant SQL, you then execute that SQL against the database, you get back the result, and then you pass that to the language model if desired and kind of like return like a human interpretable answer. And so yeah, like I think the example that we have in the documentation is like how many employees exist. And so it does like, it gets like the count of the number of rows in the employee table and then returns something to the user, like there are nine employees or something like that. Touching on the first part, like generating the relevant SQL query, as you were getting at, there's a lot of information that you actually need to put in to kind of do that correctly. So you need to kind of like put in information about all the tables that exist, and then not only the tables, but the columns as well. And if there are relationships between those columns, you need to input those as well. And so the prompt that you're constructing starts to get pretty complicated already. And so a lot of the value that LangChain provides is ways to like easily construct these prompts and then also like just like see what's going on. Like this is a complicated prompt, I'm already describing it, I already probably lost half the audience. And so like making it like really easy to see like what's going on and what it actually looks like. Okay, so that's like the simple use case, but there are a lot of like complexities. So what if there are just like too many tables and too many rows, or sorry, too many columns in those tables to put into the prompts, because there are contexts kind of like window length. What do you do then? And so one, another chain that we have in LangChain is basically a chain that first selects relevant tables, and then puts only those tables in the prompt. And so kind of like a simple idea, but basically the idea of like filtering down. So that's around like constructing the query. Then after like executing the query, what if the query is like incorrect syntax? What if it's kind of like references tables that don't exist? What do you do then? And so I think there's a few things that, to be honest, aren't in LangChain yet. They might be by the time this gets released, I think they're on our roadmap. One is the concept of kind of like output parsing or validators or guardrails. So like validating that things are valid in SQL syntax and stuff like that. Another idea is basically the idea of kind of like if it tries and it fails, just like passing that back to the language model and letting it learn from its mistakes. There's a really good example of this working from Riley Goodside, not with SQL, but with like a Python example, where he asks it to do a math problem. It tries to use like the math module, but it's not imported. And so if you allow it to kind of like correct its errors, it will see like import error math, not recognized, and then it will kind of like fix it the next time around. And so I think like things like that for SQL, for any type of database querying will be important as well. Yeah. So I think that's an overview of kind of like what's in LangChain currently and like stuff that we want to add because yeah, it gets a little complex a little quickly. ", "podNum": 36, "speaker": "Harrison Chase"}, {"_additional": {"id": "dfb4c8b7-9cbe-45dc-ad91-9204cea3c86a", "vector": [0.06779976, -0.42562017, 0.18620944, -0.08356203, 0.17280546, -0.3946415, 0.23255515, 0.11048501, 0.5607223, -0.37464857, 0.037785392, -0.23690122, 0.09453368, -0.14170854, 0.7546271, -0.06516875, 0.11335289, -0.062640384, -0.54577196, 0.35518217, -0.30073112, -0.24675825, -0.11697286, 0.041307554, -0.0029612458, 0.24122258, 0.27123818, 0.23578264, -0.20632756, 0.14409229, -0.20569095, 0.49271888, -0.19214459, -0.41133675, -0.044761874, 0.04859695, -0.13047855, 0.109277055, 0.2821543, -0.17589583, 0.07575985, -0.064720884, 0.07966133, 0.15489393, -0.13308167, 0.4004212, -0.050482858, 0.26167098, -0.3889307, -0.0014483035, 0.108578995, -0.14708044, -0.06246253, -0.39910924, 0.02769287, 0.3298359, -0.08055374, -0.017117977, 0.07105636, 0.33648458, -0.49987578, -0.08589418, -0.13505867, 0.19022748, 0.3461283, -0.05471328, -0.23433521, -0.6063054, 0.35029933, -0.12625003, 0.771844, 0.19141154, 0.253182, 0.16197273, 0.07036835, -0.3369662, 0.56503224, 0.28637543, 0.1530908, -0.17019583, -0.16111565, 0.24645957, 0.11497475, 0.1567708, -0.1970472, -0.46883333, 0.48542446, 0.43527496, -0.10360509, 0.045999352, -0.35646182, -0.36862853, 0.047787406, -0.26530105, -0.36641848, 0.37855345, 0.1795372, 0.20474789, -0.07127782, 0.05172377, -0.12876129, 0.36261457, -0.41543338, -0.28534508, 0.21646827, -0.46506953, -0.17498231, -0.22825603, 0.43900537, -0.13480093, -0.33817765, 0.035706982, 0.3143217, 0.08239867, -0.25731063, -0.022615785, -0.1994544, 0.46501887, -0.19492626, -0.37186685, -0.15772793, 0.3136801, 0.42203462, -0.2087385, -0.4456429, -0.0024530692, 0.13333918, 0.13426372, 0.33937007, -0.08342471, 0.09543431, -0.19245565, 0.11331575, 0.18049717, -0.19183704, -0.024344467, 0.6955144, -0.22790578, -0.014895797, -0.18015645, 0.3595914, 0.17136694, -0.23885028, 0.38813236, -0.66593766, -0.22607331, 0.5999969, 0.11659674, 0.028343752, -0.66929626, -0.25742492, -0.03138686, -0.15402773, -0.4975475, -0.046596356, -0.20303057, 0.0982886, 0.07354997, -0.16427903, 0.22219203, 0.29203779, 0.21559149, -0.032781333, 0.027876884, 0.34497994, 0.077307045, -0.15387474, -0.15789884, 0.43096584, 0.036263295, -0.1017077, -0.053762224, 0.040457208, -0.2673377, -0.31232, -0.14331836, -0.5895676, 0.19156305, 0.088281974, -0.010051869, 0.2283412, -0.028857987, -0.16072299, 0.16255149, 0.012789242, 0.01048324, -0.14770672, 0.008977689, -0.18116337, 0.0593234, -0.35311365, 0.019776538, -0.16783816, 0.11698047, 0.05884873, 0.014367558, 0.3163315, -0.10518719, 0.2377078, 0.12182789, -0.4562593, -0.30269986, 0.084074184, -0.37307104, -0.05906422, 0.06204279, 0.35353202, -0.08134353, 0.43018934, 0.06707682, 0.21821114, -0.24368285, -0.30863005, 0.32032856, 0.35207504, 0.4529501, -0.73117566, -0.056392267, -0.031969115, 0.015368136, 0.09636368, -0.32238054, -0.40985188, -0.4306181, -0.71811604, -0.31424627, 0.114964776, 0.040989447, 0.1327869, 0.09739621, 0.33041555, 0.074132055, -0.24114946, 0.12703273, -0.10933279, -0.15250482, 0.36242408, -0.073396645, -0.29579455, -0.1338166, -0.28512895, 0.21617621, 0.1312779, 0.00650556, 0.16408508, -0.008725587, -0.07658627, -0.015850946, 0.14387405, 0.10831059, 0.237641, 0.2693162, -0.33343875, 0.034693666, -0.27527672, 0.22195366, -0.33863243, 0.6106542, 0.13978198, 0.13027991, 0.09627767, -0.2960515, -0.44156227, -0.38747478, -0.19247647, -0.07815549, 0.023866748, 0.242479, -0.2421382, -0.16309273, 0.20033272, 0.018866207, 0.53192705, -0.043745942, -0.03792733, 0.39181012, -0.06174713, 0.3059423, -0.67431486, -0.028546058, 0.0149371475, -0.4035113, 0.58032835, 0.179564, 0.16865712, -0.109728694, 0.13731757, -0.4144928, 0.46024638, -0.01399644, 0.13092078, 0.1948731, 0.050220553, -0.18311237, 0.7558272, -0.16015983, -0.4421776, 0.06417716, 0.20980889, 0.18289997, 0.26141673, -0.33862656, -0.48911893, -0.25551623, 0.056449965, -0.1342897, 0.135662, -0.22417188, 0.14027949, 0.08599523, -0.16274586, -0.2912556, 0.1378805, 0.06779805, -0.057423647, 0.11768323, 0.32478452, -0.0638179, -0.10778413, 0.07122115, 0.18799865, -0.71992373, 0.041854933, 0.47542775, 0.19473997, -0.09435485, 0.09100775, -0.35837302, -0.24058883, -0.010676332, 0.027459301, -0.15492958, -0.22641784, 0.008544706, 0.62194085, 0.42600965, -0.15578353, -0.3304593, -0.114109464, 0.2013443, 0.36859906, 0.050309792, -0.0046269335, 0.2886789, 0.030007932, 0.28374946, 0.09129094, 0.50497144, -0.006172657, 0.022273824, -0.39701617, 0.4052634, 0.008942701, -0.08003063, -0.090158224, -0.19451708, -0.17335424, 0.10616456, 0.47144943, -0.60950977, 0.041448727, -0.25449622, 0.15042621, 0.6962774, 0.4369418, 0.029019643, 0.1921902, -0.24390116, -0.26020437, 0.05330781, 0.16926809, 0.16082306, 0.1020806, -0.24793318, 0.2959658, 0.028465236, -0.26865506, -0.11149934, -0.55478716, -0.104716636, 0.3173716, 0.3859164, -0.1568573, -0.37558156]}, "content": "So I said, it's maybe not a coincidence. Maybe some kind of subconscious decision. ", "podNum": 25, "speaker": "Etienne Dilocker"}, {"_additional": {"id": "e03e0dc4-4ab2-41c2-8803-a33a9fe7a19f", "vector": [0.1300322, -0.069979936, -0.14323872, -0.1938694, 0.072673015, 0.0356979, -0.19624609, -0.2849495, 0.08563494, 0.060768053, -0.07783411, 0.118024416, 0.030306982, 0.16876534, 0.36073053, -0.03141311, 0.039936118, -0.026303707, -0.39470452, 0.01644736, -0.3100525, 0.0695842, 0.02837013, 0.08403694, -0.049053844, 0.0064537134, 0.0043697073, -0.0022876724, -0.15698053, -0.17463826, 0.03023991, 0.35550922, 0.11586919, -0.03542061, -0.26215369, 0.103244305, 0.1623545, 0.30429745, 0.11239593, 0.2438516, -0.115965076, 0.012318886, -0.010305478, 0.3034577, 0.009248355, -0.1256197, -0.14091669, 0.010888878, -0.04854771, 0.10672743, -0.17129351, 0.07165484, -0.18084735, 0.23131706, -0.0052023693, 0.0061909286, 0.08577117, -0.01926992, 0.0020986146, -0.14470722, -0.07981993, -0.050311252, -0.13925754, 0.39659092, 0.37915656, -0.1315674, 0.056602743, 0.16971542, -0.21462606, 0.35267416, -0.10060108, 0.0013651066, -0.008440048, 0.099414304, -0.077313386, 0.02522601, -0.12634622, 0.081021376, 0.14738378, -0.18009923, 0.06374225, -0.07500544, -0.028930247, -0.14019214, -0.036777824, 0.036734495, 0.059538748, 0.024605304, -0.04653794, -0.14249831, -0.03246356, -0.100478694, 0.33664715, 0.0877619, -0.08787977, 0.21087681, 0.03836782, -0.34470075, 0.30933377, 0.13714096, -0.40046117, -0.08808141, -0.008302179, -0.29292458, -0.044392798, -0.40810382, -0.07330037, -0.11059379, -0.027509568, -0.100876, -0.052889097, 0.0047347858, -0.13569647, -0.36697105, 0.043071114, -0.17573749, 0.12960392, 0.004978779, 0.31831926, -0.2804727, -0.005823824, -0.05381869, 0.08943293, 0.092578, 0.15685935, -0.16733299, -0.18358432, 0.20415737, 0.23665147, -0.24146648, 0.10226966, 0.20642017, 0.18394488, 0.13801497, -0.063932635, -0.23239242, 0.2604414, -0.18748926, 0.02328185, 0.41201276, 0.13407625, 0.21371837, 0.014261663, 0.009815721, -0.13708365, 0.46485567, -0.19274193, -0.10981447, 0.0797736, 0.15091659, 0.03902314, -0.052569624, 0.5017112, -0.09471254, 0.13648178, -0.06719384, -0.06796438, -0.03607101, -0.06766752, 0.13178846, -0.2830993, 0.14253618, 0.011622831, 0.11153753, -0.044236414, 0.0033860991, 0.15176414, -0.08769643, 0.023461102, 0.013497109, 0.19754733, 0.011879001, 0.083046645, 0.018511815, 0.06956133, 0.011103872, -0.31513518, -0.17384602, 0.094133385, 0.18541327, -0.11034259, -0.00016487051, 0.20582749, 0.050056692, -0.18932553, -0.09718788, -0.033825263, -0.029592823, 0.005269779, 0.010381975, -0.23223375, -0.25713518, 0.055608008, 0.13474745, -0.16680191, -0.09785371, 0.38975877, 0.1912042, -0.18139924, -0.032540932, -0.16500832, -0.08432005, 0.013793427, -0.117665626, 0.0054562767, -0.13196017, 0.17403716, 0.03492778, -0.34531835, 0.16333246, -0.015637042, 0.04570935, -0.2697512, 0.100860484, 0.17397954, 0.07518104, -0.11140262, -0.014126366, -0.35977146, -0.10007739, 0.028928995, -0.20875868, 0.22117649, -0.39320794, -0.34213737, -0.08324155, -0.27165383, 0.20752722, 0.026700078, 0.16276266, 0.046469104, -0.109936, 0.08011122, 0.016977176, -0.23828474, -0.16264248, 0.06269007, -0.010415115, 0.034110352, -0.00037310747, -0.24795848, 0.0016239122, -0.050370183, 0.0742703, -0.1488968, 0.110571235, -0.21701013, 0.16676424, 0.091336206, 0.11460886, -0.1705113, -0.25443622, -0.054965023, 0.111118264, -0.25890186, -0.23306689, -0.3243962, -0.13591772, -0.017056534, 0.14519967, 0.21784681, -0.30327588, -0.0046499674, 0.02977149, 0.2190744, 0.050252542, 0.22531492, 0.24766211, -0.23143831, -0.05880275, -0.35633934, 0.34160593, 0.109184176, -0.1312632, 0.05904634, 0.035758827, -0.11856261, -0.37726223, -0.13959645, 0.019267255, -0.116329595, -0.20589371, 0.04775299, 0.3338747, -0.067433774, -0.10714078, 0.020202281, 0.16821486, 0.13020012, -0.22221237, -0.0444727, -0.106456734, -0.20556936, 0.028522223, 0.025025576, 0.04566515, -0.047912106, 0.033358347, 0.22385634, 0.14611167, 0.3392387, -0.20174776, -0.0741157, 0.118915364, 0.011565436, -0.009106233, 0.049879964, 0.35125983, 0.057068434, 0.0982201, 0.11327164, -0.023076052, 0.021351118, 0.08069736, 0.03651112, 0.020796936, -0.112371966, 0.112326644, -0.11012257, 0.015018478, 0.08515601, 0.0040614824, -0.056586083, 0.12896341, -0.12076693, 0.37154722, -0.027706133, 0.056201283, -0.060618654, 0.23705739, 0.115847446, -0.025240278, -0.19898787, -0.027284019, 0.20927, 0.15169209, -0.06688714, 0.016379802, -0.15410733, 0.20933868, 0.17274275, 0.09895623, -0.1830143, 0.1767485, 0.04144583, 0.17258821, 0.015780477, 0.37862405, 0.047420923, 0.2086286, -0.06832689, 0.18760419, -0.15081702, -0.050263222, 0.3390038, -0.08179799, -0.043257322, 0.0040316405, -0.00481092, -0.08801236, 0.061635956, -0.17426082, 0.026504898, 0.4474982, 0.11533007, -0.030785399, -0.22228399, -0.22523266, 0.0056805634, -0.054981902, -0.122688055, -0.027069915, 0.27693823, 0.016635291, 0.07779265, 0.042480335, -0.046057343, -0.115369536, -0.09026951, 0.07442122, 0.13359274, -0.11768107, 0.32982266, 0.01858236]}, "content": "Yeah, of course. So what we're essentially doing is you have for each topic, you have a vector, right? In this case, it's a sparse matrix for the entire topic term matrix. But for each topic, you have some values. And we have 5,000 topics. Some are bound to be similar to one another. Especially if you use just cosine similarity between two topics, you get certain topics that are very similar. So if you do simple linkage, some hierarchical linkage, what you basically can say is, okay, I'm going to search for the two topics that are most similar to each other. And these two topics, I'm going to find the documents for both of them. And I'm going to combine them together into one new long document, and then recalculate the CTF-IDF representation. And if we do that plenty of times, then we suddenly get a little bit less topics and more abstract and more general representation. ", "podNum": 28, "speaker": "Maarten Grootendorst"}, {"_additional": {"id": "e04dbdac-6233-496f-8ea6-3dd60d36e1a7", "vector": [-0.13331604, 0.4209832, 0.36920157, -0.089141935, -0.13805056, -0.074170515, 0.486174, 0.057299078, 0.22085485, -0.07892844, -0.060871884, -0.24049312, -0.3414655, -0.17382729, 0.24426745, -0.14240529, 0.043914948, -0.1687019, -0.07543994, 0.047164805, -0.22409984, 0.16634741, 0.26125038, 0.03408867, -0.22110806, -0.10127355, 0.04116705, 0.15222761, -0.18594132, -0.031179652, 0.12636147, 0.049240254, 0.2664506, -0.18792747, 0.014428139, 0.17565042, -0.05348564, 0.11236359, -0.11780392, 0.30399245, 0.10266651, -0.35020775, 0.10871623, 0.093966335, -0.0039387196, -0.085167184, -0.09640583, 0.022434741, -0.040320326, 0.14239958, -0.35777727, -0.12263286, 0.10499935, 0.36836863, 0.18929747, 0.30858308, 0.070045665, 0.3900342, -0.07036516, -0.08002985, 0.30996642, -0.22100495, -0.5834757, 0.84322155, -0.081234045, 0.010442909, -0.29711244, 0.09521664, -0.29568955, 0.37394008, 0.0056903176, 0.11878277, 0.040431254, -0.22082017, -0.15217313, -0.23606913, 0.330249, -0.10083929, -0.048235267, -0.27295536, 0.23079732, 0.13279204, -0.10316318, -0.17085338, 0.069646746, -0.09355341, -0.23704652, 0.2890821, -0.29299527, -0.042947553, -0.44872612, 0.2711653, 0.3761798, -0.081295505, -0.20379218, 0.5113936, -0.19792217, -0.22778024, -0.28377923, 0.27100828, 0.060882203, 0.34515738, 0.021196958, -0.37060627, -0.4050317, -0.2129454, -0.20071979, 0.10971974, 0.19545776, 0.010706648, -0.18965514, 0.059151202, -0.4257167, -0.047376964, 0.032326944, 0.22975886, -0.18311977, -0.10066678, 0.60916275, -0.43897504, 0.055765495, -0.00696069, 0.12327972, 0.15095925, -0.2789318, -0.40914938, 0.09620625, 0.54624623, 0.23766351, 0.07985017, 0.16803657, 0.4163425, 0.23281613, 0.37882966, -0.37153006, -0.4220466, -0.2966143, -0.29463685, 0.071137056, 0.07649364, 0.4053272, 0.27885586, -0.17595899, -0.12741649, -0.19359678, 0.3569885, 0.05399905, -0.36959398, -0.205363, -0.08799415, -0.056488816, 0.28745553, 0.7229837, -0.18795691, 0.4314143, -0.021291649, 0.62779623, 0.12821051, -0.17952469, 0.34502524, -0.08570507, -0.025583144, 0.1111277, -0.067931466, -0.16467974, -0.1851201, -0.048141263, -0.21693704, 0.12454069, 0.1954841, 0.09009176, 0.23939641, 0.120162964, 0.20324932, 0.0892673, 0.19787961, 0.28515223, 0.19560914, 0.043978304, 0.095703684, -0.48864418, -0.20864442, -0.016652357, -0.052544244, -0.17969644, 0.39697596, -0.22773644, 0.065043904, -0.13221966, -0.044714004, -0.0197628, -0.15760085, -0.0847359, -0.028691752, -0.06542352, 0.13342114, 0.13294967, -0.24359104, -0.22038081, 0.105472356, -0.05642104, 0.06755623, 0.2947834, -0.2848029, 0.12477663, -0.13769272, 0.5177719, 0.14922513, -0.14723188, 0.2461552, -0.16712925, -0.074712336, 0.008517543, 0.078653246, 0.111978546, -0.12757435, 0.13947658, 0.47694933, -0.11410377, 0.023626938, 0.12980798, 0.16314301, -0.1673492, -0.7233676, -0.42595807, -0.08081486, -0.15968359, 0.20552441, 0.39258096, -0.18712169, 0.023626698, 0.43129987, 0.51778567, -0.037150264, 0.016348314, -0.013087094, 0.25063947, -0.03403817, 0.22929636, 0.105061464, 0.02118501, -0.26072195, 0.054709285, 0.33047235, 0.2886672, 0.68399006, -0.48868412, 0.14547427, -0.53588486, 0.55016816, -0.013105869, -0.3005841, -0.19931518, 0.22428484, -0.2873329, -0.085652605, -0.48970914, 0.09794195, -0.0977328, 0.1714011, 0.33661824, -0.5606156, -0.19258094, -0.22550505, 0.61329454, -0.2941568, -0.041209817, 0.47876692, -0.050603725, -0.118498325, -0.66847074, -0.099777564, -0.009548441, -0.059939798, -0.15924929, 0.33815962, -0.22769539, -0.12974478, -0.07368012, 0.20129406, -0.30024523, -0.07751365, 0.29219246, 0.33987176, -0.3090214, -0.23623066, 0.39283937, -0.046220317, -0.023910586, 0.09826608, -0.072521, 0.08213124, 0.03121443, -0.09669364, -0.09030469, -0.23638421, -0.3624699, 0.3016508, 0.05445526, 0.17049052, -0.010601439, -0.25713366, -0.09184879, -0.28682068, 0.053455204, -0.143872, -0.15404549, 0.26259208, 0.1990725, -0.046053343, -0.40608495, -0.1169203, 0.300489, 0.40573654, 0.05726911, -0.2830677, 0.06328656, 0.007408172, 0.20607336, -0.25359875, 0.20657077, -0.12641603, 0.049663, -0.23194365, 0.114281, 0.36582065, 0.1478164, -0.44756585, -0.36382878, 0.1215589, 0.042153206, -0.080804355, 0.008066844, 0.3842165, 0.2257823, 0.08450635, -0.2982871, -0.30168766, -0.31357214, 0.02585398, -0.066376224, 0.18333443, -0.14979565, 0.5531815, -0.01378166, 0.16848767, 0.23426165, 0.2953439, -0.079942934, -0.21084109, -0.07008907, 0.8459662, -0.42868692, -0.16060597, 0.053262845, -0.27037045, 0.19174448, -0.25128525, 0.337583, -0.79444563, 0.09452727, -0.017080538, -0.091704935, 0.63695157, 0.029392933, 0.100659475, 0.042871833, 0.06513081, -0.44031316, -0.1868839, -0.29816282, -0.14607015, 0.4261495, -0.1791014, 0.15019768, -0.3409677, 0.061834447, -0.04186844, -0.30662847, -0.0027840436, 0.13447154, -0.33294606, 0.41671407, 0.22839716]}, "content": "Thanks, man. Looking forward to this conversation. ", "podNum": 36, "speaker": "Bob van Luijt"}, {"_additional": {"id": "e0b57c9e-19fc-45bc-9edb-917db76d3fbc", "vector": [0.010258944, -0.35045838, -0.16175283, -0.29681703, -0.14387256, -0.21154118, -0.049732704, -0.03728543, 0.07087525, 0.1887149, -0.17092001, 0.26115718, 0.22185077, 0.099214174, -0.017067889, 0.048083004, 0.1776457, -0.28201777, -0.34518954, 0.03802837, -0.18375075, 0.09781731, 0.26160333, -0.16477595, 0.18230307, -0.031021094, -0.31424052, 0.012774031, 0.14771609, -0.16092415, 0.21515988, 0.054722935, 0.24599582, -0.16335909, -0.07529066, 0.35486725, 0.09317959, 0.26979804, -0.08018474, -0.1557889, -0.04006621, -0.3557032, -0.06367779, -0.02507098, -0.11759893, -0.46745667, -0.034987524, 0.090855844, 0.24758466, 0.32081655, -0.28720865, -0.092401065, 0.013509139, -0.40204647, -0.14420868, 0.3741318, -0.042982668, -0.04586555, -0.028437933, -0.1558928, 0.019457223, -0.08824924, -0.2652025, 0.690574, 0.08351806, -0.11095869, 0.08660937, -0.17966612, -0.13388273, 0.07667498, -0.16916154, -0.0916416, -0.14313938, 0.12049063, -0.1818917, 0.0663419, -0.11433262, -0.25081158, -0.32621834, -0.31722555, 0.11333653, -0.42192277, 0.13503513, -0.22543001, 0.18758292, 0.07344059, 0.20285492, -0.1612117, 0.044379473, 0.1270454, -0.42339364, -0.1066392, 0.21264786, -0.16283101, -0.11992669, 0.05293868, -0.042006835, -0.16004936, 0.3886861, 0.23736334, -0.19669692, -0.15577428, 0.08712757, -0.43058705, 0.19864343, -0.37836817, 0.14497282, 0.11274179, 0.1341139, -0.09778518, 0.018511051, 0.0076241544, 0.03563947, -0.091733634, 0.22769864, 0.06711099, -0.17203605, 0.05024148, -0.06768962, -0.13342229, -0.035351124, 0.025446534, 0.17534877, -0.04773259, -0.12409958, -0.009088607, 0.5343341, 0.25099418, 0.29811218, 0.078421146, 0.04811317, 0.15156184, 0.27056682, 0.36487743, -0.3140129, -0.10607449, -0.16439728, -0.19593972, 0.07241095, 0.3087112, 0.13436544, 0.21055007, 0.24296133, 0.11771521, -0.48713315, -0.042837534, -0.16663156, 0.025626829, -0.024813434, -0.10920865, -0.1342481, 0.10780984, 0.18960227, 0.21586911, 0.63091254, 0.1450545, 0.19053991, 0.2173562, 0.021714121, -0.2844819, -0.108504474, -0.062153812, 0.061228085, -0.14403616, -0.0049690404, -0.16201141, 0.022469228, 0.23314579, -0.023339972, 0.023302669, -0.19337559, -0.057152197, -0.2988249, -0.044971805, 0.16440766, 0.12321488, 0.008063217, 0.119413905, 0.15537623, 0.1996327, -0.09947125, 0.39188305, 0.16346295, 0.36098197, -0.06501807, -0.011400458, -0.08390207, 0.1586451, -0.038257238, -0.06087083, 0.42049417, -0.09690914, -0.15771143, 0.08168744, 0.22771807, 0.1156773, 0.31928703, 0.07337778, -0.04895537, -0.08118664, -0.03088835, -0.7265721, 0.23766254, -0.11731414, 0.069842875, -0.0026907672, 0.09247777, 0.24867183, 0.031086108, 0.15670343, -0.11773336, -0.39867124, -0.20549507, 0.16786008, 0.032416344, -0.28815582, -0.43056118, 0.02857714, -0.29277492, 0.06849653, 0.034808356, -0.18345897, -0.12008981, -0.48869696, -0.12220725, -0.036557514, -0.022959417, 0.18195593, 0.054962084, 0.02182693, 0.18468525, 0.1919965, -0.18130887, -0.0689464, -0.08455584, 0.035464168, 0.07946498, -0.03694475, -0.21371464, 0.011036801, 0.003984014, 0.084549636, 0.057586785, -0.09215218, 0.09084529, 0.27372494, 0.09305388, 0.16834521, -0.111153565, 0.100818016, -0.1104098, 0.15391825, -0.1317951, 0.099496275, -0.067938, 0.024098197, -0.4885669, -0.20971926, 0.0034967065, 0.3947921, 0.48262128, -0.32807738, -0.3129726, -0.31041852, -0.1558661, -0.16472968, -0.24995877, 0.7162735, -0.170563, -0.08004547, -0.3638394, 0.20163365, -0.056860488, 0.102268495, -0.1330183, 0.38979137, -0.0182988, -0.21387441, -0.15171595, 0.1315461, 0.04420669, 0.057935342, 0.09898404, 0.1854225, -0.36379418, -0.21728571, -0.13051207, 0.26069933, 0.04055995, -0.054948654, 0.33472982, 0.317614, -0.3286887, 0.2921225, -0.15967104, -0.08853654, 0.27568865, 0.3478382, 0.19004834, 0.30100435, -0.14811337, 0.017343001, -0.0896118, 0.008387377, -0.016204646, -0.083288215, -0.026691696, 0.35907808, -0.018776352, -0.13830298, 0.36555326, 0.043552276, -0.16504055, 0.34425953, -0.010886031, 0.15084673, -0.37435007, 0.18090165, 0.20244719, -0.049896967, -0.24631983, 0.06608368, -0.10163819, 0.061083302, 0.23007452, 0.290997, -0.12114173, 0.4075881, -0.37442866, -0.04204144, 0.157355, -0.10624542, -0.2499433, 0.6623227, 0.5239304, 0.062453985, -0.118984096, 0.08714572, -0.09433433, -0.17114, 0.14572562, 0.20081206, 0.43385175, -0.050964158, 0.052981805, 0.034915257, -0.044467468, 0.051854137, -0.091083825, -0.1251943, -0.24026017, 0.20439947, -0.43646097, -0.22027767, 0.019755557, 0.19467443, -0.22641079, -0.32499322, -0.023592489, -0.2198302, 0.3239518, 0.29605785, -0.015306099, 0.23470588, -0.09039549, 0.2489795, -0.016109308, -0.16012682, 0.0784479, 0.11395448, -0.27668843, -0.34472504, 0.016101548, 0.014186099, 0.20593028, -0.25670895, -0.22822547, -0.121031135, 0.015171026, 0.49538517, 0.41382077, 0.24901183, 0.004818683, -0.41999245]}, "content": "Oh, yeah, incredible. And Bob and I recorded our generate module podcast. And Bob, you could hop in more on sort of just how you're seeing this kind of, you know, language model calling the search database and you know, from Google search to Weaviate search.", "podNum": 36, "speaker": "Connor Shorten"}, {"_additional": {"id": "e10779ea-c5ef-4a5b-9e29-0ad9cbd05cdb", "vector": [0.011764392, -0.09992135, 0.053607266, -0.18326898, -0.23106611, -0.24176274, 0.18943082, 0.30566806, 0.37256718, -0.20473103, -0.00357611, 0.25861314, 0.043440104, -0.35267237, 0.18626058, -0.059799094, 0.14093934, 0.05116044, -0.5590008, 0.12569945, -0.17311554, -0.11308509, -0.03066325, 0.02425926, 0.038297873, 0.051658288, 0.02364389, 0.27787158, -0.23008053, -0.036495488, -0.20461367, 0.19275646, 0.22360452, -0.24907921, -0.12533593, 0.058505356, 0.24274369, 0.3027675, -0.25695002, 0.036479037, 0.025163598, 0.002971704, 0.14856432, 0.24109624, -0.00031519434, 0.11582997, 0.061092045, -0.11040493, -0.03642939, 0.08175019, 0.338474, 0.03281066, -0.09420463, 0.18882108, 0.033036523, 0.21735108, -0.115354955, 0.002331366, 0.06157578, 0.02618209, -0.0636146, 0.08573089, -0.0081523815, 0.117168345, 0.47879705, -0.2433453, 0.06493526, -0.16866605, -0.11754776, 0.6023514, -0.007821086, -0.33722296, 0.04096342, 0.1689068, 0.12759994, 0.062845774, 0.1295529, 0.029883305, 0.08175785, -0.06486195, 0.0694704, -0.1790632, -0.10331615, 0.017037848, -0.012430725, 0.0008902848, 0.37898073, 0.099762894, 0.11266842, -0.017953478, -0.025290743, -0.15871847, -0.20351435, -0.03184246, 0.11119947, -0.012686245, -0.21160646, -0.10616765, 0.0467212, 0.14408821, 0.05934194, -0.035369605, -0.29295015, -0.048714787, 0.052855868, -0.2747513, 0.02138563, 0.27259606, 0.024356177, -0.013080659, -0.11531975, -0.16974227, 0.23386468, 0.08413503, -0.12901042, -0.2028595, -0.19921982, 0.05681665, 0.24726456, -0.11448622, -0.06828967, -0.13779546, -0.106755905, 0.034554515, -0.22730553, 0.016355896, 0.06253431, 0.10323509, 0.07612487, -0.10472757, 0.20000602, -0.35787797, 0.1864702, 0.26068515, -0.1961627, -0.024263673, 0.24422371, 0.23584564, -0.045460712, 0.022756169, 0.037724074, 0.09540555, -0.032153953, 0.037076477, -0.42893043, 0.14675088, -0.47933403, -0.09973678, -0.052962076, -0.10532718, -0.04668359, 0.13828301, -0.1074655, -0.40694603, 0.037277874, -0.1496854, -0.020952955, -0.041018087, -0.24166775, -0.03033883, 0.00028052926, -0.0666938, -0.06723002, 0.11742573, 0.31399104, 0.022344017, -0.049996395, 0.055800613, -0.06276957, -0.02747268, 0.23719068, 0.13860245, 0.12460488, 0.061775833, -0.032569345, -0.23012857, -0.54496104, 0.074057765, 0.040884055, 0.08346397, 0.50025874, 0.13988827, 0.0031225234, 0.3218901, 0.025566677, -0.018912638, 0.11412292, 0.10055766, -0.06406253, -0.13802545, 0.25972363, -0.31859046, -0.29231164, 0.3845967, -0.021269187, 0.061980814, 0.16316281, -0.015754512, 0.21535903, -0.035059396, -0.16708362, 0.012953282, 0.034251366, -0.16880286, -0.0136476355, -0.094091095, 0.39391747, -0.39321908, -0.23675509, 0.15708354, -0.18086155, -0.34557453, -0.16867454, 0.12953424, 0.023859033, 0.13557321, -0.18832512, -0.24492626, 0.0004096528, 0.023640327, 0.06518493, -0.11073071, -0.26946443, -0.3661727, -0.37362635, -0.18474956, 0.010986517, 0.17666352, -0.060847253, 0.19547848, 0.1985058, 0.02053982, -0.016333193, 0.12215561, 0.40200117, 0.097033, -0.10353926, -0.2195812, 0.12876606, -0.06080547, -0.27100164, -0.0065675676, 0.067724794, 0.06924718, 0.21727519, -0.03021934, 0.11274607, 0.36456677, -0.072885774, 0.19960208, -0.4396025, 0.15144837, -0.21529955, 0.056134462, -0.30075347, 0.053842295, -0.3104554, 0.046060186, -0.16117303, 0.04032755, 0.23055561, -0.02241007, -0.18685366, -0.038608257, -0.22323681, 0.14175537, -0.008513198, 0.46199414, -0.0703256, -0.061958447, 0.20070939, 0.0013664017, 0.4573009, -0.13128124, 0.0059684864, 0.10045799, 0.0334944, 0.5366056, -0.43230104, -0.12728857, -0.22047596, 0.031174729, -0.27432907, 0.47905704, 0.13428466, -0.05529058, -0.14723693, -0.32162505, 0.29256985, -0.094732344, 0.123447984, -0.25034794, -0.032053728, 0.25467348, 0.16310729, 0.25639048, -0.21111125, 0.44518635, 0.20389087, -0.070839286, 0.27530596, 0.045281027, -0.13546859, -0.054302875, -0.28980264, -0.06832466, -0.15184434, 0.10879335, -0.093222074, -0.04835528, -0.21891542, 0.13916837, -0.25538003, 0.10355931, 0.12936062, 0.082764395, -0.2015317, 0.054022133, 0.007867794, 0.039779164, -0.0591945, -0.3142664, -0.17389977, 0.12644513, 0.023602942, -0.09350566, 0.19239016, -0.16353752, -0.023248708, -0.2240452, 0.20345838, 0.017411955, -0.29474962, -0.02097252, 0.008502141, 0.04207383, -0.09408436, 0.19512177, -0.18398839, 0.026907012, 0.004357929, 0.20186381, 0.07306544, -0.07015457, 0.1271981, 0.023657948, 0.028494542, 0.1380028, -0.25235483, -0.2943581, -0.120005645, 0.3880608, 0.09341338, -0.05741793, 0.0028148096, 0.3492249, -0.0033118825, 0.09661224, 0.12861134, -0.36400548, -0.0058640814, -0.538832, -0.15519863, 0.21269746, 0.07269464, 0.22724573, -0.016699716, 0.29436913, -0.21638273, 0.016278848, 0.50553024, 0.21548945, 0.059796825, -0.193738, -0.0026821494, -0.44507137, -0.25816697, 0.3072814, -0.12709554, -0.041895475, 0.32470617, -0.023915166, 0.33272806, -0.06902416]}, "content": "Sorry to ask a clarifying question, but with the margin MSE, that's where don't you have to kind of explicitly set the margin in the triplet loss? And I always thought for that reason it was sort of funky. Like, because it's kind of like a alpha minus max, uh, kind of thing, right?", "podNum": 33, "speaker": "Connor Shorten"}, {"_additional": {"id": "e1bd0020-a698-48d9-b709-6470a3c980a3", "vector": [0.19442615, -0.16603325, -0.14486332, -0.20112625, 0.21413162, 0.07033448, -0.017848631, -0.09546468, 0.04731869, -0.09387845, 0.073001064, 0.14398666, 0.0048904098, -0.016545618, 0.10708795, -0.19682509, 0.16959521, -0.069376335, -0.4696764, -0.11229922, -0.23758039, -0.12843159, 0.15743878, 0.081929736, 0.146857, 0.080844924, 0.10550922, 0.14652933, -0.23638287, -0.16244915, 0.020567715, -0.15002796, 0.1383234, -0.11204861, -0.21538624, 0.12048431, -0.052837364, 0.23400088, -0.04113039, -0.033726227, -0.17818837, 0.02113131, -0.1433098, 0.20585103, 0.13398662, -0.005106137, -0.12607963, -0.028396642, -0.09908281, 0.013412535, -0.094395176, 0.00090691744, -0.28711033, 0.026368827, -0.093505956, 0.07334802, 0.06231519, -0.0056185126, 0.020770157, -0.099020004, -0.18137944, -0.2752115, -0.09814674, 0.30538863, 0.17933555, 0.08959659, -0.03339796, 0.10140069, -0.08817502, 0.4881875, -0.034500103, -0.035775114, -0.058425285, 0.19260433, 0.074277475, 0.12322776, 0.02857626, 0.08652116, 0.15934768, -0.088877454, -0.1025084, 0.018983167, -0.019288206, 0.10155551, -0.048251085, -0.0047819456, 0.10707203, 0.016865212, 0.04712322, -0.049953658, -0.18562509, -0.2993718, -0.0004883509, 0.051673215, -0.12270479, 0.18005052, -0.034005802, -0.16425923, -0.0606964, 0.17105453, -0.35010824, -0.00962428, -0.08184938, -0.2610256, 0.18324919, -0.29033726, -0.034020863, -0.09381085, -0.06289521, -0.27375597, -0.120528474, -0.006813885, -0.06276928, -0.17082122, -0.020442942, 0.12674275, -0.29544315, 0.08030568, 0.10642453, -0.25418565, 0.025750076, 0.050587296, 0.14403915, 0.1070054, -0.062460907, -0.06885274, 0.056706745, 0.13811311, 0.16268107, -0.25927123, 0.08906522, -0.04809336, 0.1687765, 0.20372927, -0.07398126, -0.15610225, 0.16814485, -0.0141150905, 0.09894973, 0.17647338, 0.098423004, 0.25061947, 0.24758765, 0.0025144652, -0.18202305, 0.35307238, -0.06799302, 0.03296587, 0.093549445, -0.32550097, 0.003289488, -0.01888968, 0.013621321, -0.19383356, 0.10633218, 0.012102598, -0.017659849, 0.06318263, -0.15959565, 0.0155322505, -0.17501467, -0.0037677712, -0.027936518, -0.072939426, 0.14964247, 0.097763345, 0.13363408, -0.09859484, 0.09318982, -0.014732406, -0.08388355, -0.08865251, -0.07135731, -0.096183755, 0.03923062, -0.040367138, -0.35891667, 0.14241862, 0.20703945, 0.07059336, 0.14546946, -0.008853456, 0.018174667, 0.22328858, -0.020871768, -0.041781355, -0.13505404, -0.08547397, -0.18614288, 0.02296572, -0.17732033, -0.0561348, -0.032212906, 0.2915151, -0.07198273, 0.05148661, 0.32656503, -0.09814638, -0.06200395, -0.1618533, -0.45766726, -0.06427951, 0.0660768, -0.20957895, -0.074262604, -0.13262717, 0.13821886, -0.05130141, -0.015329769, 0.17346998, -0.09136231, -0.03943694, -0.22342435, 0.06063942, 0.37837148, -0.08501284, -0.20771167, 0.059857517, -0.2516596, 0.070809685, -0.015200424, -0.2385494, -0.080114014, -0.37216944, -0.07778277, -0.22296831, 0.051682316, -0.021467512, 0.020407813, 0.19469026, 0.2583251, -0.039003894, -0.0386635, 0.052735485, -0.19840752, 0.016685527, 0.2352926, -0.0650873, -0.15862922, 0.03837558, -0.24260108, -0.0033487678, -0.09528993, 0.05104053, 0.026518757, 0.046060544, -0.09476743, 0.28039885, -0.01101453, 0.2517686, -0.10389801, 0.1510177, -0.31624454, 0.08894298, -0.2387106, -0.14245185, -0.3751642, -0.02225858, -0.2195692, 0.14318076, 0.29466474, -0.15339778, -0.16154543, -0.09907249, 0.18824682, -0.019649267, 0.014829665, 0.13879487, -0.23546202, -0.22340079, -0.10458851, 0.19450453, 0.14801022, 0.11662483, -0.22770143, 0.22479327, -0.02554351, -0.030496906, -0.30861223, -0.06504394, -0.004905389, -0.24199918, 0.11926915, 0.39043778, 0.016583707, -0.19484332, -0.05456369, 0.04883976, 0.3064573, -0.2000453, -0.042556725, 0.20717557, 0.010532779, 0.045643367, 0.124854006, 0.18898128, 0.05238398, 0.10876898, 0.23635992, 0.20907736, -0.017049422, 0.020948436, -0.19130692, -0.042856906, 0.013111201, -0.1765889, 0.048122652, 0.29585046, 0.1907223, 0.08885598, 0.1345293, 0.060013987, 0.10112604, 0.27244496, -0.022312026, 0.060397465, 0.11654721, 0.10542943, -0.22212753, -0.0029454683, 0.05178268, -0.028461818, 0.14985822, 0.34558314, -0.13257782, 0.19074605, 0.0008039743, -0.006992175, -0.19099846, -0.11398786, 0.18654633, -0.018930469, -0.14607824, 0.07814981, 0.05853167, 0.25277087, 0.06777646, 0.17200142, -0.111735925, 0.24790439, 0.08331357, 0.07102668, -0.103402816, 0.31295976, 0.10127132, -0.0015450775, 0.07900374, 0.4050601, -0.027796462, 0.036707215, -0.01719649, 0.18197593, 0.07450189, 0.19176881, 0.4085713, 0.030593757, -0.07804629, -0.027549049, 0.080821946, -0.24606268, -0.19174412, -0.1129951, -0.08775334, 0.37299842, 0.13059968, 0.06921286, -0.019071678, -0.3177247, -0.13842788, 0.14236987, -0.05378788, 0.015645117, -0.02428756, -0.13994111, 0.2721025, 0.061550736, 0.15905292, -0.03580355, -0.27105433, 0.32286197, 0.1519605, 0.03221648, 0.02708813, 0.023303933]}, "content": "Yeah, you could definitely. The one thing to note here is that you need to have some idea beforehand what you're looking for with topic modeling that isn't necessarily always the case. You know, you have tickets for some software, hundreds of thousands of tickets, and you just want to see what's in there without any guidance. Okay, then it's completely unsupervised. With few shot learning, of course, you can say, okay, I have some idea. I don't necessarily know the entire thing, because otherwise, it's a classification task. But with few shot learning, you can then say, okay, I have some idea. Let's see if we can do some semi supervised few shot learning on top of that. But then again, you have to define those labels very well beforehand. Because if you don't, again, then it becomes difficult. ", "podNum": 28, "speaker": "Maarten Grootendorst"}, {"_additional": {"id": "e2045da2-9fa6-40cc-b1aa-bba61cca99c6", "vector": [0.022600912, -0.28362018, 0.06974054, -0.08740415, -0.016764872, -0.30271867, 0.03156838, 0.10374359, -0.023254164, -0.200533, -0.03066785, 0.13245735, -0.05972179, -0.23541535, 0.24952197, -0.13320877, 0.06507832, -0.3080855, -0.45700356, 0.26455036, -0.494392, -0.11389839, 0.13045515, 0.08318873, 0.006206423, 0.07012768, 0.33538973, 0.22738281, -0.33550483, -0.1417197, 0.050638426, 0.2730786, -0.109755434, -0.07007307, -0.02500071, -0.05836652, 0.24864301, 0.08456317, -0.4746018, -0.119864434, -0.25607187, -0.29587367, 0.060548685, 0.41640037, 0.21040732, -0.036584035, 0.19071037, -0.14006853, -0.008054169, 0.087926656, 0.17639871, -0.11719434, 0.08054243, 0.039979845, -0.1304884, 0.25723517, 0.13840865, -0.176188, 0.1198814, 0.11236082, 0.020335883, -0.17056458, -0.35332987, 0.746843, 0.19294421, 0.09174111, 0.1077176, -0.5635891, -0.22498523, 0.23158398, -0.2932117, -0.008434276, 0.03522007, 0.082393035, -0.20431976, -0.08315583, 0.16113383, -0.024540035, 0.011640797, -0.36058766, 0.2174485, -0.026042081, -0.007448189, 0.1042038, 0.12002052, 0.14048465, 0.09289871, -0.064760104, -0.27825332, -0.2914111, -0.41655743, -0.010339601, 0.064697124, 0.1019198, -0.16655836, -0.03575751, 0.13896915, -0.33121422, 0.16021152, 0.43787193, -0.37133712, -0.11382078, -0.14820416, -0.23512612, -0.019406654, -0.34610674, 0.018464256, 0.3159181, -0.067832455, -0.27361324, 0.10516161, 0.03628891, -0.1304344, -0.0021188986, 0.022544602, -0.24120483, -0.38393486, -0.011227205, 0.040122032, -0.24101317, 0.071886495, -0.11397265, 0.08741234, -0.13825037, -0.0027190223, -0.49491876, 0.032232985, 0.22409892, 0.045388483, -0.13174722, 0.21091047, 0.017920105, 0.31223986, 0.3999285, -0.1073195, -0.0046513826, 0.102513626, -0.27123022, -0.21286526, 0.25067267, -0.037827875, 0.098163605, 0.028603695, 0.024489228, -0.388764, 0.30215606, -0.072749294, -0.08887568, -0.024221329, 0.16363066, 0.110870175, -0.004798427, 0.46543294, -0.1392928, 0.33600193, -0.0590481, 0.32464963, 0.116803385, -0.111743174, -0.120723, -0.35053754, 0.007424917, -0.06496827, 0.10112103, -0.257102, -0.15455754, -0.12655155, 0.15279269, 0.049953848, 0.016535405, -0.15472619, 0.004002992, 0.061179332, 0.020020388, -0.12341051, -0.06555384, -0.017869791, 0.27754787, 0.039231032, 0.15545107, -0.11921176, 0.029955536, 0.10006416, 0.08143041, -0.10630695, -0.15758485, 0.025324903, 0.017201621, -0.01213114, -0.14292955, -0.12815298, 0.06811194, -0.43390894, 0.28365618, 0.15383491, -0.09347883, 0.0407328, 0.18750829, 0.34698734, -0.1637191, -0.3686046, -0.073853515, 0.1474606, -0.22975299, -0.013343716, -0.0160104, 0.20117722, -0.023466395, -0.07387477, 0.017089985, 0.05979971, 0.11356603, -0.2582944, 0.2844152, -0.06622467, 0.26612622, -0.16213107, -0.090114176, 0.03478277, -0.1267524, 0.19733009, -0.21814156, -0.23770553, -0.5384568, -0.21962191, -0.22197434, 0.072848134, 0.32999852, -0.054684043, 0.18900752, 0.19096324, 0.015194811, -0.092766374, -0.16665451, 0.15344518, 0.19885762, 0.030359492, -0.55967295, -0.019103674, 0.08261405, -0.08248033, -0.21235776, -0.19270165, -0.027416762, 0.035749685, -0.13149619, -0.023689836, 0.57351655, 0.11180957, 0.21000151, -0.23741291, 0.030477755, -0.46354657, 0.07517083, -0.23742467, 0.061842304, -0.103287995, -0.17213562, 0.02528838, 0.064543754, 0.27240673, -0.2929619, -0.14066286, -0.14669043, -0.2403609, -0.17081395, -0.04042723, 0.5967504, -0.39180875, 0.020181349, -0.13442114, 0.230413, 0.3880453, -0.008946817, -0.06237653, 0.20033094, 0.07022275, 0.12896085, -0.3116451, 0.28758186, -0.0065433457, 0.01479204, -0.061477177, 0.29626852, 0.228491, -0.23155497, 0.18971935, -0.1464051, 0.041385338, -0.20481023, 0.19773865, -0.18923777, -0.07698439, 0.1608238, 0.16814011, -0.06677667, 0.22493643, 0.45639545, 0.2556846, -0.24524228, -0.17020485, 0.0019621402, -0.2451774, 0.11799376, -0.2518549, -0.23919939, -0.040682442, 0.38961315, 0.03402797, -0.067980066, 0.1320837, -0.3162596, -0.25583673, 0.15863767, 0.14530796, 0.074989386, -0.47500646, 0.24164161, 0.041469656, -0.13075855, 0.18713012, -0.039879173, 0.18032221, 0.14015909, -0.070259124, -0.03006834, 0.3199792, 0.23351981, 0.13983747, -0.34838206, 0.3363132, -0.011893228, 0.14923853, 0.11500247, 0.0055750012, 0.4883998, 0.00078831613, 0.07501282, -0.22745371, 0.32838562, 0.11344847, 0.18163523, 0.06320095, 0.2100073, 0.33617717, 0.21206757, 0.048502576, 0.5325243, 0.1137916, -0.075938255, -0.029324088, 0.2388953, -0.13495766, 0.049776774, 0.16121596, 0.17159294, 0.2553264, 0.021154888, 0.5098778, -0.28259218, 0.20029737, -0.018191248, -0.17635202, 0.44313323, -0.18862057, 0.025670175, -0.034609206, 0.08976555, -0.32262993, 0.14128202, 0.18391216, 0.20953785, -0.09380835, 0.006986918, 0.19438243, -0.3319042, -0.049101695, 0.09698227, -0.21467957, 0.38683826, 0.53456163, -0.2527371, 0.26387417, 0.021037221]}, "content": "So, that makes me think, is it similar to HDF5? If you're familiar with that? Yeah. Because I've used HDF5 previously and...", "podNum": 32, "speaker": "Zain Hasan"}, {"_additional": {"id": "e25e0b6a-e22e-48ed-af05-1d71dceed9bd", "vector": [-0.091433495, -0.18210474, -0.036829855, -0.12664014, 0.15070084, -0.08712072, -0.10978579, -0.119848065, 0.012704084, -0.01185937, -0.025019849, 0.15239225, 0.044071775, -0.03025458, 0.17746043, -0.0760805, 0.11632699, -0.03781378, -0.30406785, -0.15449932, -0.20943952, -0.0043922737, 0.1420389, 0.0026763529, -0.07194528, 0.1006232, 0.008560456, 0.006677905, -0.083929114, -0.14248857, -0.026462572, 0.20208034, 0.119411826, -0.058070328, -0.35522097, 0.12903282, 0.067190655, 0.1558401, 0.013036877, 0.011711441, -0.06370862, 0.043074645, 0.048916806, 0.28173852, 0.04473567, 0.033601686, -0.10116152, -0.04812853, -0.14450552, 0.00838026, -0.057573088, 0.099478245, -0.08358061, -0.0042729634, -0.031880427, 0.31854373, 0.17502193, 0.0663145, -0.038523816, -0.10516855, 0.02527051, -0.2002385, -0.3044138, 0.33143687, 0.2429747, -0.11541117, 0.00083787367, -0.053381197, -0.025759056, 0.14986596, -0.0056679454, 0.0404943, -0.09344483, 0.14865573, -0.14128932, -0.028205479, -0.024916153, -0.08630526, 0.21126154, 0.03667853, 0.026029587, -0.04850537, 0.04141046, 0.13465077, 0.02150812, -0.033641573, 0.14405584, -0.050617885, 0.0291952, 0.055853445, -0.11530672, -0.13843375, 0.09913596, -0.000982889, -0.09172483, 0.21616012, 0.1332851, -0.10406018, 0.08185534, 0.12254393, -0.26060155, 0.04272024, -0.088992134, -0.40197086, 0.057110764, -0.4438637, -0.04152365, 0.051640704, 0.07326507, -0.073565185, -0.054285195, 0.04506326, -0.11871831, -0.12714317, -0.028627578, -0.084315255, -0.2003801, 0.009910436, 0.07197655, -0.24654683, 0.08663152, -0.04531811, 0.058794014, 0.052036032, 0.007506132, -0.07690825, -0.061988525, 0.22086571, 0.17018902, -0.17852144, 0.17540345, 0.05952886, 0.16152322, 0.16149819, -0.06787081, -0.094005845, 0.19527729, -0.09001059, -0.07346221, 0.29540065, 0.031938296, 0.11841348, 0.07547231, -0.043956753, -0.17444307, 0.355979, -0.10005249, -0.17706567, 0.080313966, -0.12513538, -0.020831121, -0.07111436, 0.24951021, -0.13617206, 0.1843061, 0.047927685, -0.10849093, 0.07211383, 0.0905839, -0.009644903, -0.19265004, 0.08655836, -0.05269043, 0.0049843993, 0.05097038, -0.19232342, -0.031193472, -0.1699459, 0.14112848, 0.14637849, -0.06042741, -0.10145359, -0.02945572, -0.14614911, -0.022658272, -0.0130966455, -0.26705638, 0.07247264, 0.19101551, 0.20322411, 0.12065461, -0.0027342103, -0.09263262, 0.24271642, -0.1206709, 0.07088008, 0.046859942, -0.00636247, -0.06686665, -0.08927135, -0.114096016, -0.024500228, 0.18024588, 0.24460311, 0.028022096, -0.055676535, 0.21553944, 0.16201457, -0.015226984, -0.075957134, -0.40014014, -0.07358881, -0.06766657, -0.11067693, -0.03378175, -0.11764142, 0.1720549, 0.008638285, -0.03268873, 0.14101923, -0.123216435, -0.019636765, -0.14519542, 0.17430893, 0.17476377, 0.034455176, -0.23222013, 0.08408507, -0.06172069, -0.092444606, -0.058299042, -0.066744395, 0.13815075, -0.46748418, -0.24366534, -0.19589597, -0.000646092, 0.14460729, 0.0077380436, 0.0265763, 0.13591297, 0.082307205, 0.09845476, 0.007945534, -0.11932774, 0.035563353, 0.11822523, -0.041688833, 0.0071102884, 0.013983965, -0.0464383, -0.07031118, 0.05652491, -0.014379934, -0.027811375, 0.18577847, -0.19754414, 0.03336309, -0.023468643, 0.25085163, -0.16709845, 0.023532119, -0.14589176, 0.012872141, -0.14410004, -0.055318404, -0.39568985, 0.29509816, -0.11791566, 0.23989329, 0.23029622, -0.22338559, 0.051043615, -0.007747989, 0.105399236, -0.067419104, -0.026565932, 0.21195492, -0.1727496, 0.06596421, -0.25987738, 0.16775793, -0.051147196, 0.0097037265, 0.05543103, 0.17346312, 0.064266555, -0.1217945, -0.17519876, 0.17851499, 0.08780417, -0.19853187, -0.018699117, 0.28197926, 0.07011779, -0.14663813, -0.04357188, -0.027161283, 0.2261669, -0.041774318, 0.02497214, -0.09014785, -0.05585801, -0.13933259, 0.11255286, 0.076101996, 0.011702273, 0.1411794, 0.11167422, 0.10464631, 0.0553548, -0.21344316, -0.21829137, -0.033524968, -0.12297473, -0.15536964, 0.14725877, 0.09307, 0.11768833, 0.01734577, -0.011121215, 0.012808176, 0.065548144, 0.12773651, -0.09359485, 0.029277723, -0.22676528, 0.10362196, -0.07448539, -0.15464658, -0.072363995, -0.13876353, 0.04571773, 0.21967275, 0.14268476, 0.23696749, 0.053566493, 0.070510544, -0.14913526, -0.12311159, 0.021727536, -0.05423294, -0.17368534, 0.06298908, 0.31834826, 0.19278069, -0.17037886, -0.016327245, -0.22966886, 0.054177407, 0.18323217, 0.24756967, -0.008715796, 0.11504771, 0.015432113, 0.16760366, 0.013376201, 0.43989524, 0.0730499, -0.06347616, 0.06758972, 0.23370776, 0.0077584404, 0.011864769, 0.13784131, 0.019048687, -0.0093196295, -0.1446151, 0.12635857, -0.2831027, 0.13016936, -0.06521402, -0.05762986, 0.52283984, -0.14964932, 0.16027716, -0.07263782, -0.0018021958, -0.11989853, 0.0008852286, -0.02253434, -0.010889748, 0.027406603, 0.07582189, 0.040469002, -0.036738455, 0.0023989063, -0.14315692, -0.03197976, 0.2284644, 0.059425894, 0.1597753, 0.26952973, -0.012368716]}, "content": "Yeah, I would say all of the above and in no particular order. Just sort of start working towards adapting your system to include all of these different items and they all add. They're combinatorial. It makes the output better. Yeah, multi-shot prompting, having examples within the prompt space itself was I think our first iteration. And then going from multi-shot prompting to dynamic prompting where it's just not static examples. They're actually examples that fit that particular task best. And that's, again, that's being pulled from a vector database of known good examples. And we keep on adding to those over time so the capabilities improve. And that's just special prompting. Now of course you were saying about chain of prompt chaining and recursive prompting and you start to get systems that are strange in how they act very human-like. You give a hard question on Maryanne and it might take 28 seconds to find the answer. Why is that? Well, it's because it figured that it didn't quite have enough information. It needed to go back and search some more. So obviously we don't want to tell you exactly how we make the sausage and the seasonings that go into it. But it is a hodgepodge of many different things coming together. Fine tuning is, funnily enough, one of the last things I think we're focusing on right now because we find that the output from the prompting is so good that we'll be able to bootstrap enough examples, good examples, in order to fine tune later on. So maybe a later step. Well, I mean even the context retrieval model we've been fine tuning to match questions and passages from text much more effectively than what you can do when you don't fine tune. So I guess that's one area we've really pushed on that method. But there's always more coming out. And I think that might be where a lot of the improvements are coming from for chat GPT. I'm not sure if it's just the model that was innovated on. I think they also started to include some of these advanced prompting techniques, recursive chain of prompt, chain of thought prompting. And I'm sure a persistent knowledge base. It does respond to, and maybe I'm going a little bit off topic, but it does seem to respond to previous conversation that you had. So there's definitely a potentially like a lookup, vector-based lookup for previous context when it's generating the new answer from it. ", "podNum": 30, "speaker": "Chris Dossman"}, {"_additional": {"id": "e2749229-089c-4a25-b6ff-a3bd89806b74", "vector": [-0.134186, -0.12678865, -0.12311916, -0.21316396, -0.10937888, -0.11934828, 0.12330294, -0.13169907, 0.3766691, -0.09708278, 0.11351187, 0.041352328, 0.11286812, -0.00092125457, 0.1781721, -0.13268715, 0.042291448, 0.090204604, -0.2665713, -0.03667387, 0.0034250617, -0.073953524, 0.14482675, 0.09002253, -0.1412029, 0.13458754, -0.03174133, 0.15243642, -0.068462715, -0.004966594, 0.026044628, 0.16343115, 0.0142626455, -0.14371023, -0.2620428, 0.26664102, -0.04292794, 0.12489185, -0.012669707, -0.044592306, -0.14301421, -0.019789947, -0.0037116087, 0.13423619, 0.011462551, 0.0033972694, -0.03920313, -0.074173875, -0.09285224, -0.1295804, 0.0027556694, 0.040815372, -0.054141156, -0.057575427, -0.016829358, 0.23336364, 0.1343197, 0.059407517, 0.022950917, -0.00090848026, -0.09843765, -0.100425884, -0.30777106, 0.40194374, 0.15190433, 0.020405237, -0.10402574, -0.18432929, -0.15990983, -0.028982759, -0.031029942, -0.18239695, 0.029511519, 0.1088897, 0.051144555, -0.083142266, 0.06765687, 0.06964438, 0.12528469, -0.12370559, 0.114600256, -0.0766853, 0.11700911, 0.18054064, 0.12567647, 0.062202018, 0.20645428, -0.10382019, 0.10876273, -0.043997996, -0.2119934, -0.13067417, 0.17692396, -0.03130941, -3.828796e-05, 0.056582935, 0.0129912365, -0.04046795, -0.05321578, 0.017106323, -0.2162032, 0.27632576, -0.072739735, -0.13004163, 0.17487481, -0.38908783, -0.030502308, -0.11739843, 0.26992533, -0.018900756, -0.16807085, -0.05717302, -0.1463344, 0.07348483, -0.14407027, -0.09276937, -0.043709423, -0.1303479, 0.057425015, -0.07196723, 0.04512575, -0.21172683, -0.09574044, 0.11029704, 0.1102926, -0.035774097, -0.035113137, 0.16185981, 0.12134202, 0.02841809, 0.27343363, -0.097146034, 0.2203358, 0.04249637, -0.17752136, -0.17365223, 0.22631434, -0.09806581, -0.20329973, -0.0066828383, 0.13729638, 0.32624772, -0.08665561, 0.050940074, -0.32384747, 0.14764899, -0.1636184, -0.0155373495, 0.10981568, -0.13817741, -0.014958347, -0.13947143, -0.0065932046, -0.006648614, 0.07975667, -0.0002512204, -0.15293492, 0.10980666, -0.011682283, -0.09992285, -0.044649366, 0.10795256, -0.07380571, 0.064749405, 0.3958971, -0.12724148, -0.09481546, -0.13769072, 0.10794168, 0.02223673, -0.04691877, -0.05643938, 0.027427237, -0.06325863, 0.024733298, -0.12187261, -0.29503998, 0.045771603, 0.2136519, 0.19568656, 0.061761573, 0.011543163, 0.13102844, 0.10800025, -0.08876683, 0.020018958, 0.056531332, -0.06169339, -0.18554881, -0.120938316, -0.025348332, 0.0019543932, 0.15264782, 0.2820187, -0.023428084, -0.08332777, 0.21809998, -0.06034607, -0.012687451, -0.094181865, -0.24195197, -0.008681392, -0.12130312, -0.17609781, -0.10644043, -0.11786314, 0.24222586, 0.040972967, -0.0836879, 0.10434163, -0.0099197375, -0.27023506, -0.14319332, 0.09647538, 0.25533092, -0.0821735, -0.23151956, 0.16893846, -0.10719556, 0.016788648, -0.10637372, -0.054406848, 0.0666525, -0.3642018, -0.3551906, -0.05082585, -0.08047562, 0.01182249, -0.1620608, 0.08742726, 0.3313309, 0.12469621, 0.048337486, 0.14549129, -0.17947938, -0.091916494, -0.0062511954, 0.003396291, 0.15041092, -0.17917596, 0.045827586, 0.15845554, 0.011082798, 0.07384013, 0.057133913, 0.027215537, -0.13905123, 0.2516053, -0.005871579, 0.23340538, -0.056903638, 0.17099494, -0.032937434, -0.032652184, -0.21437405, 0.06667699, -0.22557664, 0.048103206, -0.11666213, 0.10418899, 0.0667702, 0.05679237, -0.13397573, -0.106187254, 0.07219572, 0.08868488, -0.1962288, 0.3277656, -0.15912725, -0.07378967, -0.1282387, -0.011570801, -0.0536899, -0.111112446, 0.23025534, 0.054726966, 0.1253637, -0.062081024, -0.27338326, 0.11240645, 0.032005865, -0.26826766, 0.032124367, 0.25852937, 0.10557557, -0.21088324, 0.0402001, -0.1575986, 0.25161552, -0.07655647, 0.045879543, 0.11179238, 0.15788999, 0.09323792, 0.13297036, 0.14113472, -0.05484455, 0.11020997, 0.2691301, 0.07143604, -0.080497175, -0.20853578, -0.18209435, -0.11394893, -0.09681102, -0.12340292, 0.12307013, 0.045379557, 0.07606589, -0.09480304, -0.020725664, 0.100839086, -0.1420142, 0.15665478, 0.0015787958, 0.21620013, -0.19531892, 0.08110066, -0.14606118, -0.017607225, -0.052645523, -0.15126944, 0.21546625, 0.08383159, -0.11478328, 0.13429166, 0.22478916, -0.21473826, -0.20037359, -0.24384397, 0.0012559879, -0.031158153, -0.05912582, 0.17115885, 0.1373716, 0.31962124, -0.081966005, 0.007943622, -0.11946702, 0.021265296, -0.031598058, 0.0999869, -0.021905392, 0.038904805, -0.070600204, 0.11435464, -0.03190611, 0.45733044, 0.035314802, -0.15582897, -0.010701989, 0.38679263, -0.04348602, 0.17394367, -0.015979694, 0.03593204, -0.100675434, -0.17830944, 0.24273112, -0.18003908, -0.0062156757, -0.23236495, -0.24619156, 0.39971212, 0.22511016, 0.2883539, 0.046050087, -0.17782208, -0.047583487, -0.031099383, 0.12838997, 0.046749398, 0.101814985, 0.06483437, 0.069997, -0.18387264, -0.037473254, 0.0028441697, -0.020043168, 0.36857694, 0.13817455, 0.12859589, 0.29357865, -0.08262406]}, "content": "I want to jump in quickly on this idea of this conversation around not understanding meaning and there's this great paper that went out, it was called climbing towards NLU on meaning and understanding in language models. And the picture is painted like this. There's two people stranded on desert islands, and they communicate with an underwater cord, and an octopus is intercepting the cord. And it learns how to mimic the language such that it could cut it and then talk to the other person, you know, and you don't know it's the octopus or the person. And so that's kind of been like the example of it saying the language models are just mimicking the text, they don't act in it. But I think now what we're seeing with chatGPT, and building on instructGPT and reinforcement learning from human feedback is that it is embodiment because the language model is being given some kind of instruction, like, write this in Shakespearean style. And then it's predicting the tokens, but then it gets that kind of feedback signal. So I think it is now embodied, and I think that kind of idea that it doesn't have meaning or understanding, I think that we're actually moving past that. And I think this reinforcement learning from human feedback idea, I think is being underappreciated. Like, you still see people reacting to chatGPT, like, it's just predicting the next token. Well, it's not. It's also, you know, has humans labeling how well it's following the instructions. And I think that's just a significant difference. ", "podNum": 30, "speaker": "Connor Shorten"}, {"_additional": {"id": "e2c20e91-7463-4c7b-8ecb-8ac98fa84eea", "vector": [-0.17835543, -0.25773355, -0.1514012, -0.20401755, 0.0075219474, -0.2700697, -0.18589199, -0.12956676, 0.027320286, 0.024074573, -0.0009775639, 0.25729805, -0.033074938, 0.11186359, 0.27242288, -0.11424484, 0.086446665, -0.07809625, -0.31350178, -0.044677667, -0.0016270697, -0.24354322, -0.014007273, -0.1412634, -0.0065830685, 0.059319895, 0.025103342, -0.16969475, 0.009780961, -0.02678385, 0.025966292, 0.05892264, 0.084737346, -0.100470975, -0.14533195, 0.20669715, -0.055434205, 0.052284457, -0.0299447, -0.24566989, -0.20201977, -0.020210648, -0.08319827, 0.24932039, -0.0032242187, -0.060698844, -0.09986621, 0.025380155, 0.025930619, 0.09101595, -0.14892468, -0.031752266, -0.10656544, -0.13621268, -0.07454638, 0.23229487, 0.031911563, -0.018596515, 0.040389497, -0.17887953, 0.30280453, -0.07888294, -0.016409082, 0.17405745, 0.28428993, -0.05313772, -0.0011698097, -0.12167697, -0.050132286, 0.09481986, -0.116154395, -0.1257496, -0.18894526, 0.37719238, -0.11130297, 0.022422442, 0.05237754, 0.045973398, 0.13914882, 0.106806025, -0.0052004145, -0.099603005, 0.06970185, 0.09231143, 0.01903829, 0.10261607, 0.03427378, -0.06476031, 0.2728584, -0.07345724, -0.07541521, -0.15125674, 0.15911019, -0.0441144, -0.09719758, 0.016991127, 0.15600926, -0.017246574, 0.013279324, 0.11701896, -0.30717844, -0.02251485, 0.11443715, -0.39019537, 0.13389239, -0.09681721, -0.045860343, 0.009502223, 0.13492319, -0.2174978, 0.051088788, 0.019435903, 0.0013132602, -0.0037092783, -0.011517632, -0.10207901, -0.21515384, 0.054463513, 0.14429471, 2.0575466e-05, -0.042609554, -0.20726252, 0.050438605, -0.010054228, 0.18853746, -0.047216725, -0.14244875, 0.22759059, 0.0037399554, 0.11318586, 0.06407517, 0.005127664, 0.0909481, 0.10825648, 0.02658968, 0.040308982, -0.10154585, 0.019576231, 0.01460633, 0.3229096, 0.008144232, 0.36189038, 0.40036187, -0.004294628, -0.100469574, 0.23861432, -0.16886461, -0.098676436, -0.081575826, -0.057492506, -0.015772182, 0.025454808, 0.16713558, -0.17799525, 0.15180889, 0.0052536326, 0.063085794, -0.01737068, -0.22410388, -0.19514552, -0.08479057, 0.18947211, -0.14492741, 0.0055614887, 0.19037443, -0.15387568, -0.052135516, -0.059185, -0.0783242, 0.11971988, 0.005111882, -0.18806578, -0.0066193417, -0.114092276, 0.11568463, 0.10298477, -0.24138758, -0.11768876, 0.0014302343, 0.26812345, 0.15879805, -0.0007865563, 0.14380404, 0.2241931, 0.069423735, 0.03974213, 0.22890082, 0.11257212, -0.21434948, -0.19745836, 0.11825202, 0.09409686, 0.024009455, 0.1267572, 0.018782679, -0.14123309, 0.2585719, 0.216622, -0.0156679, -0.083587185, -0.18723509, -0.1094927, 0.07626932, -0.071541764, 0.085198626, 0.004006239, 0.026699359, -0.08237305, -0.2290525, 0.13428462, -0.08735521, 0.01481314, -0.04400419, 0.163942, 0.062306475, -0.24475972, -0.078197956, -0.10321007, -0.26493222, 0.097199544, -0.0994089, 0.00684883, 0.11629365, -0.25735354, -0.3075938, -0.34817347, -0.04256542, 0.120100215, -0.16054179, -0.01626776, 0.0951374, -0.538521, -0.10640691, 0.028085614, -0.038065776, 0.025228515, 0.14166903, -0.09518273, 0.031034544, 0.13334839, -0.049350746, -0.034798205, -0.0755161, -0.04683972, 0.07555531, 0.22157165, -0.20807655, 0.11782487, 0.11691852, 0.038764812, -0.2403454, -0.029274702, -0.18448345, 0.041159578, -0.27907705, -0.0802014, -0.29344675, -0.051144343, -0.11616359, 0.05481882, 0.2618807, 0.02977703, 0.114363275, 0.07150257, -0.008277726, -0.031469114, -0.24537662, 0.09953121, -0.19659492, 0.047699362, -0.03342005, 0.06656803, 0.04007631, -0.041283324, 0.18741405, 0.09285866, 0.03135518, -0.25670552, -0.2618591, 0.045760524, 0.121619605, -0.045545302, -0.10506598, 0.3120357, 0.03237763, -0.08210523, -0.014179917, 0.12431179, 0.060708445, -0.21802764, 0.08732554, 0.097570024, -0.31274125, -0.22985168, 0.009434976, 0.037857212, 0.1490653, 0.23391604, 0.17905043, 0.1779075, 0.26200038, -0.067533955, -0.06865532, -0.06829432, 0.008678926, -0.055211537, 0.23950489, 0.17341964, 0.06693338, 0.0387095, 0.028554535, 0.101947665, -0.05472467, -0.026026998, -0.077789016, 0.14461203, -0.27391383, 0.0851256, 0.015359694, 0.10111252, 0.007695773, -0.0402129, -0.0021349117, 0.11906068, -0.061373644, 0.07469801, 0.016020719, 0.18431485, -0.0737979, -0.022602897, 0.11316135, -0.054620467, -0.18326944, 0.20535776, 0.12743296, 0.21844408, 0.010001248, 0.04725551, -0.11295676, 0.10651626, 0.1271757, 0.039266877, -0.068469055, 0.25096726, -0.0003670506, 0.02314845, 0.04604486, 0.19803281, 0.10418403, 0.115550265, -0.14356926, 0.2232097, 0.051474087, 0.10282048, 0.38274273, 0.015776753, 0.028182868, 0.023206387, -0.07301593, -0.19294563, 0.15532896, 0.0036385506, -0.23817866, 0.18839952, -0.2048574, 0.011336666, -0.09329451, -0.2776341, 0.0018350917, 0.13478291, -0.042181037, -0.0036126613, 0.041206945, 0.026556665, 0.17470554, -0.09418767, -0.10634036, -0.19375147, -0.051695358, 0.4130695, 0.22655392, 0.07012636, 0.12541683, 0.024589892]}, "content": "Yeah, I think that we're trying to think of, especially with what we're trying to do with our You Imagine suite, which is like an image generator from natural text, something that is very popular as of this year, that trying to kind of create like this very multimodal search experience across images and audio and text is going to be important. And being able to handle having one system that kind of handles vectors in a very vector-first way instead of trying to like kludge a bunch of systems together, which is I think how traditionally you would have done this. And I think that especially with what Weaviate is doing with the hybrid search, that I think is going to be a really big player for a lot of people, even if they don't even know it yet. Because people who are operating these search indices right now know that you basically need two different systems, right? There's no system that does lexical search and semantic search together. You have to do that work. And it's not simple code to write. It is hugely complex to kind of figure out how to run those systems in parallel and how to stitch all of the data coming back together and how to rank it all very holistically. Having a system that supports hybrid search at its core is really important. And so just something as far as like architecture simplicity in the search space is really important, especially from a maintenance perspective.", "podNum": 32, "speaker": "Sam Bean"}, {"_additional": {"id": "e32fc85f-20a5-450b-a199-b184f0f2a1fb", "vector": [0.15390928, 0.008675168, -0.062811084, -0.2562927, -0.15518059, -0.22572912, 0.2621387, 0.19733761, -0.052461505, -0.34491822, 0.10634738, -0.031779084, -0.13210082, -0.09263977, -0.1362303, -0.20193602, 0.43827268, -0.31434467, -0.3501394, -0.26784533, -0.341135, -0.3086314, 0.08100842, 0.28283593, -0.02071163, 0.1048604, -0.08890767, 0.26689002, -0.006177125, -0.4083685, 0.04266457, -0.04183057, 0.28038928, -0.17316781, -0.2839807, 0.41658235, -0.061079692, -0.10871738, -0.07028112, -0.08039141, -0.008536513, -0.4598887, -0.06597775, 0.14458494, 0.052412424, -0.19590695, 0.12906261, -0.013718039, 0.2834376, 0.15145491, 0.0362545, -0.17497845, 0.1367998, -0.34204772, 0.060659926, 0.24658208, 0.16253942, -0.21319194, 0.027706638, -0.0726766, 0.11824096, 0.01251854, -0.44515908, 0.6593998, 0.03138329, -0.22810335, 0.030864729, 0.0074038305, -0.44229722, 0.14096862, -0.0519176, -0.045690496, 0.21221328, 0.015346547, 0.03892556, 0.04332648, -0.052187383, -0.28034052, -0.23966695, -0.1439072, 0.40253136, -0.41927826, -0.30082497, -0.31442025, 0.41475216, -0.08800437, -0.09251153, -0.12976952, -0.14910802, -0.24355733, -0.23541446, 0.29838204, -0.115895696, -0.03664498, 0.11252013, 0.3102784, -0.06952078, -0.10030824, -0.1337072, 0.6589006, -0.06517611, 0.00249436, 0.25487438, -0.0645608, -0.059865016, 0.040890872, 0.061555605, 0.20169665, -0.16590033, -0.2644095, -0.041935354, -0.09677056, -0.08771493, -0.048767433, 0.23529601, 0.23757069, -0.058020238, 0.108996846, 0.35474825, -0.10779208, 0.089164, 0.10020938, 0.2908841, 0.25011334, -0.04058705, -0.124151684, 0.33348748, 0.2523481, -0.1781748, 0.068498395, -0.082545646, 0.021579022, 0.194435, 0.42157874, -0.24943484, -0.31210795, -0.16869551, 0.05271249, 0.080400884, 0.16206452, 0.0871942, 0.034119934, 0.3756065, -0.10174307, -0.16648453, 0.28449318, -0.021257252, 0.10218251, 0.13051848, 0.13612998, -0.06046578, 0.44347218, 0.28386274, 0.24791612, 0.3242304, 0.10717294, 0.10551504, 0.31230026, -0.1793762, 0.012752705, -0.06670767, -0.027796855, -0.12833063, 0.037797946, 0.038226724, -0.34376857, 0.04438402, 0.24945009, -0.04798017, -0.06571517, -0.30286476, -0.12555543, -0.21028936, 0.22773695, 0.051215995, -0.096003175, 0.43044344, -0.0717864, 0.034326106, 0.030160272, -0.17010282, -0.010365997, 0.2057877, 0.26146868, -0.061123475, 0.1295753, 0.0326222, -0.22466333, -0.031382013, 0.06378538, -0.11027008, -0.20951809, -0.21974611, 0.07877078, 0.25543112, 0.22871745, 0.12166879, -0.16220234, -0.23691833, -0.052056804, -0.15844421, -0.43166772, 0.40481946, -0.110962786, 0.15294902, 0.0052625635, 0.20631756, 0.14488152, -0.075056344, 0.13092922, 0.13097388, -0.13784319, 0.10547179, 0.38847408, 0.17265397, 0.061740056, -0.30437458, 0.30203933, -0.14694774, -0.12528808, 0.51677674, 0.015419148, -0.022108912, -0.5072072, 0.06560477, -0.16372961, 0.2343492, 0.09379077, 0.38410714, -0.030312417, -0.023854174, 0.29820737, -0.0011423925, -0.09008788, -0.13189964, 0.06374099, 0.10145644, -0.23129429, -0.13351037, -0.012330726, -0.09665371, -0.08387903, 0.09211049, 0.040919553, 0.56661576, 0.1967719, -0.1639442, 0.09095549, -0.51263505, 0.41356027, -0.23837668, 0.09729624, -0.31221136, -0.0061405315, -0.35116622, 0.12932603, -0.2702254, -0.18208832, -0.081360824, 0.5024371, 0.20447052, -0.30715656, -0.36230835, -0.22228064, -0.15649787, -0.17291391, -0.36298108, 0.48088446, -0.09532825, -0.08050136, -0.33362174, -0.16983162, -0.074082606, -0.32737717, -0.25018796, 0.17430264, -0.2787036, -0.20638536, -0.20441611, 0.022392623, 0.24962717, -0.21490777, 0.19975793, 0.2053587, -0.06584554, -0.022721121, -0.12622462, 0.26421392, 0.17400569, -0.06370685, -0.15849525, 0.29868454, -0.42417672, 0.43654028, -0.1411792, -0.06797102, -0.43012953, 0.42466736, 0.1806361, 0.048004795, -0.17053138, 0.056036413, 0.08074032, 0.1320987, -0.29108885, -0.20919655, -0.15182795, 0.4342061, 0.2553791, -0.03723228, 0.26999643, -0.14599614, 0.094967045, 0.11533886, 0.15219378, 0.11430287, -0.16035083, 0.036461562, 0.20164414, -0.24923728, 0.030944958, 0.3938317, -0.09841022, 0.064371325, -0.10863627, 0.0058092675, -0.2371914, 0.05656755, -0.44006142, -0.10479515, -0.08618734, 0.06080356, -0.006730309, 0.13849278, 0.3981643, 0.27318147, -0.18483788, 0.30880657, -0.18747747, 0.03548864, 0.017699696, 0.26300144, 0.22965817, -0.30944118, -0.017136442, -0.043050945, 0.1815371, 0.20800638, -0.08486276, 0.09981466, -0.3058113, 0.16123588, -0.15890934, 0.0559691, 0.3932617, -0.09845892, -0.36073172, -0.22167103, 0.09527853, -0.31539196, 0.17834164, 0.23704167, -0.033341404, 0.3580589, 0.061693594, 0.17173256, 0.11406633, -0.08645306, -0.13014269, 0.36044356, -0.090060614, -0.1699518, -0.09713289, -0.033841964, 0.16742168, -0.12351742, -0.012771, 0.07461706, 0.053658772, 0.24126764, 0.5625801, -0.16751714, -0.1520626, 0.06603312]}, "content": "Awesome. I think this release is just so special because, you know, we all got together in Italy and these having everyone in the SeMI Technologies team in the same room as we're up on the whiteboard with the slides and presenting these new features. Etienne, can you tell us about your experience with that? ", "podNum": 31, "speaker": "Connor Shorten"}, {"_additional": {"id": "e60134aa-5a41-4363-97c1-1eaa2329fc27", "vector": [0.1391405, 0.022452658, 0.5030704, -0.21953553, -0.23123129, -0.3579007, 0.746387, 0.059413284, -0.29403365, -0.19721532, 0.041184433, -0.26577142, 0.090235524, -0.21576308, -0.0032505393, 0.005746567, -0.03935206, -0.6529506, -1.3411366, -0.26672736, -0.7496247, -0.05527426, 0.42999962, 0.23167188, 0.10009938, 0.1240262, 0.13094151, 0.5075001, -0.33473873, -0.38708866, -0.18822813, -0.3418258, 0.32730386, -0.106137276, -0.04913768, 0.6111023, 0.10499471, -0.020792982, -0.23831798, -0.0978779, 0.010836661, 0.00562493, -0.17616473, -0.009437561, 0.23745877, -0.13494723, -0.067035384, -0.0144913895, 0.26268938, 0.123247065, 0.16830063, -0.16804396, 0.1902002, 0.17864831, 0.30248126, 0.48539063, 0.02102565, -0.1776085, 0.31963128, -0.077262335, -0.27423748, 0.018718736, -0.14505677, 1.2853904, 0.0090032695, -0.11498719, -0.07238159, 0.2638615, -0.59049964, 0.42701963, -0.41217974, 0.417465, 0.27003282, 0.2856725, 0.05963419, -0.0074963295, -0.012802186, -0.34727308, 0.11240175, 0.21295805, 0.10538695, -0.21453898, -0.042028885, -0.5064804, 0.49051812, -0.036127787, -0.109974205, 0.23787875, -0.25432304, -0.56463104, -0.8719931, 0.7751042, 0.3678185, 0.1661831, 0.17910182, 0.14046513, 0.12236598, -0.43555847, -0.4801496, 0.8997653, 0.031044006, -0.21707372, 0.7491617, 0.19711626, 0.0708372, 0.026241919, -0.36202514, 0.3457261, 0.17642955, -0.23872127, 0.0079764025, -0.115480565, -0.20631628, 0.030321404, 0.17756031, -0.017889336, 0.0035523127, 0.049572285, 0.3053254, -0.59475136, -0.06997331, 0.28729498, 0.03400838, 0.17258315, -0.06257279, -0.38127717, 0.8794157, 0.30988613, -0.15916567, 0.17219734, -0.11140243, 0.4928956, -0.32835636, 0.25670126, -0.28812927, -0.35971153, 0.14462774, -0.0048450925, 0.42931572, -0.13401286, 0.037586022, 0.031318787, 0.04553421, 0.19972043, -0.0643465, 0.40437746, -0.17849731, 0.18232201, 0.15969239, -0.019118031, -0.0949085, 0.42348218, 0.2784245, 0.30869916, 0.27286616, 0.21235073, 0.45927835, 0.13286832, 0.15068917, -0.13644321, 0.2478017, 0.18345511, 0.20124377, -0.5116094, -0.24095714, 0.34837675, 0.04932831, 0.2202423, -0.19143319, 0.22980006, -0.102055095, -0.012911816, 0.1278743, 0.1752543, 0.049892176, 0.07190979, 0.4366746, 0.41126063, -0.14680217, 0.07247168, -0.0078002214, -0.041994203, -0.33069432, 0.09887879, -0.40012026, 0.006843932, -0.46464667, -0.2791313, -0.50992113, -0.23480308, -0.11929813, -0.28065124, -0.31028652, -0.05332605, -0.10262046, -0.30006737, -0.08411706, -0.106795944, 0.11920053, -0.25148746, -0.4470196, -0.23535846, 0.18537545, -0.36624542, 0.4782432, -0.29176474, 0.4475511, 0.23779629, 0.55096096, 0.60475844, -0.26075882, -0.29336506, 0.33641064, -0.39558926, 0.17941041, 0.055729944, -0.18956636, 0.66561234, 0.05988534, -0.05266553, 0.4616029, -0.18051231, -0.6285765, -0.60577536, 0.61441183, -0.25452057, -0.056767795, 0.19230165, 0.22987193, -0.153029, 0.06740538, 0.39933977, -0.055212066, 0.4073772, -0.0016223391, 0.16674654, 0.24334286, 0.09324869, 0.40109074, 0.5105822, 0.043455675, 0.026760837, 0.14315452, 0.5525655, 0.26954755, 0.5787792, -0.504183, 0.6354564, -0.5520529, 0.2324901, 0.09072664, 0.15273884, -0.28898418, 0.08826355, -0.4545684, -0.23839182, -0.5149258, -0.3692056, -0.045348357, 0.43077493, 0.52548206, -0.3717575, -0.20422405, -0.22791553, -0.025055572, -0.52062315, -0.3889413, 0.6313598, -0.23683287, -0.08173733, -0.07095571, 0.10018603, -0.679554, -0.48387513, -0.23853622, -0.044086445, 0.22997765, 0.06784461, -0.008661951, 0.5790733, -0.47976926, -0.15695444, 0.186639, -0.051004577, 0.17374057, -0.12042912, 0.13565756, 0.5483991, -0.3120377, -0.039088868, -0.013414075, 0.23188019, -0.32209837, -0.23059945, -0.031075576, -0.34872195, -0.83385104, 0.1600607, 0.32373476, 0.41558453, 0.15644987, -0.21489368, -0.10665283, 0.130489, 0.5439013, -0.13028839, -0.29404727, 0.33146036, -0.10075528, -0.29307792, 0.102855295, 0.11627128, 0.06347099, 0.19702744, 0.2177998, -0.20094354, -0.055344354, -0.06658443, -0.16928117, -0.22677928, -0.049226526, 0.30188176, -0.3735963, -0.009672116, -0.18810785, 0.38189283, 0.2396922, -0.07514946, -0.47540268, 0.5549417, 0.3361361, 0.2064475, 0.1841414, -0.29848382, 0.31403056, 0.07007801, -0.57275456, 0.027412703, -0.43519226, -0.014214094, -0.10514686, -0.13794912, 0.054969817, -0.24336036, 0.5366024, -0.01896471, 0.45374596, -0.007989998, 0.096056364, -0.01460284, -0.25253952, 0.23270313, -0.84437776, 0.116217025, 0.0387128, -0.18784206, 0.035740107, -0.37901726, 0.13783194, -0.45406875, -0.19338459, 0.0019378687, -0.1817311, -0.08603898, -0.17449725, 0.040697586, 0.48103523, -0.3780626, -0.30564174, 0.038325008, 0.013968766, -0.37796342, -0.20681156, 0.05556418, 0.09404507, -0.40936518, 0.0055114776, 0.14910065, -0.31629452, 0.19709766, 0.034110736, 0.024996335, 0.19805235, 0.37779883]}, "content": "Hey, everyone. ", "podNum": 32, "speaker": "Zain Hasan"}, {"_additional": {"id": "e6023723-0e76-441f-8abb-c4ba9b570711", "vector": [-0.19489051, -0.10907107, -0.098050736, -0.19468537, -0.10929393, -0.106904335, -0.025577556, 0.006021783, 0.22390456, 0.013701408, -0.08262186, 0.1587698, 0.1441301, 0.026821809, 0.06118679, -0.049215056, -0.02173094, -0.06799963, -0.35307515, -0.0032907454, -0.088326715, -0.049243975, -0.044024464, 0.033579234, 0.08273794, 0.0055487426, -0.09576678, 0.056929078, -0.152831, -0.110294156, 0.04228806, 0.26327094, 0.053001497, 0.039680015, -0.15090756, 0.10981824, -0.01546339, 0.03563583, -0.04066199, 0.14344166, -0.014207164, -0.10788212, -0.05506308, 0.16792044, 0.13237505, -0.13886489, -0.19204526, 0.003507541, -0.038905587, 0.14490616, -0.050357755, 0.05074886, -0.06790329, 0.026332015, -0.12930574, 0.1682489, 0.088363655, -0.17317794, -0.029166875, -0.07836472, -0.062185667, -0.109982796, -0.1375815, 0.2113163, 0.26102048, -0.076337524, -0.019530557, -0.041565035, -0.11208285, 0.13178898, -0.07177341, -0.110096045, -0.05719525, 0.14144513, -0.04167172, 0.069059186, -0.034848783, 0.015338792, 0.096137285, -0.04416418, 0.07335579, -0.07030065, 0.07978629, 0.052676413, 0.058461413, 0.005010098, 0.17853373, 0.04476195, 0.15239455, 0.03381308, -0.15483081, 0.025890203, 0.100206524, -0.06347179, 0.008108072, 0.20834576, 0.0039634304, -0.29553926, 0.19343276, 0.08165638, -0.22515206, 0.17422742, 0.038454596, -0.54500693, 0.009318915, -0.3586045, -0.015482301, 0.03462852, 0.103931114, -0.16118251, -0.078846954, 0.01894008, 0.111920714, -0.21430026, -0.090826586, -0.06411017, 0.0077979835, 0.026466023, 0.20560266, -0.2579006, 0.014792941, 0.03837012, 0.06577191, 0.10591648, -0.02210862, 0.061459485, 0.03717539, 0.1895429, 0.09846453, -0.018386865, 0.24023065, -0.02582828, 0.13867539, 0.061257742, -0.09513691, -0.15546651, 0.040483933, -0.18513852, -0.14129992, 0.1519312, 0.18059158, 0.10489318, 0.042895224, -0.025682498, -0.22627488, 0.4343277, -0.18608624, -0.0022436788, 0.13106078, -0.17677243, -0.005805575, 0.018652149, 0.17648114, -0.042396512, 0.07210436, -0.016479906, 0.0642127, 0.09306829, -0.02899009, 0.017378487, -0.1993698, -0.04365171, -0.045125198, 0.061265945, 0.2498086, -0.014158717, 0.03085292, 0.03466695, -0.0806421, 0.09287241, 0.088377506, -0.04050685, -0.15147352, 0.06046242, -0.07475156, -0.033108857, -0.15194736, -0.015316478, 0.027570369, 0.10115326, -0.027296131, 0.045307916, 0.15957107, 0.1261764, -0.15398334, -0.041586548, 0.015725642, -0.085020274, -0.10697803, -0.0004133494, -0.13357843, 0.0061183055, 0.041421596, 0.20142525, -0.117122084, -0.13196366, 0.26285142, 0.18597046, -0.08554502, 0.013797444, -0.23459545, -0.19119659, -0.093235016, -0.10892892, 0.021395681, 0.010812681, 0.24185465, -0.011898764, -0.14394741, 0.11340404, 0.06953048, -0.12964803, -0.0093333, 0.19521636, 0.1436579, 0.016434975, -0.29370132, -0.07344183, -0.17790866, 0.034595355, -0.048875917, -0.11281066, 0.028012477, -0.3900799, -0.42713162, -0.013031796, -0.12755074, 0.1592883, 0.13036472, 0.057669476, 0.1307841, -0.12566572, 0.12363234, 0.16365333, -0.0108457655, -0.07062711, 0.03599498, -0.051620938, -0.049567044, -0.12034145, -0.08382854, -0.090846725, -0.09449112, 0.057023887, -0.07410962, 0.2463875, -0.11572233, 0.24146801, -0.04160497, 0.07498833, -0.10251753, -0.11397362, 0.081375875, 0.05416384, -0.07547247, -0.15868007, -0.36377496, 0.1697506, -0.044656858, 0.18715735, 0.34816873, -0.25589296, 0.026000686, 0.0518689, 0.14109278, -0.04367106, 0.032945875, 0.119432755, -0.1305252, -0.13103515, -0.11606307, 0.18429361, 0.15262532, -0.027919255, 0.053938497, 0.11699259, -0.11539793, -0.060827922, -0.280021, -0.0642757, 0.08512244, -0.114592664, -0.1222281, 0.14498082, -0.07939642, -0.13444164, 0.14844312, 0.18666315, 0.011480006, -0.16585205, 0.09960005, -0.0545841, -0.13934724, 0.09816034, 0.038451307, -0.013877609, 0.031869948, 0.20210753, 0.2616082, 0.025629701, -0.048852347, 0.02452745, -0.07366497, -0.01208902, -0.08401572, -0.01456025, 0.15545367, 0.19710597, 0.2204401, -0.11502249, 0.15094689, -0.08817107, -0.10154955, 0.1981361, -0.08761459, -0.010721251, -0.3569696, 0.11127136, -0.06498543, -0.043002583, 0.0656584, -0.041842643, 0.044906203, 0.32331276, 0.022226112, 0.24152303, 0.006675984, 0.071750075, -0.041184302, -0.004756816, 0.07073834, 0.05746665, -0.22425832, 0.13048378, 0.24591957, 0.098974556, -0.038703933, 0.12411203, -0.12759742, 0.08247832, 0.019996239, 0.21358491, 0.04632585, -0.0657656, 0.115965694, 0.09116936, -0.0006123619, 0.3465942, -0.07302764, -0.022333233, -0.031156974, 0.24244429, -0.16138558, 0.05014732, 0.21428056, 0.067323714, -0.08449224, -0.049428806, 0.09350772, -0.22073379, 0.073288366, 0.016112229, -0.20274891, 0.41423455, -0.03417962, 0.056348577, -0.08838271, -0.18637158, 0.017619813, 0.03240964, -0.05091652, -0.08971706, 0.13489337, 0.0018896894, 0.03253908, -0.0033269904, -0.038977895, -0.13816692, -0.0738695, 0.10200136, 0.20085712, 0.010609628, 0.18043737, 0.047816698]}, "content": "There's a lot that I want to unpack and I do think this, the creativity is kind of like a characteristic of compositional generalization and novel. But I want to just kind of tell you about one other idea that relates to how you had chat GPT come up with the title for your blog posts. And so I want to credit Bob van Luijt and Jerry Liu, the creator of GPT index. They included me on this call where they were, you know, hashing out their understanding of the GPT index top level indexing. And I just think this idea is so profound on how we use chatGPT. And it's the idea of when we search and we get like 15 results, as you mentioned, we need to like parse through the result. And so like one thinking was like, how about we use a crossing, like a high capacity cross encoder, which is like going to be another, like, let's say it'd be like maybe like an 80 million parameter transformer. Their paper is where they use like big T5 models, like billion parameter T5 models to re-rank. And there's like this paper where you have the density on yes, no. like query, and then you put the query document, document, and then yes, no. And you re-rank with that and you use high capacity models, similar to log prop, that kind of idea. But so this idea of like, how do we parse through a bunch of results? And then another idea was like, okay, well maybe we use a question answering model and we'll re-rank it based on the confidence of the extractive question answering model. And we'll try to calibrate the question answering model to demonstrate uncertainty, maybe Bayesian networks, something like that. But this new idea of having GPT summarize the results by having the original question and then saying, please summarize these results. You'll receive it one by one. And then it receives it one by one, updates its summary. Maybe as you mentioned, like you would want to have the reference. It could maybe say like, oh, and also please like, you know, keep a queue of the most influential results as you've been parsing through it. And it's like ability to reason and do this, I've been playing around with this a little bit, I think is just super profound. And that, so that kind of summarization across results, what do you think of that idea? Because I am mind blown by it. ", "podNum": 34, "speaker": "Connor"}, {"_additional": {"id": "e6047616-0ce8-4a43-a28c-a256d2dfb835", "vector": [0.23506, -0.21274047, 0.005374712, 0.06939139, 0.024391351, 0.052589823, -0.0217749, 0.10292865, -0.24672718, -0.08657573, -0.3107211, 0.11556504, 0.08001532, -0.10379674, 0.19256175, 0.00094052556, 0.30694604, -0.18675503, -0.25244847, -0.11780636, -0.4893492, 0.04013611, 0.053527523, 0.12621729, -0.0972243, 0.11193569, -0.02160039, 0.11019324, -0.23564844, -0.24897313, -0.16013552, 0.012829207, -0.11785506, -0.13990605, -0.09838483, 0.19636385, 0.2701413, 0.13761032, -0.031147037, 0.16750233, 0.046417713, -0.4195408, -0.104940675, 0.10368377, 0.12155672, -0.039393697, 0.110284306, -0.11862604, -0.05336232, 0.32326686, -0.012124861, 0.032842547, 0.05290516, 0.07423606, -0.10159179, 0.41660625, 0.07934956, -0.07396636, 0.07901089, 0.025970507, -0.02385413, -0.28524053, -0.21077351, 0.4367931, 0.25988048, -0.2724868, 0.044061042, -0.009773895, -0.2026426, 0.335387, -0.29563147, -0.025214547, 0.13125594, 0.014248392, 0.082278475, 0.010931462, -0.020852227, -0.17590868, 0.14477947, -0.272413, 0.08772018, -0.37731707, 0.022666788, 0.09076996, 0.16253562, -0.009159103, 0.090464525, -0.0120112505, -0.1173982, -0.21616554, -0.3339784, 0.17046055, 0.15222417, 0.018391434, -0.06508406, -0.110192515, -0.025886666, -0.086777225, -0.08192238, 0.4312466, -0.1393897, 0.08704056, -0.025412465, -0.58149415, 0.014618358, -0.3258385, -0.07218494, 0.18295476, 0.024737285, -0.11382842, 0.17696255, 0.0044593634, -0.13773958, -0.17691739, 0.0029032663, 0.19847286, -0.25435784, -0.12084265, 0.366405, -0.26498204, 0.07670869, -0.02644009, 0.003971678, 0.1285927, -0.2094897, -0.277695, 0.28679496, 0.24817407, 0.18489946, -0.06151227, -0.057598136, 0.04691755, 0.06784929, 0.18268779, -0.38696015, -0.13616712, 0.3250093, -0.108340204, 0.22703855, -0.063130915, -0.15592375, 0.28904235, 0.1884138, -0.078585505, -0.28960112, 0.28612217, -0.035135724, -0.068580136, 0.030934975, -0.004424882, -0.20254736, 0.25843328, 0.45510155, -0.086597696, 0.1661121, 0.12250781, -0.016619835, 0.09446587, 0.21100493, -0.117826685, -0.10319638, 0.058688067, 0.037659533, -0.16990902, -0.21900721, -0.22790983, 0.032455407, 0.08069109, -0.051873434, 0.069527104, -0.04978973, 0.015393058, 0.15564582, 0.14067206, -0.04739067, 0.16572015, 0.055066667, -0.038289092, 0.070959985, 0.13432054, 0.002244462, -0.023670692, 0.06461175, -0.02344031, -0.29523355, -0.26989964, -0.03653232, 0.0399026, -0.04257941, -0.14222506, -0.32567316, -0.15304366, -0.16470341, 0.33240992, 0.12376483, -0.02527817, 0.07026285, 0.2077491, 0.10913243, 0.036451757, -0.12586981, -0.20395966, 0.11144833, -0.11356787, 0.36117402, -0.21613228, 0.020198714, 0.07638572, 0.14762911, -0.024929093, -0.018434715, -0.1153751, -0.110440776, 0.044438675, 0.1862976, -0.1171865, -0.22062445, 0.21354523, -0.1717687, -0.0010505691, 0.024418557, -0.0296812, -0.038197827, -0.4955164, -0.21165411, -0.24751477, -0.2052211, 0.50307864, 0.13649407, 0.15213995, 0.1136302, 0.07562812, -0.072012566, 0.12487626, -0.14806826, 0.030741066, -0.039910506, -0.16502444, -0.18728647, -0.066430464, -0.14135975, 0.09299776, -0.06751697, 0.09558809, 0.07079718, 0.26720434, -0.21353173, 0.4139699, -0.025065195, 0.3125129, -0.16514936, 0.056260925, -0.47008166, 0.04094533, -0.26644024, -0.042266108, -0.5746167, -0.07017387, 0.10059466, 0.27616626, 0.2667546, -0.6143478, -0.08876483, 0.07673754, 0.15459995, -0.1569805, -0.2154243, 0.31746736, -0.1730668, 0.1549209, -0.23024574, 0.30151168, -0.2299542, 0.0240428, -0.03197909, -0.006167999, 0.09749979, -0.12080385, -0.24050908, 0.18459907, 0.007691282, -0.014752543, -0.10478501, 0.36871335, -0.15446796, -0.15068401, 0.19695374, 0.3135595, 0.062630646, -0.23389336, 0.041137714, 0.19907422, -0.16949861, 0.16014847, -0.0547626, 0.092688695, -0.1820316, 0.32683903, -0.10074028, 0.17710976, 0.13035592, -0.08323778, -0.13757923, 0.017992325, -0.34837675, -0.02537356, 0.039569825, 0.14588705, -0.0852147, 0.3012995, -0.18499629, -0.22350442, -0.15092564, -0.020588841, 0.033078488, -0.11829553, -0.38922465, 0.052313887, -0.2708163, -0.18253233, 0.16026199, 0.111363314, 0.075120226, 0.21004589, -0.1441568, 0.1937207, 0.25274056, 0.091452524, -0.022717763, -0.027843187, 0.14060149, -0.16722181, -0.2073135, -0.04953581, 0.45149225, 0.13674235, -0.020419413, 0.25085723, -0.23417608, 0.028988343, 0.31264204, 0.21736512, 0.12622401, 0.09889181, 0.17715752, 0.11488899, 0.2910041, 0.62469363, 0.07892676, 0.09378181, 0.1905173, 0.36464605, -0.014278911, -0.12385645, 0.48950642, -0.13860777, 0.02130475, -0.15530768, 0.056961607, -0.10260029, 0.008548292, 0.12111576, 0.054060906, 0.45664087, -0.19946529, -0.093091026, 0.13070661, 0.20386353, 0.011180091, 0.019627795, -0.0982486, -0.052787423, 0.17822081, -0.10060503, 0.10866227, -0.15714842, -0.049348094, -0.1599091, -0.22225681, 0.09892464, 0.450994, 0.04225699, 0.18355098, 0.060108237]}, "content": "Yeah. And it's basically getting better day by day. So another topic that I want to talk about is benchmarks. You're of course famous for the ANN benchmark website. But before we go into that, we talked a bit about what you did at Spotify, but I'm also super curious about what you're doing right now. ", "podNum": 25, "speaker": "Etienne Dilocker"}, {"_additional": {"id": "e6270afe-a9c8-4510-a269-dd3f818a88b1", "vector": [0.10026678, -0.20410538, 0.11432515, -0.16706003, -0.10838158, -0.012515588, 0.13733351, 0.0537905, 0.0656085, -0.048659164, -0.06402075, -0.053106003, -0.0071266997, -0.04428888, 0.23305862, -0.12672238, 0.24206537, -0.28795463, -0.29081693, -0.13361774, -0.16749689, -0.0022295048, 0.0012830759, 0.030891284, -0.0032676887, -0.0685422, -0.014353271, 0.1105855, -0.13364707, -0.17804453, -0.046517335, -0.0036037609, -0.10410288, -0.08128388, -0.036249567, 0.147142, 0.09201271, 0.058073234, -0.044497073, 0.036625456, -0.00032290816, -0.26476958, -0.07350359, 0.15880781, 0.11142845, -0.08206995, 0.04623113, 0.018297402, 0.1485564, 0.28973052, 0.11034986, 0.012111291, 0.11322745, -0.0072339596, -0.0625461, 0.17258194, 0.11247468, -0.04420942, 0.019800063, 0.011685841, 0.19531026, -0.06215725, -0.39442602, 0.49865144, -0.031286705, -0.17039616, 0.022449397, -0.17902915, -0.22105369, 0.31454247, -0.052584995, -0.008096355, 0.20189704, 0.056085255, -0.1636748, 0.06978591, 0.17382386, -0.13098498, 0.008098551, -0.25413752, 0.018270925, -0.149524, 0.13863143, -0.012242279, 0.21355645, -0.1251023, -0.06359769, 0.25705844, -0.031831685, -0.06934597, -0.35977012, 0.17044553, 0.252805, -0.02638977, -0.18726777, 0.15079963, 0.08957405, -0.13593099, -0.03366948, 0.42422235, -0.17368618, 0.07881375, -0.012295842, -0.46600685, -0.0326367, -0.26119035, 0.018869068, 0.11760875, 0.08169443, -0.23889141, -0.044543054, -0.017820254, 0.07198378, 0.016601587, 0.015144261, 0.15369432, -0.16549814, 0.18024884, 0.1814977, -0.34161454, 0.12514149, 0.08697626, 0.041323815, 0.07031079, -0.053432673, -0.25956464, 0.2408377, 0.23503603, 0.023985203, 0.0030324198, -0.023697896, -0.022593455, 0.11995711, 0.24102774, -0.2934697, -0.14815843, -0.005523079, -0.055673514, 0.05885136, -0.06701781, -0.011170489, -0.054141458, 0.20687157, 0.017692946, -0.27615252, 0.14280593, -0.04943103, -0.035537597, 0.004234548, -0.10904023, -0.043645438, 0.2002013, 0.2781862, -0.01982964, 0.14207374, -0.06402943, 0.24965441, 0.12040699, 0.044420272, -0.0268787, -0.1505044, 0.049441308, 0.021873856, -0.05645295, -0.08571039, -0.16524614, 0.0041992315, 0.12231391, -0.0038717513, 0.06504666, -0.1436551, 0.10668183, 0.13647854, -0.035235003, -0.13146436, 0.039652072, 0.03465622, 0.13520648, 0.008801305, 0.12644364, -0.273467, -0.0680456, 0.07369007, 0.20954564, -0.1743714, 0.106489345, -0.07385364, -0.04445256, 0.041222483, -0.22708264, 0.030929236, -0.20674248, -0.39796448, 0.09354621, 0.03127113, -0.0452751, 0.015385238, 0.10223174, -0.10105365, 0.004635302, -0.24887854, -0.19711156, 0.12074375, -0.26526862, 0.29233634, -0.06018628, 0.34229052, -0.0007044848, 0.07883896, 0.02039651, -0.011102275, 0.059067447, 0.039244663, 0.10365707, 0.1420333, -0.19682783, -0.14434785, 0.14209986, -0.3516512, -0.03156774, -0.012850337, -0.22044194, -0.08370958, -0.5108616, -0.12771216, -0.17955393, 0.08833222, 0.1720508, 0.2074994, -0.036078896, 0.10484478, 0.06578885, -0.059997052, 0.062703736, -0.0068989336, -0.05048631, 0.03419838, -0.06593341, -0.113794, 0.108941734, -0.006482571, 0.08762029, 0.090742886, 0.018210191, 0.055393208, 0.3213064, -0.14247349, 0.4117112, -0.14401968, 0.2850302, -0.27078757, -0.03718513, -0.34365582, 0.065426834, -0.21893883, -0.058244843, -0.45278737, 0.13619198, -0.14142293, 0.29259783, 0.4031784, -0.37315267, -0.2397126, -0.11370069, 0.14443019, -0.1849754, -0.14760265, 0.52693206, -0.2078163, 0.034170326, -0.1848092, 0.23653664, -0.025267066, -0.035735995, -0.29597378, 0.09330095, -0.0379044, -0.120071016, -0.2389549, 0.19659317, 0.08193371, -0.27202106, 0.02915891, 0.06428768, -0.1047619, -0.086758845, 0.19483596, 0.098654866, 0.1952173, -0.11776523, -0.06928593, 0.22459425, -0.24096057, 0.10368994, -0.024053657, -0.10668768, -0.18292458, 0.3455731, 0.15570456, 0.1908263, -0.024843419, 0.058252707, -0.104767, -0.012519741, 0.02131728, -0.18346478, -0.03629934, 0.24054348, 0.16606098, 0.06940779, 0.13130426, -0.12893574, 0.06490083, 0.21041675, 0.13234155, 0.012847641, -0.078633204, -0.017085493, 0.16592155, -0.106512584, 0.06244991, 0.055636678, 0.070645384, 0.079719774, 0.011779706, 0.12910347, 0.13934708, 0.05372795, -0.1005443, -0.014078634, 0.07763586, -0.063480124, -0.07773465, -0.014061905, 0.30689526, 0.27205127, -0.1251212, 0.1179063, -0.30097824, 0.018792005, 0.0039495965, 0.26692265, 0.18810064, 0.08357221, 0.13179795, 0.064897634, 0.10019196, 0.18083572, -0.010871598, 0.03216897, -0.08699169, 0.28625098, -0.18673222, -0.12505592, 0.25824922, -0.06386419, -0.05242872, -0.21417063, 0.21053419, -0.43597993, 0.16165173, 0.18061511, -0.066381484, 0.4571278, -0.042829674, 0.07930357, 0.16129893, 0.030595671, -0.15666677, -0.0811791, -0.10171704, -0.12877762, 0.10893221, 0.022247765, 0.12774503, -0.14132625, 0.07539767, -0.03586552, -0.27188456, 0.13358068, 0.2565752, -0.07210072, 0.19569294, -0.12131154]}, "content": "Yeah. Great example of basically need to do whatever is right for your use case. I could imagine search cases where that would be very problematic. Yeah. Thank you so much for joining. I'm looking at the time to see where we're approaching our end. This was super fun, super, super nice to hear. Yeah. Hear about Spotify and Annoy, hear about, yeah, ANN benchmarks, and then of course about modal. So do check out modal. As we heard, you can't register yet, but you can register for the wait list, right? So do that. And check out Weaviate as well. If maybe Eric was the reason you got here and not Weaviate, and if you haven't heard of Weaviate, then check out that as well. Check out our other videos. And yeah, thank you so much for coming. Had a great time. ", "podNum": 25, "speaker": "Etienne Dilocker"}, {"_additional": {"id": "e6fcd021-a1e6-430c-84d1-51a22dbcc860", "vector": [-0.20048015, -0.25494567, -0.22175792, -0.22376382, 0.028527394, -0.18164654, -0.14978285, -0.12373895, -0.11463028, 0.023828467, -0.06273371, 0.16334398, 0.016522273, 0.043129884, 0.23980878, -0.09470335, -0.0075885607, 0.034589823, -0.2850319, -0.080401964, 0.006865441, -0.12496544, -0.104889154, 0.009427048, 0.01935634, -0.057936743, -0.029403333, -0.103685826, 0.09496172, -0.2392805, 0.12724638, 0.04048283, 0.05729771, -0.007685012, -0.1756992, 0.2061826, 0.026502399, 0.06656664, -0.19342269, -0.07001697, -0.09839657, -0.13922147, -0.11388345, 0.16751158, 0.063411154, -0.15729548, 0.00043803826, 0.07039081, 0.0010995343, 0.26553068, 0.056289382, -0.091683365, -0.17742096, -0.12982439, -0.026773397, 0.2289423, 0.093321726, -0.13638502, -0.055496566, -0.08730995, 0.13274068, -0.19164638, -0.12088155, 0.31745803, 0.13434069, -0.23914386, 0.094261855, 0.07564598, -0.020975877, 0.13721308, -0.18833582, -0.08814327, -0.1390712, 0.11123632, -0.10314075, 0.1500526, 0.07627661, 0.010661749, 0.10932942, -0.036727145, 0.100596584, -0.07208118, 0.18380286, -0.009961143, 0.21559854, 0.13029432, -0.010536021, 0.10819617, -0.07500224, -0.10770801, -0.15167342, 0.05669032, 0.08493653, -0.0088990275, -0.21232927, 0.23448853, 0.11059031, -0.059279576, 0.09428419, 0.069741085, -0.20883788, -0.14867172, -0.08841984, -0.2649245, 0.069498554, -0.31790963, 0.019722234, -0.00937173, 0.2001935, -0.18421575, 0.038213935, -0.01148692, -0.076925196, -0.12706397, -0.0055432795, -0.23497562, -0.07967849, -0.058736566, 0.15088809, -0.08866036, 0.049826067, -0.0045491457, 0.11088585, 0.008679724, 0.25915873, -0.08833873, 0.17160057, 0.23432927, 0.11478487, 0.0075145047, 0.22642879, 0.090433896, 0.12167559, 0.27486745, -0.0115965195, -0.07315622, -0.15328106, -0.24554737, -0.13494128, 0.023017332, -0.12455358, 0.32722008, 0.26030788, -0.07551074, -0.054095037, 0.18288219, 0.01637417, -0.038121093, -0.05346265, -0.13695495, 0.0040162615, 0.011986969, 0.2802037, 0.13184658, 0.20745361, 0.105857275, -0.058129158, 0.1439528, 0.089558735, -0.321839, -0.21348219, 0.26934725, -0.065563686, 0.037900046, -0.024698075, -0.124719225, -0.09247807, 0.06920497, -0.0067869294, 0.0659426, -0.14863145, -0.13499463, 0.014385285, -0.094713144, 0.101433605, 0.08660972, -0.1264589, -0.1797655, 0.013048094, 0.2721739, -0.007932927, 0.060197394, 0.1073298, 0.1590478, -0.11367063, -0.0072324295, 0.21377714, -0.0745841, -0.11155876, -0.053478137, 0.091374844, -0.072829485, -0.0022636505, 0.22213419, 0.075178914, -0.2341642, 0.21561712, 0.12540497, -0.1369722, -0.065329954, -0.17915305, -0.06705583, 0.053886134, 0.078276806, 0.18197177, 0.020824041, 0.24648911, 0.03746817, -0.29491875, 0.119696766, -0.054606628, 0.042590886, 0.12429143, 0.14005406, 0.15294117, 0.0010815058, -0.27583274, 0.046293512, -0.12280104, 0.012574835, 0.048748344, -0.10168633, 0.11558717, -0.43177962, -0.06489157, 0.045112547, -0.05903128, 0.037408892, -0.03319559, 0.022890704, 0.07231201, -0.17519185, -0.14170063, 0.14819089, -0.01723505, 0.07783147, 0.12749152, -0.18028285, -0.026317634, 0.09277787, -0.13483165, -0.061580326, 0.040678557, -0.11677271, -0.08839195, 0.32616946, -0.07359625, 0.19250827, -0.053607594, 0.16339825, -0.29258507, -0.11255023, -0.022385139, 0.051551625, -0.14088848, -0.048175745, -0.3521299, 0.042886894, -0.011340885, 0.098723635, 0.34596258, -0.23362178, 0.03788799, 0.026148897, 0.037200034, -0.016528701, -0.1336731, 0.34924474, -0.21505512, -0.090352625, -0.109962516, 0.14793636, 0.03822048, 0.006544438, 0.021479858, -0.03058607, -0.07598235, -0.36642924, -0.14241199, 0.071440354, 0.020947328, -0.083990045, 0.032597274, 0.25416905, -0.049605656, -0.2612613, 0.03609825, 0.056026727, 0.108098865, -0.123187564, -0.0016043596, 0.22368221, -0.15640807, -0.038284246, -0.011777135, -0.0033825808, 0.06256031, 0.24432722, 0.19971395, 0.04460877, 0.058298532, 0.0043207444, 0.033229087, -0.085965544, -0.03981331, -0.11485155, 0.2613322, 0.15479812, 0.34085172, -0.23348325, 0.2799734, 0.027501576, -0.13714834, 0.046444327, -0.013510739, 0.115441, -0.2503758, 0.2820186, 0.111758694, -0.016621957, -0.0148523, -0.062590115, -0.06999747, 0.013622096, -0.036898408, 0.16879886, -0.053900246, 0.13259126, -0.012724271, -0.09299984, 0.052239217, 0.056567203, -0.08755614, 0.19768444, 0.24318549, 0.2971511, -0.027070044, 0.07727488, -0.15027454, 0.07108899, 0.021616168, 0.34085754, 0.049832024, 0.07312947, 0.06422422, -0.11700264, -0.01769469, 0.3509213, 0.11959569, -0.0004204372, -0.07350938, 0.06663011, -0.1214481, 0.026080582, 0.07091577, -0.030673377, -0.12870982, -0.21109797, 0.084218234, -0.24332952, 0.11662268, -0.057134412, -0.16711913, 0.21066803, -0.00913119, 0.09825812, 0.032097727, -0.12223055, -0.15937316, 0.18484329, -0.1113645, -0.038639195, 0.18720338, 0.07694372, 0.08770901, -0.24776855, -0.062374916, -0.07514156, 0.15979746, 0.16062444, -0.027031207, 0.08250425, 0.26035774, -0.1991933]}, "content": "Yeah, sure. So what, so as you might know, and so for the listeners, of course, that Weaviate has a modular ecosystem. So you can use Weaviate standalone to add your data or your embeddings. However, you can also use modules. And the first wave of modules that we had were vectorizers, right? So you have text2vec, for example, or image2vec from different providers. But we're now also introducing these generative modules. So basically what the generative module does is that it does something with the data in your database. And so, for example, if you have a product stored in your Weaviate and you're looking for Adidas shoes for the summer, then now you can also add a task or prompt for the model where you say, okay, present the results as if they were Facebook ads or whatever you want to do with these results or summarize them all together. And I think that is super exciting because if we look at the origin, right, of how vector database and vector search engines have evolved, we started to see this change that the inputs that we were giving as a query, we didn't necessarily have to make 100% match on what was stored. So, for example, if we had stored the Eiffel Towers in Paris, we could locate it by searching for landmarks in France. But now we're going to see the same thing for the output. So we can actually do something based on the output and what we've stored inside the database. So I'm super excited about this. And this will just be a module like any other. So you can just hook it up to Weaviate and press button and you're good to go. ", "podNum": 35, "speaker": "Bob van Luijt"}, {"_additional": {"id": "e7473639-d735-4230-968c-ff74c5b2c58e", "vector": [0.1549147, -0.1568321, 0.032708522, -0.09080362, -0.13630655, -0.045613784, 0.31263116, -0.03848587, 0.22307141, -0.04927088, -0.0016042143, -0.08304944, 0.14673997, -0.0484633, 0.38553706, 0.01930213, 0.077139854, -0.3393456, -0.49824357, -0.16805021, -0.44806954, -0.12420065, 0.21742462, 0.009376372, 0.0019049818, 0.0014066094, 0.08446733, 0.20253457, -0.14493687, -0.12091602, 0.074218355, 0.15578337, -0.020716429, -0.02505286, -0.18813355, 0.13962752, -0.006748408, 0.18884437, -0.115656145, 0.17889048, -0.12427085, -0.4089882, -0.29068962, 0.16417958, 0.16934842, -0.13777052, -0.016308313, -0.036788363, 0.04857498, 0.22284497, 0.04917732, 0.018836647, 0.019710578, 0.14811502, -0.056027323, 0.48860788, -0.016753046, -0.39151713, -0.13078989, 0.15998824, 0.17305076, -0.021147886, -0.54774255, 0.97297025, 0.251419, -0.2569228, -0.050924804, -0.34407076, -0.5593547, 0.5918077, 0.07004702, -0.10331759, 0.30234265, 0.20298345, -0.12440836, -0.24315281, 0.15810889, 0.05128506, -0.06498062, -0.20624729, -0.017674236, -0.2931366, 0.09786105, -0.010840803, 0.120557815, -0.061046813, -0.1797824, 0.10193179, -0.38835278, -0.086996645, -0.5476632, 0.20617855, 0.20057613, 0.026853016, 0.06444544, 0.03408828, 0.072312586, -0.23008609, -0.165598, 0.88517135, -0.4096042, 0.14507015, -0.012985259, -0.32182264, 0.12987354, -0.30024436, -0.22708458, -0.08904475, 0.10327625, -0.18842506, -0.16494761, -0.058214147, -0.24033785, 0.18789136, 0.04700944, 0.09159907, -0.24938865, 0.31946784, 0.20174612, -0.23798186, 0.020115875, 0.013089273, -0.118371375, -0.056800514, -0.09417063, -0.70993596, 0.6278632, 0.06747528, -0.06728307, -0.19385298, -0.14710219, 0.115463965, 0.209078, 0.3595396, -0.33230835, -0.26623538, 0.108776964, 0.07226935, -0.17539306, -0.1363258, 0.05226161, 0.13638994, 0.3057059, 0.22860177, -0.3858029, 0.21863663, -0.14425169, -0.054620665, 0.033807386, -0.04238397, -0.22274886, 0.17931539, 0.32954034, -0.11905039, 0.3825316, -0.10989031, 0.2779759, 0.13386492, 0.23669727, 0.035998404, -0.20953877, 0.17460304, 0.09378756, -0.1763434, -0.2862462, -0.10985189, 0.01830539, 0.21870981, -0.02407646, 0.109590285, -0.31857046, 0.15779626, 0.13497284, 0.27117255, -0.2186328, -0.071369536, 0.0655264, 0.29020834, 0.22181739, 0.1393926, -0.274717, -0.005001658, 0.15472017, 0.055009816, -0.32586277, -0.20630069, -0.26491627, -0.039278526, -0.031807482, -0.41431955, -0.19390894, -0.07468016, -0.3936455, 0.30658796, 0.18949513, -0.12967242, 0.29166487, 0.17619787, 0.09776646, 0.09777298, -0.61362654, -0.37545085, 0.081653476, -0.45245802, 0.31201446, -0.12476017, 0.46882784, 0.06996378, 0.24885242, 0.21984267, 0.021845669, -0.085822344, -0.26314548, 0.38268337, 0.284944, -0.13691823, -0.020810127, 0.38831088, -0.1040292, -7.521113e-05, 0.06306347, -0.10215285, -0.15502807, -0.73847914, -0.1563373, -0.42102155, 0.023742506, 0.31548208, 0.1424874, 0.033481967, 0.23638673, 0.12778044, -0.2052915, -0.08860769, -0.22107272, -0.08616808, 0.07277184, -0.022057006, -0.15556103, 0.041260388, -0.116263844, 0.055943336, 0.035206243, 0.17025186, 0.18668024, 0.23273428, -0.13200288, 0.39380106, -0.16048367, 0.29856792, -0.20389415, -0.08917121, -0.5122161, 0.13314867, -0.43431225, -0.28071648, -0.41969597, 0.0069486327, -0.14784329, 0.3006092, 0.49134973, -0.46576414, -0.22606109, -0.25614884, 0.03577116, -0.331916, -0.14155993, 1.1395687, -0.29953685, 0.020643063, -0.2192959, 0.25392225, -0.11612168, -0.13421349, -0.300703, 0.2189417, 0.19963439, 0.009789586, -0.31441405, 0.30672744, -0.29796976, -0.29708678, -0.066486694, 0.065496184, 0.008757244, -0.21325727, 0.32676384, 0.22258073, -0.0030891125, 0.039793786, -0.10827532, 0.08148944, -0.29863057, 0.09607282, 0.071556784, 0.0335039, 0.06296695, 0.37820646, 0.25281408, 0.25139713, -0.24899995, -0.028749803, -0.20572881, -0.13025285, -0.1235044, -0.32803643, -0.11286905, 0.29855803, -0.026573882, -0.16748758, 0.20761822, -0.2122138, -0.17475282, 0.1491826, 0.34851372, -0.04377374, -0.27863535, -0.10489834, 0.093488075, -0.17459826, 0.018902415, -0.057839334, 0.148142, -0.015995106, 0.16643338, 0.36704776, 0.27194884, 0.067924194, -0.09250329, -0.12819414, 0.27401423, 0.024322137, 0.0040075094, 0.08000735, 0.29718247, 0.30270743, -0.26580924, 0.09773896, -0.19560023, 0.18336357, 0.16560055, 0.112878285, 0.16033244, 0.44256258, 0.25365147, -0.032426506, 0.03734437, 0.6267089, -0.08321291, 0.046581924, -0.038732562, 0.33777344, -0.03733691, -0.0179822, 0.49132463, -0.047318354, 0.114744894, -0.36946568, 0.40307772, -0.61019176, 0.20457883, 0.07246125, -0.016801722, 0.46501362, -0.10170857, 0.3377284, 0.24810053, 0.043097496, -0.08634607, 0.041633997, -0.027547078, -0.10195973, 0.2982152, 0.01831901, 0.1456969, -0.22625326, 0.009289004, -0.0054596537, -0.25483245, 0.34838328, 0.44483796, 0.02271668, 0.6706268, -0.0994091]}, "content": "Yeah. Yeah. I mean, it's just, it's a dating app for those embedding is what you're describing even, you know, it's very interesting. ", "podNum": 30, "speaker": "Marco Bianco"}, {"_additional": {"id": "e7e4842b-8388-4a43-9866-15e9a48d4087", "vector": [0.096502215, -0.10753745, -0.057189204, -0.1935392, -0.019074168, -0.08697781, 0.12802085, -0.017138321, 0.01631034, -0.03924509, 0.02548349, 0.34580845, 0.085698426, 0.00073565263, 0.21557595, -0.09491273, 0.049240887, -0.1203822, -0.36742812, 0.0009945668, -0.19835329, -0.17583594, -0.0799152, -0.009444911, -0.18058139, 0.025303576, -0.01226395, 0.009733446, -0.14194722, -0.061273575, -0.025555478, 0.17045963, -0.0994586, -0.09659432, 0.016785596, -0.01066071, -0.12374475, 0.02266943, -0.12337379, -0.051772796, -0.019573769, -0.10806538, -0.11385089, 0.14381228, 0.10678165, 0.09487283, 0.06992903, 0.019657768, 0.10140221, 0.08661017, 0.11483496, 0.0003239304, 0.08579163, 0.07202442, -0.11481695, 0.18750116, 0.10264361, -0.016143134, -0.01528034, 0.14847943, 0.10926462, -0.18179941, -0.20114006, 0.34532237, 0.12264587, -0.10611757, 0.01706755, -0.06989085, -0.28136224, 0.41510913, -0.048250116, -0.11470251, -0.03850307, 0.11449598, 0.1125156, -0.017982643, 0.17539373, -0.122963294, 0.10328771, 0.004211318, -0.06778055, -0.21775472, 0.00477874, 0.09390072, -0.06631837, -0.12235022, 0.118702725, 0.06948563, 0.10201238, -0.16015002, -0.0892901, 0.048018698, 0.080182195, -0.009680608, 0.01979307, 0.15101732, 0.047867414, -0.08654007, -0.1349513, 0.19124156, -0.16949072, -0.111342825, -0.02621258, -0.32711893, 0.040497646, -0.2648062, -0.008210197, 0.14310178, 0.13585666, -0.07921058, -0.15105385, -0.02226314, 0.083731264, 0.05250002, -0.18725891, -0.012592854, -0.14818679, 0.10573595, 0.07076941, -0.26757106, 0.069966085, 0.0139479935, -0.01597599, -0.011700163, -0.056147665, -0.26887962, 0.007525794, 0.18117535, -0.136561, -0.07084381, 0.12710245, -0.2083967, 0.009599233, 0.07491739, -0.06763896, 0.0046681874, 0.034069907, 0.08793138, -0.051671185, 0.014411574, -0.04723029, 0.2174518, 0.3054639, 0.009846634, -0.24453044, 0.04322618, -0.07185769, 0.03195579, 0.09500968, -0.26486123, -0.08402279, 0.090984516, 0.10015342, -0.17877832, 0.0010113921, -0.08824368, 0.19874972, 0.04896581, 0.003930579, 0.019023214, -0.1703463, 0.0667328, -0.15612316, -0.066189244, -0.08595212, 0.0064908545, 0.109628566, -0.06622429, -0.12996173, 0.13401726, 0.019492429, 0.02117609, 0.12776628, 0.037831508, -0.005971317, -0.06807843, -0.28136384, 0.13177504, -0.03453368, 0.12300943, 0.13362062, 0.12720422, -0.00530947, 0.06299004, -0.06732519, -0.046172693, -0.102133945, -0.07211538, -0.032507535, -0.21258408, 0.016824536, 0.0110414885, -0.23295686, 0.2579337, 0.038358957, -0.14738747, 0.106659174, 0.039570585, 0.034952793, 0.0814307, -0.26193553, -0.08018363, -0.040622003, -0.1903927, 0.21128576, 0.048996855, 0.2647444, -0.16663139, -0.101493925, 0.009971933, -0.032568254, 0.029655822, -0.012338265, 0.12941109, 0.14366326, -0.1314125, 0.059638716, 0.05317811, -0.15768883, -0.045396402, -0.2069744, -0.042024393, 0.06768067, -0.40913862, -0.07941209, -0.19780731, 0.09117409, 0.2019198, 0.017402072, 0.06198831, 0.11905356, -0.25058466, 0.05289539, 0.2618956, -0.100567795, -0.06141752, -0.052603073, 0.021870866, 0.0550603, 0.012369733, -0.020614954, 0.03380122, 0.11929197, -0.048202634, 0.024004884, 0.17233168, -0.116428226, 0.2892173, 0.0074824803, 0.16460773, -0.3293783, 0.04873748, -0.09604197, 0.16695347, -0.31064272, -0.14510195, -0.20275414, 0.052199937, -0.18176702, 0.045079794, 0.18074298, -0.119423844, -0.08945935, -0.0022750953, 0.075966924, -0.11081475, -0.19993168, 0.18425262, -0.10478663, -0.06926632, 0.035213254, 0.022935644, 0.17987958, -0.08848281, 0.06057335, 0.19701919, 0.08940978, -0.0022136066, -0.31241024, 0.038871277, 0.01820679, -0.1632061, -0.10055698, 0.16505294, 0.2584907, -0.09212977, 0.06534475, 0.078158036, 0.09104936, -0.14413996, 0.12638873, 0.110355, 0.013234753, -0.04981695, -0.0060707293, -0.054989442, -0.06650604, 0.16376124, 0.14119779, 0.23123227, 0.22832456, -0.050990872, -0.16293281, -0.073409684, -0.0968367, -0.08677464, 0.05375886, 0.21414831, -0.037694726, 0.06663169, 0.022825243, -0.10413104, -0.076116696, 0.06482857, 0.039571475, 0.0919162, -0.11908436, -0.061968975, -0.10295807, 0.03207923, 0.037089128, -0.10656662, 0.09035765, 0.26612228, -0.1097808, 0.09203407, 0.1096517, 0.056417927, 0.009710241, -0.011983845, 0.08653988, 0.01546908, -0.059753157, -0.0063256207, 0.12580884, 0.34140942, -0.11582956, 0.08311622, -0.084317125, 0.19907738, -0.021678474, 0.15417397, 0.09347811, 0.15282576, 0.044652455, 0.09860718, 0.12107436, 0.2356686, 0.047654573, 0.020433055, 0.016664706, 0.13250493, -0.02475159, 0.12999672, 0.2516637, -0.1569652, -0.14778504, 0.00052207895, 0.0036645383, -0.25578418, -0.026329735, -0.022101417, -0.19543119, 0.24270558, -0.06043168, -0.007596465, 0.04855749, 0.019954693, -0.114282735, 0.0726422, 0.086418666, 0.080351144, 0.01998623, -0.11037984, 0.18063794, -0.11728549, 0.08279323, 0.05015819, -0.17737204, 0.18756902, 0.09272708, -0.1168361, 0.40148264, 0.1321899]}, "content": "So it has to, right? So there's always this trade-off, right? So for example, let's take the example of using your own embedding from hugging face versus in hosted embedding. Let's say that your use case for your use case, you're fine using a hosted embedding somewhere. Then there's this trade-off point. So if I run it myself, I have that control, but that comes with certain costs. I need to pay for the GPUs, for the infrastructure, those kinds of things. Or it might tilt off. Like it became so cheap to run that somewhere else. So we saw like, of course, these prices, they're just going down, down, down, down, down. And it becomes cheaper, cheaper and cheaper to actually use these models. So then it might tip over for your use case. It's saying, okay, now it's just cheap enough. Right? So it's just, it's the, it comes with that UX inflection point. And that will really, really, really depend on the use cases that you have. Because if you're in hospital and you're storing patient files and you want to quickly search through these patient files, then it can get as cheap as you want. Right? So, but it will not tip over. It will stick to that other side. And then maybe ways that people scale these models and work with them and how cloud providers interact with them might be more interesting for those kinds of use cases. So there's always this inflection point that has a combination of price and UX. You know, so if it's, if the UX becomes, if it's so easy versus so difficult to run one over the other, it might just tip over or it becomes so cheap that it might tip over. But sometimes it never tips over. It's like, sorry, we just need to do it the hard way because that is for our use case important. And that is why we also see companies like, I don't know, like Ray or something, right? You know, we help you run these models, which is great because there will be enough use cases. I mean, there will be so many use cases in the world that there's like enough for both worlds. And also I think these embedding providers, they struggle of course with the fact that they somehow need to scale the effort of running these models. And but that's how it's, that's how it's solved. Right? So that's like the market just determines if it goes left or right. And that is the big difference between that academic side and the product side. So that's what I mean when I say like, good enough. There's always like, okay, you know, maybe on benchmarks XYZ in this article, it says that A works better than B, but B is so much easier to run and so much cheaper and I get the results I want. So why not go for B? And that is just, that's just age old wisdom coming from the market, you know, how it operates. So well, I hope that answers your question. ", "podNum": 35, "speaker": "Bob van Luijt"}, {"_additional": {"id": "e7ef78f3-20fd-4bd5-aeb9-98f6a1410b26", "vector": [0.21116255, 0.08405827, 0.20915994, -0.0061898604, 0.0050986707, -0.2058273, -0.16913497, -0.14475828, -0.04332961, -0.002045367, -0.0033688191, 0.32934904, 0.08318716, -0.23778957, 0.338759, 0.08538352, -0.1891028, 0.14326714, -0.7644645, 0.064215615, -0.23419988, -0.04716962, -0.22883317, 0.00082660466, 0.17507008, 0.33513415, 0.12920341, -0.0029603243, -0.2621934, -0.29328334, 0.14827888, -0.16894913, 0.06692885, -0.23292013, -0.17149684, 0.26678178, -0.01518004, 0.14871065, 0.33211285, -0.09943673, 0.011829933, 0.30771917, 0.13626963, 0.21082152, 0.15250668, -0.20053971, -0.1700483, -0.18017225, 0.05003096, 0.14572689, -0.056218818, -0.06906956, -0.05043293, 0.039711542, -0.21255976, 0.117806815, 0.2109083, -0.09317893, 0.0333756, 0.18843094, -0.48685205, -0.10110608, 0.04944923, 0.28401178, -0.25793844, -0.086077735, -0.11512568, -0.0062420145, 0.13054751, 0.33862093, -0.08013825, -0.12961136, -0.16452417, 0.0119562745, 0.035551883, -0.031129152, 0.029672317, -0.014743805, 0.19528848, -0.18956341, -0.18374184, 0.10768876, 0.10139443, 0.44032654, -0.11603505, 0.08997835, 0.11916512, 0.011686519, 0.42597783, -0.045263432, 0.0056613, -0.117413916, 0.581448, 0.0034334622, -0.157524, -0.33116183, 0.1231677, 0.15601625, 0.24654652, 0.08638963, -0.17719503, -0.13501213, -0.22972162, -0.55402046, 0.069888994, -0.39248133, 0.16618451, -0.09966281, 0.07498794, -0.21253753, -0.09977835, -0.05316428, -0.17010175, 0.0036655068, -0.11752985, 0.3933016, -0.003528228, -0.004305981, 0.014719181, -0.43525708, 0.280326, 0.1386097, -0.07231571, 0.045167256, -0.38394967, -0.2993573, 0.38446766, 0.08798077, -0.019099882, -0.257938, -0.018619493, 0.12472686, 0.38140178, 0.002758231, 0.12023626, -0.1965119, 0.05592031, -0.20118742, 0.403949, 0.090941176, 0.15830857, 0.10177813, 0.049815126, 0.21445793, -0.2698102, 0.16917312, 0.25782096, -0.120557815, 0.12755273, -0.14860602, -0.12200774, 0.22105628, -0.08608689, -0.1425725, -0.10939251, 0.02749379, -0.031435825, 0.023648318, -0.13950413, -0.1935789, -0.019665617, 0.02533935, 0.16704084, -0.025379006, 0.48101234, -0.08477567, -0.0488679, 0.23629464, 0.19253409, 0.06379338, 0.25230765, -0.014068535, -0.07771059, -0.29640192, -0.13610402, -0.054843873, -0.49471322, 0.20260285, 0.037293293, 0.15437904, 0.53893775, -0.17619833, -0.22320983, 0.1971962, -0.15433453, -0.15542814, -0.107994586, -0.20142025, 0.08346183, 0.11855139, 0.063743986, 0.06482144, -0.23028217, -0.073905446, -0.23884575, 0.07475451, 0.007874094, 0.107693195, -0.4012789, -0.07816113, -0.43074304, -0.16728157, -0.14430262, -0.2276597, -0.18837827, -0.07582198, 0.19433396, -0.24687982, 0.3243987, 0.22543558, -0.31632334, -0.48847258, 0.04655277, 0.22032839, 0.22679996, -0.18420923, -0.2093809, 0.12345873, -0.06292952, -0.3226484, -0.112397686, -0.43788594, -0.18646167, -0.48886734, -0.040694214, -0.07682206, 0.11042217, -0.19608216, 0.070417315, 0.08736333, 0.35915983, -0.032642458, -0.017707877, 0.23076792, -0.051612332, -0.10338665, 0.35959145, -0.11618882, -0.13564616, 0.07758454, 0.04687357, 0.20445336, -0.3386957, -0.084620304, 0.033497527, 0.15264072, 0.069975235, 0.33141255, 0.034263358, 0.5840368, -0.1342933, 0.32125908, 0.034885075, 0.13445392, -0.334656, -0.09573103, 0.1197027, 0.30634972, -0.08367851, 0.17312384, 0.13419165, -0.010349685, -0.30432183, -0.2999787, -0.3157001, -0.17885241, 0.04264046, 0.5290877, -0.20821793, -0.23048353, 0.03490243, 0.37270057, 0.1841212, -0.0624552, -0.12698948, 0.21799135, 0.22883943, 0.036084533, -0.14954747, -0.22719353, 0.1661122, -0.46201336, 0.15738966, 0.12377119, -0.2868821, -0.12017221, 0.28861713, -0.34274366, 0.49503666, -0.29873466, -0.1863657, 0.13571523, -0.043167524, -0.11301613, 0.26762873, -0.113554716, 0.06323036, 0.4217295, 0.32414043, -0.1913293, -0.051295597, -0.22229645, -0.36455396, 0.11139369, -0.034881476, -0.2925883, 0.050572164, 0.036835328, 0.29673344, 0.027470645, -0.27246344, -0.083703496, 0.07540217, 0.054971423, 0.27489105, -0.07175017, 0.13613138, 0.26885793, 0.06790839, -0.28447002, 0.083337605, -0.064955875, 0.14914045, 0.19897683, 0.055603698, -0.0042565055, 0.12024326, -0.03468863, -0.18554726, -0.15698513, -0.117001556, 0.26071048, 0.06435449, 0.04428553, -0.16974217, 0.22257635, -0.02737544, -0.0928412, 0.0815392, 0.14210968, 0.2994244, 0.14093755, -0.2648224, -0.05845374, 0.08885722, 0.34576643, 0.23738223, 0.08454701, -0.011830713, 0.052770752, 0.010191095, 0.1435004, -0.17023815, 0.2782724, -0.057307474, -0.13809709, -0.037306666, -0.15191913, 0.43022263, -0.043440647, 0.07662943, -0.04169616, -0.12363292, 0.47842604, 0.0021561682, 0.05030464, -0.27266067, -0.10829877, -0.07980194, 0.19514047, 0.18908507, 0.22259018, -0.1995259, 0.3958485, 0.20690258, -0.13618475, 0.25107768, 0.1293977, -0.41374552, 0.22578259, 0.3378095, 0.26764295, -0.017200448, -0.016311463]}, "content": "Uh, so could you kind of take it on that, uh,  kind of what I left off. Uh, could you kind of take over the, like, kind of the origin story of how you came to be working on, this kind of like Siamese encoding of representation?", "podNum": 33, "speaker": "Connor Shorten"}, {"_additional": {"id": "e82cc6dd-813d-437a-b483-1b63b1db875e", "vector": [-0.18179263, -0.3300033, -0.05864303, -0.16131404, 0.0316375, -0.07116835, 0.03789961, -0.07461313, 0.06394029, 0.044707794, -0.077126466, 0.06315547, 0.002442358, -0.034968536, 0.21598817, -0.095886014, 0.11931151, -0.061616234, -0.2500742, -0.012771519, -0.059945814, 0.027375977, -0.12257725, -0.019658133, -0.06705516, -0.024640309, -0.103467494, -0.10540126, -0.028646084, -0.2092805, 0.18076216, -0.09674938, 0.006312401, -0.098761275, 0.014863248, 0.08864034, 0.014204391, 0.10246706, -0.11065859, -0.013234903, -0.038584627, -0.23520404, -0.13844828, 0.20847887, 0.012037482, -0.15223625, -0.043132335, -0.010617815, -0.07483167, 0.19501896, -0.08551334, -0.098751396, -0.12563911, -0.11449418, -0.109961584, -0.0026785024, 0.08780807, 0.12320024, -0.054333918, -0.027952516, -0.01573969, -0.18428, -0.090097554, 0.23837727, 0.08270203, 0.032131754, 0.055908114, 0.10818917, 0.07216889, 0.02652062, -0.16117203, -0.104030594, -0.20244849, 0.1859203, -0.05974084, 0.10504458, 0.10724547, 0.10414191, 0.16272649, -0.1231927, -0.0725652, 0.012857018, 0.14666167, 0.011171959, -0.04614631, 0.10050703, 0.16122799, 0.118266, 0.15174074, -0.100637354, -0.20935595, -0.049378984, 0.121729344, -0.0028645427, -0.12060936, 0.2168314, -0.07251398, -0.04570768, 0.23636454, 0.06434031, -0.20526658, 0.06425734, -0.0423634, -0.30472565, 0.018947642, -0.36279005, 0.077672996, 0.10606389, 0.11252479, -0.18105128, -0.026289023, -0.009115368, 0.048234444, -0.11996563, 0.04576466, -0.08348259, -0.0010002214, 0.042065267, 0.2618525, -0.17196447, 0.09302089, -0.004632921, -0.018848727, 0.07628293, 0.006310504, -0.023355573, 0.1339663, 0.17154409, 0.2285661, -0.018307583, 0.17740777, -0.020782977, 0.11363361, 0.14446816, 0.03503196, -0.0706813, -0.0947328, -0.14445385, 0.0071990695, -0.013934546, -0.15779823, 0.27537972, 0.12167785, -0.16082348, -0.22430368, 0.22021365, -0.034321956, -0.100359716, 0.00894135, -0.19826281, 0.016275551, -0.13009885, 0.21566258, -0.085588485, 0.012545667, -0.08068688, -0.11249827, 0.096351184, -0.009217145, -0.10535243, -0.3028697, 0.081451625, -0.17478202, -0.023000274, 0.21429324, -0.035273194, -0.03205301, -0.018232754, -0.025070582, 0.10571763, 0.030607352, -0.078915186, 0.019157717, -0.12883224, 0.124252245, 0.12264409, -0.17518444, -0.11483741, 0.032586157, 0.1680554, 0.09047829, 0.08091106, 0.08981241, 0.08071406, -0.12858771, -0.06154625, 0.024669668, 0.018186705, -0.08624532, 0.02732566, -0.017106164, 0.0068650246, -0.08487714, 0.13652045, 0.027381312, -0.17801987, 0.1895172, 0.120520696, -0.1332566, -0.0027508428, -0.19539034, -0.0976642, -0.10048574, 0.03779953, -0.014011512, -0.007619697, 0.21286623, -0.033805333, -0.039211627, -0.027856136, -0.03748352, 0.03629445, -0.04767419, 0.060555466, 0.22575867, -0.12640889, -0.19901708, 0.031689346, -0.22016545, 0.090092845, -0.054012265, -0.10474108, 0.16970459, -0.32312554, -0.2272969, -0.13142914, -0.01814714, 0.18991369, 0.022999011, 0.083661705, 0.23328082, -0.07193334, -0.00049599074, 0.19934802, -0.14541946, -0.00772518, 0.18754578, -0.119738005, 0.012833286, -0.00045165373, -0.021624545, -0.0118742585, 0.07879957, -0.13485543, -0.20242885, 0.28531, -0.21573348, 0.20669633, 0.09999008, 0.114302605, -0.16255172, 0.05578751, -0.11620851, 0.11917422, -0.26983222, -0.022444367, -0.3018613, 0.08460646, -0.12081526, 0.113810636, 0.21159579, -0.22307546, 0.07273208, 0.06461352, 0.20409721, -0.063330084, -0.051842812, 0.11023689, -0.2564697, -0.046436135, -0.11376878, 0.17040211, -0.045467827, 0.049962416, 0.093659796, 0.19428514, -0.07969264, -0.2466339, -0.1669187, 0.03252971, 0.052310135, -0.10993889, -0.17101835, 0.2066147, -0.08289308, -0.18000871, 0.07912443, 0.08164158, 0.12176034, -0.17716447, 0.068266824, 0.09235023, -0.18159732, -0.01231833, 0.101732604, -0.117265925, 0.120238915, 0.14404887, 0.21973799, -0.075624146, 0.104528874, -0.0066745305, -0.16151696, -0.031351697, -0.1593844, -0.028313078, 0.21663304, 0.10357923, 0.42772925, 0.030607231, 0.05256358, 0.04287281, -0.005523703, 0.13810712, -0.08015442, 0.05965209, -0.1898908, 0.13364364, -0.08345528, 0.029979981, 0.09602456, -0.20561816, 0.2124592, 0.23951213, 0.0041042687, 0.16883627, -0.08069404, 0.16171362, -0.06452537, 0.08098952, 0.16492867, -0.06823427, -0.10510054, 0.09649767, 0.17209975, 0.2101447, 0.12553231, -0.036679685, -0.21583275, 0.023539847, 0.016811036, 0.21330449, -0.0500127, 0.06142992, 0.034924377, 0.00058262376, 0.15743434, 0.2707765, 0.0530055, -0.0013155278, -0.030874016, 0.17936262, -0.073082425, -0.012843464, 0.14330092, 0.14538263, -0.038071346, -0.08033833, -0.029808955, -0.2604763, 0.033036176, -0.154565, 0.052801132, 0.3256405, 0.020678107, 0.1642536, -0.087366655, -0.077984504, 0.019357804, 0.0031772908, -0.0556463, -0.06289457, 0.11218946, 0.0703566, 0.1904761, -0.0208621, -0.04823459, -0.14490557, -0.051607683, 0.27105254, -0.0030120932, 0.10641758, 0.20763423, -0.10110639]}, "content": "Yeah, and I think I'd want to start with connecting with our earlier conversation of the lost money in retail and more and more brand stores trying to build their own retails. And I'd even maybe extend that to people with their own blogs, looking to have searchable things on their blogs, and also paying the bills and not worrying about this thing. I kind of want to start off with say, like the data pre-processing layer. Like I see kind of with these neural search frameworks, they define these pipelines. And I think pipelines is sort of the key term here. And I'm going to talk about what I, what are the pipeline I think should live in Weaviate and what I think should live outside of Weaviate. I think maybe starting off with just like the data ingestion part, like maybe you have some kind of API that you query to get the data. You have maybe like a PDF parser with some kind of OCR. How are you thinking about that first part of the data ingestion layer? Because it may be if I could just add one more thing to transition the question. And coming into like running things in production, Jina AI, they have these executor pattern. And I learned a lot about this on the Weaviate podcast with Maximillian Werk. I highly recommend that if you're curious about learning more about this pattern for listeners. But this kind of way of scheduling like a cron job that say, you know, every two hours is going to query this API, like, or say every day it's going to hit the arxiv API to get the new batch of machine learning papers, parse out the text and chunk it in the PDF, then vectorize those chunks. And then maybe put that to Weaviate. And then, yeah, I don't want to, let's start just on that first part of.", "podNum": 34, "speaker": "Connor"}, {"_additional": {"id": "e9d8d828-57b4-4b0e-93d7-d54f630379e3", "vector": [-0.016683051, -0.18604839, -0.15754436, -0.19955136, -0.078781225, -0.14203238, 0.07093132, -0.16397355, 0.052533094, 0.12307015, -0.0972662, 0.09224491, -0.0309267, -0.044494286, 0.34203646, -0.1727504, 0.09970026, -0.2373808, -0.4590808, 0.09708832, -0.05763526, -0.271665, -0.0039263815, -0.05333359, -0.17560689, -0.019368397, 0.037264578, -0.07717103, -0.009976121, -0.09208251, -0.026977915, 0.14073078, 0.08339641, -0.084986776, -0.18362074, 0.24440978, -0.048650265, 0.00091765745, 0.01334366, -0.07091731, -0.024222236, -0.16057013, -0.063590944, 0.18664917, -0.072227195, -0.079153895, 0.05427385, 0.00048498143, -0.008397369, 0.09162283, 0.14529599, -0.0570658, -0.025146594, -0.15371485, -0.064313084, 0.12153959, 0.14759372, -0.14199416, 0.059387326, -0.09556301, 0.10579395, -0.15719822, -0.11273147, 0.25852588, 0.15331818, -0.18171965, -0.047477953, 0.008582109, -0.1847647, 0.14742675, 0.032183357, -0.052410573, 0.124071084, 0.1561931, 0.030482173, -0.014860225, 0.13433585, -0.0667848, 0.046487972, 0.017447481, 0.07944599, -0.21116164, 0.039648145, 0.106922925, 0.13447617, -0.012293741, 0.0115170935, -0.0701139, 0.12925954, -0.07183527, -0.20894937, 0.12208981, 0.14965054, -0.060585674, -0.114894226, 0.20359091, -0.01721887, -0.11230095, -0.06020095, 0.12766196, -0.23334493, 0.024743924, 0.16929318, -0.33359772, 0.14058523, -0.30453178, -0.0139433425, 0.14461434, 0.13210504, -0.0635426, -0.11509199, -0.022124242, -0.06261075, -0.010624195, -0.016492136, -0.07374681, -0.21162443, -0.05628462, 0.123925485, -0.30946586, 0.021511564, 0.0737389, 0.13955271, -0.08837704, 0.029119607, -0.07363629, 0.015616624, 0.19962029, -0.13391021, 0.06350363, 0.16607864, 0.062104903, 0.0969004, 0.16884175, -0.025107535, -0.06006557, 0.047960214, -0.15180598, -0.007907254, 0.06955305, 0.031299006, 0.32540986, 0.3118661, -0.06738628, -0.2622645, 0.07108833, -0.055270772, 0.027285488, 0.004471324, -0.1274458, -0.0693197, 0.047547694, 0.07650126, -0.040226273, 0.18766844, 0.117559694, -0.03438026, 0.029369377, 0.018157817, -0.044971276, -0.038128935, 0.09521208, -0.1261677, -0.042259403, -0.010999511, -0.10105791, 0.04024081, 0.0066565056, 0.00020280245, 0.05613451, -0.035599187, 0.042447347, 0.038499925, 0.12527272, 0.1191208, -0.0010045861, -0.25629115, 0.02039278, -0.042954408, 0.15504579, 0.120955996, 0.10837964, -0.03631978, 0.00058569876, -0.079625905, 0.04433613, -0.022758609, -0.17709604, -0.020150734, -0.11735581, 0.0763, 0.07009653, -0.06755191, 0.24450111, 0.06988105, -0.114767134, 0.2760082, 0.11708226, -0.10914578, 0.075692676, -0.40421018, -0.113810994, -0.061245844, -0.07076636, 0.19249505, 0.09398544, 0.30008146, 0.18516739, -0.11932008, 0.008908958, -0.05180326, 0.012274524, -0.052451886, 0.035926882, 0.23837958, -0.1353968, -0.056840666, 0.052268736, -0.102392964, 0.028635621, -0.042262767, -0.077230565, -0.021426871, -0.38264441, -0.12969497, -0.10296333, 0.043173954, 0.08636107, 0.13908255, -0.039401677, 0.0924721, -0.37170386, 0.00849434, 0.20908792, -0.09458978, -0.05212861, 0.10081454, -0.12136942, -0.12645148, -0.105497725, 0.019789705, -0.08344285, 0.18480983, -0.14495504, 0.068429254, 0.2400351, -0.14274858, 0.24873646, -0.09423661, 0.17427367, -0.21188827, -0.10960997, 0.037910122, 0.104067415, -0.26350233, -0.120266035, -0.33921748, 0.13813257, -0.058032457, 0.18361242, 0.120048225, 0.019835629, -0.06748324, 0.113108635, 0.06409418, -0.1424816, -0.2600135, 0.21089303, -0.25237775, 0.05333528, 0.16503097, 0.0026855078, -0.079054646, -0.18779798, 0.022568004, 0.083033524, -0.11227309, -0.2137025, -0.21421653, -0.048171844, 0.20189472, -0.12696636, 0.14509407, 0.24261856, 0.10231203, -0.0222825, 0.07621714, 0.22168405, 0.0972283, -0.19201545, 0.13052046, 0.15997739, -0.18755788, 0.036160123, -0.035770316, -0.19516583, -0.103308655, 0.28368923, 0.11069683, 0.037364706, 0.19784468, -0.02100876, -0.008410484, -0.077296205, 0.0076172743, -0.091608874, 0.066561796, 0.17246927, 0.1440594, 0.014013529, 0.15280312, -0.049725726, -0.050144307, 0.14182556, -0.10551205, 0.117675416, -0.26062047, 0.036376882, -0.0812233, 0.0036935578, 0.005055032, -0.03501478, 0.037771195, 0.099649526, -0.11201952, 0.028170787, -0.09331813, 0.11152315, -0.061134025, -0.004755315, 0.035126265, 0.090671994, -0.012928651, 0.20984943, 0.2861871, 0.375309, -0.12953985, 0.17893367, -0.14062934, 0.08663207, 0.13600075, 0.1630782, 0.061912823, 0.028347617, -0.0046647927, 0.065117344, -0.021968072, 0.16964103, 0.04589712, 0.1449464, -0.02339387, 0.11190897, -0.21098046, 0.016107857, 0.20565344, -0.056709044, -0.29484752, -0.1961294, 0.0925597, -0.21107575, 0.07527759, 0.046829384, -0.08552826, 0.34998298, -0.06945118, 0.115717195, 0.046417646, -0.010747242, -0.16986766, 0.16309538, -0.07972784, -0.104860686, 0.09095675, -0.02498959, 0.06699967, -0.19463496, 0.005010949, 0.067277215, -0.012461443, 0.13923106, 0.2129122, 0.012200696, 0.21705931, -0.0037851632]}, "content": "So this is super interesting, right? Because I think our friends at OpenAI did an amazing job also in positioning the model, because just the DaVinci 3 model, but using just as a layer on top, the chat functionality, and this here, and this is what I find super interesting, right? So we have in this one corner, we have the academic side of things, but on the other hand, we have the product side of things. And they just did a great job there, because I was literally the other day, I was in a bar and I explained to the bartender what it is and he was like, oh, is it some kind of, you know chatGPT related? And I mean, that's a good sign, right? So they did something great there. But the point that I want to make with this is like, we do not only have that model from OpenAI. And so we see what Google is doing indeed with Flan, which is super interesting, because they decided to open source that. So that means that certain people who just for whatever reason want to use a model that they can control themselves, that becomes available to them. But we also see indeed others who create generated modules, right? So for example, like Cohere, and what we do with all these models, within Weaviate, it\u2019s like we want to support everybody. So we decide, it's up to the users and the customers to decide what they want and what they need for the use case. We're just going to make as many as we can available so that people can just decide what they want. And what I would guess is that if we take this out of the realm of academia, more into product and engineering and design, it is different people have different use cases have different needs, right? Size of the models can play a role, whereas hosted can play a role, how you can control the model might play a role. And the fact that we have this wide variety of flavors and choices and what kind of generative model we want to use, same by the way goes for models we use to create embeddings. I think that's a beautiful thing. So then people can decide whatever they want. And again, we try to support as many as we can. ", "podNum": 35, "speaker": "Bob van Luijt"}, {"_additional": {"id": "ea27163f-428a-43cf-ac69-ae2694527293", "vector": [-0.3593094, -0.16174743, -0.12487165, -0.4066785, 0.013114843, -0.11178591, -0.12551923, 0.14024417, 0.14361586, 0.082676455, -0.08577036, 0.010472, -0.14637244, 0.01678718, -0.03824102, 0.007466042, -0.00011675656, -0.2557056, -0.12881663, -0.19724908, -0.21898623, -0.019777203, 0.24508536, -0.13514394, -0.018674504, -0.025519466, -0.22482443, -0.09673412, 0.012402681, -0.03760174, 0.21123977, 0.22517988, 0.32025337, -0.13275853, -0.22442475, 0.32066077, -0.054706655, -0.2075189, -0.26483425, -0.04464888, -0.10674934, -0.18749306, -0.06852021, -0.15572649, -0.015736252, -0.4473273, -0.15070729, 0.12215469, 0.08458845, 0.280541, -0.07899187, -0.12730823, -0.017720366, -0.07257781, -0.046352882, 0.026223738, 0.10091045, 0.18990949, -0.086778805, -0.23174997, 0.2860059, -0.23921442, -0.03737677, 0.37127, 0.19358718, 0.020879164, 0.09973113, -0.038449667, -0.0064954013, -0.090942785, -0.336584, -0.13840155, -0.090164125, 0.2786818, 0.021581182, 0.23226686, 0.09173976, -0.23569265, 0.1127393, 0.041924693, 0.22676814, -0.08892668, 0.17370465, -0.17008236, 0.115597725, 0.042424843, 0.124658644, -0.19427015, -0.031424113, -0.30097476, -0.38823146, -0.070822455, 0.23617634, 0.021079307, 0.026052082, 0.26638886, 0.036815338, 0.05240664, 0.06852879, 0.20408008, -0.005989683, 0.09610196, 0.08203535, -0.32720226, -0.12923671, -0.14376736, 0.18517247, 0.18713404, 0.24498293, -0.026001563, -0.068536416, 0.046648633, 0.2753356, -0.11590159, 0.26013684, -0.0077129304, -0.055567313, 0.06653764, 0.20117247, 0.036838498, -0.13701929, -0.21977648, 0.13001972, -0.00889979, 0.15645584, -0.010253014, 0.04589454, 0.16731164, 0.28345647, 0.20428821, 0.117290474, 0.2654187, 0.09777354, 0.23633663, -0.16816458, 0.05378679, -0.3236049, -0.29278716, -0.2195436, 0.13787177, -0.07056199, -0.034003627, 0.1996294, -0.18182568, -0.31988615, 0.1934175, -0.035999388, -0.02996878, -0.08969635, -0.3097809, 0.118377194, 0.08769202, 0.38718385, 0.17651725, 0.52181804, 0.04454655, 0.5408179, 0.06734593, -0.26976678, -0.24740107, -0.17615335, -0.3005939, -0.1309771, 0.15284951, -0.039101172, -0.30622005, -0.23740447, 0.13485625, -0.115457036, -0.09489735, -0.15752085, -0.34370846, -0.009319639, -0.0872631, 0.15298998, 0.07693488, -0.0052702604, 0.010254199, 0.011886589, 0.10080246, -0.21974266, 0.21130595, 0.17243586, 0.07763012, -0.25533336, 0.24448068, 0.13851818, 0.17928164, 0.042288985, -0.18508084, 0.10930119, 0.14015786, 0.12201111, -0.0752432, 0.2895366, -0.18629952, 0.2207083, 0.18678214, -0.13272624, 0.09802625, -0.16442369, -0.10986145, -0.152965, 0.011996636, 0.09632792, 0.14279027, 0.26924744, 0.28668106, -0.10467428, -0.0038890187, -0.06918299, -0.1528269, -0.22518285, -0.01046457, -0.06868618, -0.36487442, -0.43333727, 0.16485712, -0.31839085, 0.20289858, -0.10640167, 0.16178948, -0.025637949, -0.2490248, -0.29295206, -0.0077864104, -0.17359634, 0.21314713, 0.11823124, 0.11060961, 0.062194902, 0.114032984, 0.016867377, 0.14010794, 0.14499733, -0.088919334, 0.14036417, -0.27500936, -0.06764528, -0.034724023, 0.3288324, -0.068235144, -0.031904478, -0.03834669, 0.13588966, 0.3352825, -0.3169243, 0.0766976, 0.005838239, 0.08336521, 0.17522275, -0.11461824, 0.053746022, 0.218433, 0.14191473, 0.06158469, -0.40465212, 0.023157643, 0.1897495, 0.67010385, 0.30745447, -0.07323942, -0.016630013, 0.08417835, 0.15453513, 0.08375722, -0.36939365, 0.076989934, 0.018648379, 0.007837826, -0.36557135, 0.14253469, -0.08584176, -0.16050622, 0.22164154, 0.043941516, 0.0976422, -0.29117137, -0.016165929, 0.25673833, -0.09527345, 0.20454045, 0.10134937, 0.19354245, -0.28181443, -0.2802817, -0.07578914, 0.061652087, -0.2691269, -0.13141324, 0.093087174, 0.18715808, -0.27889237, 0.30885062, -0.04765695, -0.076567836, 0.13793358, 0.11303613, 0.09935931, 0.035294257, 0.022082634, 0.065234944, -0.13511935, -0.11097398, 0.07850461, -0.07740221, 0.14209597, 0.07569719, 0.12723206, 0.15353306, 0.32914418, -0.069508515, -0.058309305, 0.17541274, -0.18392996, -0.0046169995, -0.35671067, 0.11774377, 0.29474992, 0.010572629, 0.16907744, -0.16989143, -0.04107854, 0.05017651, 0.08303621, 0.20704229, -0.15238619, 0.20608409, -0.23819593, 0.046463598, -0.03743421, -0.08674378, -0.29987583, 0.57559365, 0.44720212, 0.27802214, -0.035867907, 0.22953376, -0.09333317, -0.23504634, 0.22812697, 0.06138245, 0.09544604, 0.019384176, -0.07863424, -0.06303793, 0.14071852, 0.008033154, 0.12097536, -0.22062013, -0.118368186, 0.11406326, -0.58119386, -0.16923971, 0.11591531, 0.1162858, -0.12881275, -0.31232685, -0.18498848, -0.08231235, 0.07245238, 0.11114111, -0.006725204, 0.16175194, -0.08561871, 0.15399423, -0.09946555, 0.012022346, -0.10341509, -0.112648405, -0.33808762, -0.2675763, 0.19716237, 0.032788374, 0.03880437, -0.24925837, -0.08531936, -0.07075196, 0.04246231, 0.1676232, 0.06349922, 0.16417196, 0.14670332, -0.16603264]}, "content": "OpenAI's ChatGPT is an incredible breakthrough in artificial intelligence. ChatGPT has inspired many people to wonder about the future of search engines. The latest WeVa podcast features people at the cutting edge of large language models and search technology together. Today we host Semi Technologies CEO Bob van Luijt and FAQx co-founders Chris Dossman and Marco Bianco. So thank you so much for joining the Weaviate podcast. ", "podNum": 30, "speaker": "Connor Shorten"}, {"_additional": {"id": "eb61509a-949f-43b6-9320-58d1b0df2cbe", "vector": [-0.16645141, -0.10432154, -0.23198375, -0.3119555, -0.026039701, -0.19277692, -0.22244309, -0.05416324, -0.032030206, 0.003964763, 0.080992654, 0.31288743, 0.20125362, -0.022498399, 0.12262901, -0.07844683, -0.11846915, -0.0076829977, -0.17920533, -0.036019936, -0.1798242, -0.1882551, -0.012016989, 0.08420268, -0.06273478, -0.080056205, 0.037381932, -0.10417925, -0.036169022, -0.18714453, -0.06437519, 0.03621525, -0.14338489, -0.120250486, -0.003712466, 0.24113923, -0.13744567, -0.1030533, -0.115702696, 0.037677333, 0.11990787, -0.029520068, -0.05157315, 0.15801863, -0.11992228, -0.005344309, -0.1142284, 0.07200737, -0.18876144, 0.06063634, 0.1798691, 0.04262982, -0.029400818, -0.116509885, -0.15020949, 0.22795129, 0.07724561, 0.0062107425, 0.060020298, -0.11886675, 0.3113957, -0.09167815, -0.071085274, 0.1581635, 0.25619006, -0.200418, 0.101013586, -0.13393372, 0.02011823, 0.2036936, 0.061084136, -0.10762319, -0.08921407, 0.08266093, 0.13289493, -0.054081086, -0.036346707, 0.19374278, 0.17003354, -0.022874998, -0.04992964, 0.01498251, 0.062446274, 0.07170179, 0.04693824, 0.034429874, 0.026512204, 0.08894082, 0.076321185, -0.02064364, -0.06875876, 0.026693491, 0.12425751, -0.021433823, -0.21918434, 0.299797, -0.0077259354, 0.15413517, 0.19732156, 0.089284286, -0.1228145, -0.00204626, -0.16559117, -0.38173345, -0.025705766, -0.36282355, 0.056647368, 0.084093824, -0.086480714, -0.026524791, -0.07411043, 0.1221411, 0.03959928, -0.09313904, 0.02458179, -0.07106317, -0.13408306, 0.021003757, -0.027054057, -0.25000912, 0.16734886, 0.0016814265, 0.043638248, 0.15327162, 0.10192861, -0.020235604, 0.06953308, 0.18293196, 0.12720732, 0.05054136, 0.14539854, -0.017525699, 0.12618364, 0.010870157, 0.12730427, -0.13822255, -0.045714792, -0.29125836, -0.17036302, 0.06105858, 0.116820276, 0.029772108, 0.2030932, -0.15868104, -0.030690864, 0.40270445, 0.017765444, -0.04603454, 0.23182255, -0.10389175, 0.016893364, -0.004337214, 0.18568277, -0.02909054, 0.040902074, 0.06394109, -0.07946275, 0.0070917252, 0.046696384, -0.09337601, -0.17227647, 0.19180834, 0.019082418, -0.102955736, -0.0488806, -0.24649653, 0.022461338, -0.025922056, 0.039280567, 0.14503473, -0.18236202, -0.27934918, -0.028779592, -0.09768447, 0.1461351, 0.010021046, -0.028046822, -0.17749442, 0.13744292, 0.1824249, 0.13403381, -0.03469623, 0.03067328, 0.04950596, 0.076324075, -0.06596391, 0.014027129, 0.022033032, -0.028196787, -0.22376934, -0.11217628, 0.19335727, 0.04390049, 0.117198005, 0.031454176, -0.25992662, 0.22696826, 0.08940835, -0.01856329, -0.12168418, -0.20504728, -0.053118322, -0.12616941, 0.02538033, 0.10647603, 0.13021012, -0.0033010207, -0.05852276, -0.24036622, 0.07155523, -0.19000804, -0.09787064, 0.07227466, 0.09850964, 0.14924036, -0.09333335, -0.25182247, 0.23281401, 0.06291662, -0.04029328, -0.039942198, 0.06266958, 0.08626889, -0.3335023, -0.18362369, 0.007220477, 0.22420275, -0.027634596, 0.09681018, -0.005222923, 0.081630506, -0.11120885, -0.019146489, 0.17830339, -0.013604347, 0.0062025655, 0.15797469, -0.043120205, -0.17338799, 0.067190394, -0.03767641, -0.18071586, -0.055145685, -0.09874807, 0.08774865, 0.2643976, -0.07891301, 0.1742855, -0.003845105, 0.10099521, -0.27886873, 0.036596525, 0.04263027, -0.15093175, -0.15087521, -0.24878505, -0.30493927, 0.0686157, 0.014617707, 0.14801347, 0.23451419, 0.023522539, 0.07519317, 0.050485075, 0.20491584, -0.05509001, -0.20666885, 0.045397207, -0.00887423, -0.12133491, 0.15339005, 0.12048277, -0.113726996, 0.10676345, -0.05677158, 0.06928373, 0.09005274, -0.24949455, -0.18708545, 0.2999705, 0.032864753, 0.045283407, 0.07354383, 0.258918, 0.01823593, -0.3009748, 0.14658828, 0.052591994, 0.13491616, -0.07137748, 0.010204069, -0.056132294, -0.18590073, -0.05886097, -0.008632105, 0.13794975, 0.029299108, 0.122492574, 0.17580909, -0.099036574, -0.048193187, -0.26399916, 0.009722957, -0.1272919, -0.21785644, -0.056443006, 0.034495503, 0.19311835, 0.4192856, -0.1068041, 0.22496541, -0.15107839, 0.030779896, 0.046785768, -0.04494274, 0.07335203, -0.20862138, 0.18607427, -0.049131658, -0.03505024, 0.023584645, 0.0012566978, -0.12362719, 0.2342836, 0.13488118, -0.002361266, 0.0918811, -0.02024163, 0.06143553, -0.0036388673, 0.02114192, -0.029186144, 0.027069068, 0.071046054, 0.30750954, 0.10753172, -0.03486431, 0.123574615, -0.23740153, -0.01860386, -0.053688902, 0.12587166, -0.056009606, 0.11643144, 0.027892888, 0.06307105, 0.047884993, 0.39352587, 0.058685564, -0.09915463, -0.05030249, -0.120909125, -0.09031907, 0.019287989, -0.013986044, 0.058614194, -0.12124187, -0.016177315, 0.15119557, -0.14942653, 0.00514663, 0.19270442, -0.11112699, 0.37719432, -0.14116284, 0.023991242, -0.15859005, -0.031585842, -0.18029742, 0.029392732, -0.07073105, -0.01739656, 0.046507984, 0.0034866473, 0.16813894, -0.04585316, 0.09464444, -0.10820776, 0.040548243, 0.18143257, 0.025689013, 0.1246348, 0.25500596, -0.009867333]}, "content": "Yeah, absolutely. So when I first started at the company, we had a milestone. It was like the last milestone of the roadmap, which was replication. And it seemed so far away, such a monumental task at the time, right? We didn't really have anything to support that at the time that I joined. So over time, we've built towards replication. For example, starting with backups, first, we introduced the ability to backup whatever's in your Weaviate instance, maybe on a single node. And then that evolved into distributed backups, which allows you to backup a cluster. And all of this was working towards the ability to automatically replicate or to support replication. And finally, we were able to build on the back of all the work that we had done with backups and introduce replication. So it's something that we had in mind the whole time throughout the planning and development of backups. We knew that we were building towards replication. So we wanted to just build it up incrementally until we got to this point. So the really fun and interesting thing is that really the capstone of the replication work, I guess you could say, was done in Italy. So up to that point, I hadn't met anyone in the team in person. I'm based in the US, and the rest of the core team is based in Europe and other places. And so getting to sit specifically next to Redouan, another core team member, and work with him in person to finalize this replication that we wanted to build was super, super interesting. And it just made the whole experience so great. So the way that we decided to implement replication, we first looked at the CAP theorem. Like, what tradeoffs do we want to make here? Do we want to prioritize consistency or availability or partition tolerance? And so after discussing many times with the core team and Redouan and I discussing for a while, we decided to make the tradeoff for partition tolerance and availability, similar to Cassandra. The thing with Weaviate is that it's super read heavy. So oftentimes the use case will be where we'll insert a large amount of data up front, and maybe there will be more inserts in the future. But we want to prioritize read availability. So that being said, we decided to follow a leaderless replication algorithm. So the idea is that a request will come in to a cluster of Weaviate nodes, and the node which happens to receive the request will be promoted, I guess you could say, as the coordinator for that request. And so this coordinator also considers itself one of the participant nodes or one of the other nodes that it needs to relay this replicated data to. So the coordinator will participate in a two-phase commit with the rest of the nodes, including itself. So a request comes in, let's say a write request for a piece of data, and then the coordinator receives the request and sends out a broadcast, basically asking every node that is part of the replica set, I guess you could say, to acknowledge the request has come in. Once that acknowledgment comes back, then the coordinator will actually send out the rest of the nodes, the data that it needs to actually commit or write to disk. So the advantage to going with this leaderless algorithm is that it's more flexible in the case of node failure. We don't have a single point of failure with a leader-follower algorithm. So yeah, it just makes things more flexible in the event of node outages and things like that. ", "podNum": 31, "speaker": "Parker Duckworth"}, {"_additional": {"id": "ebf9b38d-ac4b-42cb-9e98-119147bb273e", "vector": [-0.22933134, 0.76299644, 0.6833579, -0.36695513, 0.25454667, -0.00030731224, 0.5758099, 0.45641834, 0.22342959, -0.03908322, -0.017271256, -0.5574597, -0.18506117, -0.040933717, 0.005921948, 0.0071468293, 0.070366606, -0.028919008, -0.3456685, -0.3133843, 0.016498502, 0.27459738, 0.33088446, -0.07323268, 0.0105614215, -0.23355885, -0.09264257, 0.25579464, 0.021497086, -0.52789176, -0.32139176, -0.2754953, 0.3763863, -0.15999603, 0.042416878, 0.29391128, 0.20437893, 0.17791495, -0.32980683, 0.12672621, 0.06732342, -0.53937083, 0.23887667, 0.10916833, 0.12917557, -0.26276162, -0.18683174, 0.11982548, 0.16974632, 0.56424934, 0.010182125, -0.006573373, 0.10303353, 0.192336, -0.04042516, 0.21966204, -0.08022754, 0.31239158, -0.1066293, -0.0886661, 0.5599635, -0.20417099, -0.93458, 0.85551816, 0.16465017, -0.2698716, -0.33038336, -0.4014472, -0.4975047, 0.19516735, -0.10087228, -0.24995175, 0.40390468, -0.2900557, 0.051350035, 0.09622594, 0.27803573, 0.0486416, -0.51184595, -0.16419828, 0.25551048, 0.33959296, -0.15028527, -0.4186433, 0.21248834, 0.3442201, 0.15043935, 0.019828498, 0.14394322, 0.0049162, -0.16761392, 0.3442203, 0.8514695, -0.083332054, -0.2054945, 0.2658794, -0.03414201, -0.465983, -0.42504868, 0.6287594, 0.14049803, 0.12203665, -0.070513144, -0.31569362, -0.696865, -0.081781045, -0.20272693, -0.018919338, -0.009494744, 0.0066089155, -0.10063262, -0.117802, -0.19195594, 0.28437212, -0.13272586, 0.11379812, -0.3276587, -0.22171469, 0.3400405, -0.49849862, -0.14671017, -0.20434122, 0.079299316, -0.070384756, -0.91668236, -0.4584404, 0.17489913, 0.4982534, -0.18180361, 0.23834786, 0.075296305, 0.03115435, 0.3866811, 0.35530466, -0.4490091, -0.36113986, -0.95813143, -0.45761585, 0.24629283, 0.07396505, 0.4033528, -0.07874815, -0.015891224, -0.22789693, 0.10667066, 0.45210728, -0.17609262, -0.101159945, -0.082834944, -0.10953703, -0.17558174, 0.114335276, 0.85969895, 0.3820897, 0.3767025, 0.1716516, 0.71709543, 0.038092375, 0.15776153, 0.0797374, -0.18315955, -0.31363997, 0.35843354, -0.23388276, -0.35841465, -0.2688753, 0.12653573, 0.09586699, -0.013427568, 0.18276134, -0.13083611, 0.20625976, 0.20183721, -0.123570584, 0.18853465, 0.21192332, 0.675738, 0.2737326, -0.122645244, 0.34328973, -0.761641, -0.66953117, -0.16618654, 0.08657022, -0.05333654, 0.49861306, -0.34631836, -0.16933188, -0.17922203, 0.00047978162, -0.12455311, -0.18244307, -0.23239812, 0.21749401, 0.11767107, 0.15591122, 0.25964648, -0.21249878, -0.44392657, -0.14782213, -0.02070493, 0.13442554, 0.4005548, -0.54439527, 0.102501705, -0.10625613, 0.7208431, 0.137972, -0.41280127, 0.1807986, -0.2640273, -0.15381816, 0.34696254, -0.1641887, 0.06247164, 0.32710767, 0.0075125396, 0.15514089, -0.14094809, 0.20098487, 0.2117914, 0.42209345, -0.4758802, -0.6599654, 0.029788967, -0.10850197, -0.0032073737, 0.3739305, 0.43879643, -0.17640997, 0.2993539, 0.32835245, 0.3328857, 0.26656765, 0.09934716, -0.040653355, -0.46834603, -0.1316379, -0.31645155, 0.2561721, 0.061713774, -0.12959985, 0.046584707, -0.010340756, 0.1535211, 0.69192314, 0.006125939, 0.45835072, -0.32690877, 0.27272794, -0.7368618, -0.6121919, -0.5665077, 0.3271413, -0.039515913, -0.010809702, -0.464926, 0.3086844, -0.084512405, 0.08119154, 0.67672276, -0.9256214, -0.15639329, -0.20786819, 0.23887944, -0.16653636, 0.3627926, 0.45698613, -0.25104424, -0.16237628, -0.28779656, -0.23456101, 0.30291754, 0.16863635, -0.227406, -0.08237821, -0.1395478, -0.0022553415, -0.0599612, 0.5533924, -0.09371365, -0.109706424, 0.07652725, -0.00020807385, -0.59327567, -0.01475977, 0.48926863, 0.05158285, 0.27575815, 0.037363436, 0.05622651, 0.32846102, -0.107100405, -0.19137725, -0.08334293, 0.2219398, -0.05122765, 0.32802606, -0.26865062, -0.09557225, -0.06603919, -0.013883579, -0.011754533, -0.1741037, 0.55510247, -0.27013212, -0.36783653, 0.6382454, -0.17291766, -0.38788062, 0.25048533, 0.07841925, 0.34074506, 0.67350215, 0.07068072, -0.15357915, 0.23158875, 0.31766465, 0.60359895, -0.2208281, 0.219493, -0.12898917, 0.059988488, -0.22067913, -0.081157744, 0.019702088, 0.013646081, -0.27074578, -0.21623318, 0.019604523, 0.085359655, 0.04034409, -0.30839124, 0.19537666, 0.35551423, -0.17930695, -0.11493175, -0.017640222, -0.22090907, -0.091247454, 0.23802046, 0.42177486, -0.17085883, 0.019980371, -0.027142107, -0.0630595, 0.04621299, 0.09501145, -0.20714049, -0.44703466, 0.31949073, 0.5972026, -0.03250522, -0.1690658, 0.053488605, -0.17461887, 0.36451772, -0.1412524, 0.32393593, -0.70002365, 0.33298033, 0.13637674, -0.21752891, 0.64649117, -0.05418595, 0.1692721, -0.30017483, 0.1904184, -0.57708114, -0.29860565, -0.176285, 0.12197522, 0.33492407, -0.1246534, -0.19301751, -0.352294, 0.07185949, 0.0862939, -0.11184587, -0.18896477, 0.17627652, -0.17662612, 0.57033175, -0.101205006]}, "content": "Thank you. ", "podNum": 30, "speaker": "Chris Dossman"}, {"_additional": {"id": "ec80df48-0410-4f28-b267-d3d1a9d63d2a", "vector": [-0.048605535, -0.05148993, 0.010332791, -0.18555348, -0.09534746, 0.0024645687, 0.38745478, 0.09510054, 0.028104126, 0.019244922, -0.1842819, -0.12719999, -0.00902386, -0.030115018, -0.051125444, -0.038888656, 0.14373174, -0.3716324, -0.45264715, -0.1867956, -0.22909892, 0.17891635, 0.24090162, 0.0058257356, 0.0379753, -0.097342975, -0.18391445, 0.15561672, -0.16818067, -0.1377086, 0.14687678, -0.14922382, 0.09214542, -0.18421184, -0.09892662, 0.29618996, 0.24464121, 0.04007622, -0.12294352, -0.0043284297, -0.028597359, -0.4661006, -0.08175125, 0.07067389, 0.027671864, -0.21033545, 0.044435658, -0.0010998056, 0.30486822, 0.3105374, 0.14192751, -0.16145495, 0.00124368, -0.23094311, -0.00011610538, 0.3080841, 0.039027475, 0.050919395, -0.046733968, -0.2296911, 0.28058416, -0.19590516, -0.4378748, 0.8425528, 0.1588712, -0.4053332, -0.014045465, -0.24052289, -0.30805248, 0.34320483, -0.07305603, 0.120644584, 0.34647697, -0.11901502, 0.06714006, 0.056466382, 0.13741586, -0.12335895, -0.25578016, -0.24173248, 0.115395404, -0.4345166, 0.10611315, -0.3213258, 0.24852152, 0.00557729, -0.09867923, 0.08717324, -0.17680612, -0.033122152, -0.542512, 0.2406334, 0.33997363, 0.0077122925, -0.15534845, 0.23340122, -0.010594259, -0.2942035, -0.25906038, 0.5152059, -0.05355527, -0.033018574, 0.13373086, -0.3776339, -0.1009449, -0.21152668, -0.04615762, 0.14231905, 0.04384463, -0.22118135, -0.027019361, -0.11558702, 0.07663363, 0.16136833, 0.19616354, 0.33696562, -0.0073967995, 0.08009964, 0.36733788, -0.36316973, 0.013681901, 0.014210284, 0.23121493, 0.025740832, -0.2092119, -0.37623852, 0.52585584, 0.2761856, 0.1930202, 0.057695936, -0.023522526, 0.21622626, 0.29378465, 0.54493874, -0.3396898, -0.20206062, -0.1224073, -0.06364403, -0.022944301, 0.1750687, 0.13566312, -0.011414601, 0.16174516, -0.28581634, -0.4447671, 0.037636176, -0.08079465, 0.03893842, 0.10590259, 0.15063182, -0.17182472, 0.3279826, 0.38922897, 0.040650792, 0.47380528, 0.12235884, 0.25621793, 0.21586609, 0.075411275, 0.013387471, -0.23495892, -0.10727763, 0.075144745, -0.08877085, -0.28696784, -0.29386157, 0.01718635, 0.3303156, -0.10029252, 0.16269238, -0.2723318, 0.05453675, 0.04967412, 0.20206156, 0.09846403, 0.033584304, 0.28021783, -0.02207235, 0.15191296, 0.15439819, -0.12904948, -0.0048241196, 0.09813368, 0.18326852, -0.19355056, 0.23211285, -0.11029123, -0.11829166, 0.0427622, -0.322258, 0.17870827, -0.29945016, -0.32042998, 0.29636186, 0.2826957, 0.2510127, 0.1338872, -0.02393272, -0.05274155, -0.0052051367, -0.22088178, -0.5243219, 0.2784242, -0.34573296, 0.3731532, -0.28171176, 0.39077216, 0.022794219, 0.09909181, -0.03138035, -0.14637378, -0.17706908, -0.027810942, 0.14223823, 0.03188341, -0.14174291, -0.2964653, 0.13838942, -0.10898924, -0.10987697, 0.3017749, -0.08598605, -0.0969767, -0.63342106, -0.07166454, -0.23748922, -0.1580684, 0.25472122, 0.2531111, 0.09137319, 0.017878335, 0.20078115, -0.24732319, -0.039094083, 0.062222015, -0.04613685, -0.027692964, -0.09765501, -0.10677612, -0.07669282, -0.08614789, 0.017062664, 0.18398073, -0.010472047, 0.35183692, 0.4481841, -0.21762839, 0.4131825, -0.3565386, 0.2774498, -0.3632134, 0.05075445, -0.29258278, 0.20673966, -0.2589496, 0.119420625, -0.3499347, -0.16244188, -0.085913695, 0.36446038, 0.50779676, -0.39436728, -0.31229395, -0.23596136, 0.10548894, -0.21094593, -0.08712739, 0.78587216, -0.12337506, 0.09831609, -0.2565356, 0.10010378, -0.17399816, -0.028495762, -0.25144753, 0.24968898, -0.21768114, -0.05662369, -0.26066223, 0.20901361, -0.039524592, -0.047183048, 0.18151462, 0.15865764, -0.33021855, -0.18999055, 0.08846397, 0.044216663, 0.026721623, 0.035296787, 0.13884036, 0.029099574, -0.30730543, 0.14998339, -0.061604083, -0.046287935, -0.20381923, 0.31366047, 0.20704293, 0.26232645, 0.10319243, -0.0003073931, -0.10829131, -0.0031896054, -0.0704379, -0.2477698, -0.2582998, 0.314418, 0.13979347, -0.085536815, 0.18240449, -0.19360928, 0.03884731, 0.3981766, 0.18080807, 0.017825741, -0.028444339, 0.0572595, 0.2202464, -0.21786204, 0.09434874, 0.15048979, -0.12356839, 0.046608847, -0.10289218, 0.30839747, 0.061965514, 0.1368006, -0.26462886, -0.19990854, 0.25223976, 0.043268483, -0.1446346, 0.2986142, 0.56183755, 0.3776245, -0.17586249, 0.1669819, -0.1847824, -0.01775505, 0.07712688, 0.24735303, 0.34427944, -0.038861938, 0.078058325, 0.00030281246, 0.2042627, 0.24996586, -0.17572565, 0.00087691547, -0.18324104, 0.12544812, -0.24322644, -0.14950402, 0.16134158, -0.06125444, -0.05911102, -0.27867508, 0.2098153, -0.6286715, 0.21945652, 0.19013818, -0.08424423, 0.48450193, -0.17901942, 0.15325284, 0.0101844845, 0.0692444, -0.27979445, 0.03046757, -0.2517925, -0.21199986, 0.124338225, -0.046169057, 0.14915915, -0.28553313, -0.047335047, 0.09824169, -0.22139685, 0.17059544, 0.42669064, -0.01270475, 0.28629407, -0.19746771]}, "content": "Yeah. Well, thanks again, Jonathan. Thanks so much for doing the Weaviate podcast. And it's awesome. So excited about these things. ", "podNum": 26, "speaker": "Connor Shorten"}, {"_additional": {"id": "ecb9e733-e3ff-4edd-a7c6-00c05cdc3537", "vector": [-0.09309225, -0.29909655, -0.10472298, -0.18423909, 0.13755216, -0.12694444, -0.09708207, -0.1860341, 0.18982515, 0.048824478, 0.11214476, 0.23777603, 0.21895933, -0.07193783, 0.10760512, -0.112143524, 0.033253096, -0.13582508, -0.4377182, -0.066629246, -0.32284927, -0.045967557, 0.09457498, 0.019443575, 0.05947106, 0.11177195, -0.018188411, -0.07458528, -0.24010324, -0.14469701, -0.03258127, 0.28294614, 0.12446645, -0.17613393, -0.22803952, 0.098779246, 0.04243736, 0.06990702, 0.15874292, -0.07199852, -0.13497838, -0.13942747, -0.031985138, 0.19812185, -0.06959135, -0.035217214, -0.093480416, 0.014220952, -0.112584665, 0.012125205, -0.10924482, 0.07522773, -0.04450662, 0.08173339, -0.107891224, 0.15824364, 0.056694195, 0.015889581, -0.021354692, 0.0407437, 0.09116426, -0.21161409, -0.19951214, 0.3308575, 0.09990437, 0.08552184, 0.02455796, -0.2701094, -0.09147382, 0.108786985, 0.05073246, -0.07738274, -0.12128196, 0.113620736, -0.08111056, 0.06746333, 0.113814786, -0.11197733, 0.14602493, 0.13087709, 0.02184203, -0.06446714, 0.1503753, 0.17015794, 0.11619203, -0.026795628, 0.021095581, 0.08390981, 0.07394617, -0.021808343, -0.17970428, -0.17491917, 0.057346486, -0.08350023, -0.009928267, 0.15963489, 0.046001866, -0.22649607, -0.108266585, 0.14978096, -0.33978415, 0.1086044, -0.08687628, -0.4914877, 0.07140971, -0.2827997, -0.10508775, -0.09750013, 0.07906472, -0.23262596, -0.103823684, -0.044855684, -0.06884297, 0.07784798, 0.11631968, 0.04445285, -0.20937033, 0.113142654, 0.109680764, -0.18216577, 0.049137045, 0.021197125, 0.116339445, 0.07568401, 0.22988239, -0.029770296, -0.043434765, 0.13491601, 0.118190356, 0.171374, 0.08224731, 0.038252532, -0.014091745, 0.079927094, -0.078336254, -0.02362526, 0.31179783, -0.26702082, -0.1558826, 0.14458527, 0.09875682, 0.2868722, 0.14220619, 0.1820444, -0.21083528, 0.29012334, -0.026879756, -0.05829916, 0.15525371, -0.14901204, -0.041817293, -0.08854278, 0.25072312, -0.29634172, 0.09648163, -0.09007505, -0.055581905, -0.0007521693, -0.062147234, -0.023474801, -0.09375718, 0.09284008, -0.12402704, -0.03955772, 0.10026894, 0.016029999, 0.021851968, -0.076433666, 0.12336703, 0.26401758, -0.034227755, -0.0351863, 0.20091319, -0.038287755, -0.050011996, -0.022282822, -0.35187584, -0.10162301, 0.116167076, 0.1805023, 0.14686045, 0.092903286, 0.14459251, 0.1340167, -0.05793416, -0.018439032, 0.014726331, -0.011617731, -0.09964097, -0.021908693, -0.10286076, 0.08169833, 0.12435462, 0.23204327, -0.0020222447, -0.08878118, 0.260589, 0.14557816, 0.08705609, -0.1750706, -0.46261483, -0.12419531, -0.10706704, -0.10882302, 0.0567929, -0.21693006, 0.14592603, 0.10212524, 0.0056987596, 0.07225764, -0.09297282, -0.12057871, -0.17102312, 0.11309988, 0.19239639, 0.100598976, -0.19243526, 0.026935529, 0.014894908, 0.06842917, -0.11315035, -0.21945542, 0.0047322186, -0.3519297, -0.37364092, -0.4544733, -0.019628154, 0.15169589, -0.026100434, 0.051065207, 0.13166048, 0.0033736797, 0.042455826, 0.0023031556, -0.18514174, -0.12233887, 0.12737024, 0.02904408, 0.044423398, 0.0064977678, -0.17301115, 0.029501503, 0.1336944, 0.032431427, 0.021834146, 0.1346199, -0.16178077, 0.16731872, 0.12740897, 0.14110576, -0.10373121, 0.06088272, -0.1157443, 0.004789095, -0.19007617, -0.12546894, -0.30832025, 0.13089241, -0.0057719704, 0.24524905, 0.09826501, -0.09703116, -0.06979567, -0.016109502, -0.010758311, -0.015913663, -0.2296052, 0.17879993, -0.24715005, -0.10576825, -0.03367965, 0.164147, -0.06206659, 0.012161371, 0.21341595, 0.17915395, -0.042686295, -0.06274992, -0.2011345, -0.07631076, 0.023544155, -0.21437563, -0.016328452, 0.15493323, 0.09553831, -0.18779589, -0.014160544, -0.051727172, 0.04299126, -0.04116179, 0.079746336, 0.23809867, -0.15000105, -0.042208925, 0.32025087, 0.030867858, -0.056783985, 0.0051702857, 0.102914594, 0.2843888, -0.0031562282, -0.061539594, -0.16047159, -0.21192573, -0.091130026, -0.116082065, 0.15086544, 0.116088025, 0.022362867, 0.027539672, 0.14905356, -0.03202979, 0.14664544, 0.01691906, -0.07943604, -0.03612467, -0.36372098, 0.060637582, -0.14896283, 0.033996508, 0.05477637, -0.08557058, 0.072250575, 0.3598344, 0.05801302, 0.1663184, 0.18478793, -0.039097454, -0.15574244, -0.1391391, 0.15026128, -0.0977199, 0.06621, 0.11147123, 0.30992696, 0.33801442, -0.059929144, 0.04454279, -0.11611461, 0.057394933, 0.24306768, 0.07190624, 0.13269752, 0.041494027, 0.07411635, 0.10423853, -0.0074808057, 0.38436174, -0.07516364, 0.009099241, -0.062090013, 0.106058665, -0.023983032, 0.02702906, 0.2831436, 0.0009671531, -0.073166825, -0.07038567, 0.03662256, -0.28176352, -0.11142386, -0.09570072, -0.14062887, 0.36104593, -0.050914034, -0.026180267, 0.17169106, -0.16993116, -0.050263405, -0.020301335, 0.06970866, 0.088029616, 0.14271139, -0.05664617, 0.072729714, 0.106671475, -0.078000315, -0.021433808, -0.24496542, 0.22523494, 0.15891792, 0.2599983, 0.30875018, -0.046593413]}, "content": "You know, I just to add a little bit, I maybe don't see it as a difference at all, actually. And maybe that is just intelligence. It's picking the next right word, right? How much of really great podcasting is just knowing what to say when, right? Predicting the most effective, like, maybe we have that ability internally as humans, but we're just now getting to the point where we figure out how to do it with computers. And I'd like to think that there is the same type of intelligence that we have for natural language processing, they are gaining, like, at least the ability. And you know, it's, it's truly, I think, intelligent. And what's missing is the persistence aspect of it. Like, the problem is none of these systems persistently exist over days, weeks, months, years, and so have no ability to, to form, like, long term memories. And I think that's when we would start to wonder whether or not they truly are intelligent when they have that persistence. They're sort of like at call right now, and only exist for a short time before they're, you know, scrubbed, and then like, refresh somewhere else. ", "podNum": 30, "speaker": "Chris Dossman"}, {"_additional": {"id": "edcc0489-138e-44a5-9e39-2a6414ecd9b5", "vector": [0.00060769916, -0.08955166, -0.21621604, -0.34577176, -0.27719966, -0.21109845, -0.32298765, -0.14877291, 0.15574418, 0.0017769883, -0.22709663, 0.37388182, 0.18291862, -0.014303033, 0.13953136, 0.042466328, -0.07717221, -0.17268701, -0.44249198, 0.11388796, -0.17882395, -0.07998641, 0.1083977, 0.037428763, -0.011419331, 0.19184935, -0.08106499, -0.14826407, -0.08513406, 0.122838855, 0.099045664, 0.4899086, 0.18922208, 0.018833399, -0.073932216, 0.1218402, 0.087128885, -0.013730253, 0.005462011, -0.00045822063, -0.12819788, -0.007348159, -0.038450453, 0.15331489, 0.03377383, -0.20663397, -0.19841182, -0.041281257, -0.20027803, 0.18018647, -0.19277309, 0.20547055, -0.12561028, 0.22897463, -0.12211057, 0.01836907, 0.042693447, 0.09816604, 0.04883136, -0.054701954, -0.0033566058, -0.018758709, -0.072226964, 0.3096079, 0.19483866, 0.158025, 0.07702767, 0.17998476, -0.04330696, 0.06267724, -0.18123396, -0.20854127, -0.10652781, 0.1884226, 0.12554239, -0.12566492, -0.19624174, -0.015952991, 0.14234966, -0.1459539, 0.3058178, 0.1118323, 0.12865378, 0.06928601, -0.004658302, -0.087090336, 0.088525034, -0.2519572, 0.11872098, -0.26376554, -0.010222997, -0.23095195, 0.40841857, 0.30758384, -0.095028855, 0.038187232, 0.12913947, -0.007923148, 0.20691949, -0.007871841, -0.23355639, 0.2404648, 0.20110922, -0.29928064, -0.13208379, -0.23753579, 0.24264865, 0.046412647, -0.09543869, -0.0054632276, -0.07484377, 0.03614526, -0.16690426, -0.41029748, -0.05371264, 0.036044642, -0.091603614, 0.021121109, 0.27138516, -0.0038469073, -0.013269395, -0.116659485, -0.07824577, 0.051718872, 0.17051314, 0.024769872, -0.25730342, 0.20273916, 0.2358792, -0.027396327, 0.004857195, 0.14750761, 0.103733204, 0.11323824, 0.15849577, -0.11885319, 0.08269933, -0.2207454, -0.061215755, 0.30029976, 0.20373861, 0.13196965, 0.09813177, -0.18214434, -0.24033113, 0.37218675, -0.2669295, -0.062988885, 0.12561476, -0.1564036, 0.20370458, 0.026176028, 0.36875224, 0.0018430998, 0.06518798, -0.06369916, 0.08763427, 0.08849185, -0.29888, -0.029393315, -0.21815568, -0.026255747, 0.046477105, 0.076227404, 0.25740245, -0.17792805, -0.00041284412, -0.2765219, -0.15534328, 0.033537924, 0.21047395, -0.1394778, -0.014136943, 0.1254584, 0.10095393, -0.13567801, -0.27608147, 0.09324058, 0.16310157, 0.102463625, 0.03759884, 0.27223906, 0.122702874, 0.020022431, -0.26520017, -0.037367165, 0.33493972, 0.039794814, 0.14566268, -0.10897589, -0.10625327, 0.045161426, 0.29952136, 0.0784303, -0.14732963, -0.051728774, 0.40432462, 0.13226269, -0.17977928, -0.033523854, -0.303817, 0.035624627, -0.16999735, -0.06353007, 0.033792764, 0.08664661, -0.015057768, -0.057502303, -0.23882495, -0.021134019, 0.06766126, -0.020123554, -0.1445735, 0.1729421, 0.084972255, -0.09575536, -0.23440818, 0.11714289, -0.25773254, 0.014452805, -0.052799452, -0.085498214, 0.13350667, -0.38957444, -0.14551568, -0.094817795, -0.15211304, -0.0035049617, -0.100391306, 0.10530778, 0.014768343, -0.1215638, 0.06577306, 0.10211279, -0.07524208, -0.062060773, 0.24714005, -0.071452595, 0.09753712, -0.16355345, 0.09123343, -0.08175488, -0.0965074, 0.05678683, 0.044284653, -0.14597322, -0.20720641, -0.014503613, 0.23388678, 0.037585214, -0.06791999, -0.3076273, 0.04302977, 0.14862652, -0.052793864, -0.16880584, -0.3886956, 0.07344759, 0.045470756, 0.2170517, 0.16152592, 0.05142657, -0.008824517, -0.017706448, 0.19100945, 0.050628085, -0.08895948, 0.06144305, 0.0006746898, 0.024512118, -0.3171993, 0.18103886, -0.062140767, -0.12816246, 0.34923914, 0.13383579, 0.081199296, -0.39673948, -0.1354842, 0.031284973, -0.011693199, -0.07049439, 0.057815474, 0.033828124, 0.1369064, -0.08822432, 0.04593593, -0.0823681, 0.09296787, -0.31184503, 0.029587751, -0.39634332, -0.07910198, 0.13669646, 0.009140161, -0.17675526, -0.21310908, 0.26737443, 0.40875623, -0.082160704, 0.08437937, -0.23512878, -0.33419183, 0.012379177, -0.008135612, 0.0408368, 0.10599389, 0.13607891, 0.26777393, 0.060267944, 0.11073914, -0.08767778, -0.20536478, 0.14381571, 0.0019820656, 0.0748794, -0.09551761, 0.24398024, -0.19148612, -0.11768042, -0.056107014, 0.019197594, -0.01884365, 0.013659912, -0.0561371, 0.14227806, -0.1922818, 0.25897953, -0.009403319, 0.09248782, 0.33494332, -0.06404691, -0.29567388, -0.05446424, -0.0852344, 0.12909247, -0.03369395, 0.04777956, -0.2103793, 0.11129003, 0.23490949, 0.07480121, -0.05978441, 0.07787148, -0.009931768, 0.20656407, 0.054836843, 0.39795282, 0.07169076, -0.2751166, -0.09568548, 0.40007365, -0.20667414, 0.059444, 0.039300922, 0.056850422, -0.103703715, -0.04236519, -0.011912361, -0.16802919, 0.21446903, -0.08904321, -0.14240958, 0.39069077, 0.19819407, 0.138749, -0.084509216, -0.08697883, -0.044814, -0.044100355, -0.11516181, 0.04000079, 0.18911977, 0.1570061, 0.06472827, -0.059020102, -0.04123384, 0.052842468, 0.12861873, 0.19539481, 0.08134547, 0.08318628, 0.006633436, 0.06331932]}, "content": "From guiding my thinking with these four things, I've kind of started to put long documents and multi discourse, kind of together into the same category where I mean, yeah, long documents is such an interesting problem. I think with the ChatGPT and like the dialogue models particularly, it's making a lot of people think about this. So here's maybe what I've been thinking about and I'm really curious what your thoughts are on this, is sort of clustering the windows, and then because you embed the windows of the long document and then you kind of cluster it and then you have sort of a representative centroid that you try to pack into the context window, sort of, and maybe also in addition to, you know, the retrieving facts and it's some kind of prompt designed to overcome the long document limitation.", "podNum": 33, "speaker": "Connor Shorten"}, {"_additional": {"id": "ee0ed7a3-1089-4826-847b-d86a99e76a27", "vector": [0.06274837, -0.21274598, 0.076028034, -0.15141569, 0.056386713, -0.088053286, 0.028082788, -0.0058239815, 0.23841704, 0.030971058, -0.04500185, 0.14463943, 0.07938563, -0.030404707, 0.038951587, -0.0955174, 0.40645167, -0.080285326, -0.1717609, 0.023826769, -0.31850627, 0.0048441268, 0.04272509, -0.039429594, -0.052819084, 0.032502707, -0.13839422, 0.06447306, -0.2107635, 0.0152889425, 0.15206647, 0.2074017, 0.11258864, -0.3376249, -0.27061632, 0.09172633, 0.21941239, 0.09116254, -0.030685931, 0.093566954, -0.18180762, -0.045295525, 0.051945824, 0.18092583, -0.03575513, -0.1326621, 0.039718222, -0.14541923, 0.064184785, 0.053774208, -0.02315403, 0.10481367, 0.061473068, -0.031113869, -0.113969564, 0.10710058, 0.1415402, -0.08902126, -0.09761358, -0.02094484, 0.24746235, -0.123151235, -0.15805899, 0.44533673, 0.24235606, -0.13708368, 0.0905235, -0.16006495, 0.0005701979, 0.25230107, 0.02489082, 0.010928121, 0.20845109, 0.19753055, 0.06352819, 0.060477864, 0.08213415, -0.101377465, 0.07433751, -0.11175261, 0.15728538, -0.15342294, 0.083687745, 0.05220741, -0.024400083, -0.012575075, 0.12511425, 0.12861891, -0.064207874, -0.05096068, -0.28818902, 0.064376436, 0.019406656, -0.1162864, 0.06265762, 0.14176242, 0.051337812, -0.19288437, 0.049349565, 0.19870193, -0.12352731, -0.008634173, -0.01277813, -0.26149592, -0.001969713, -0.38181683, 0.030617965, 0.11043825, 0.11349436, -0.12089931, -0.14416815, 0.014406634, 0.014551395, -0.0997867, 0.026431927, 0.09082339, 0.0512632, -0.039855603, 0.37023434, -0.1944247, 0.030582301, -0.09477078, 0.034775544, -0.0016747663, 0.08642471, -0.13520682, -0.05183894, 0.11566917, 0.105805755, -0.037701767, 0.14126766, -0.22760165, 0.24339068, 0.20318101, -0.2996352, -0.14165972, 0.24607635, 0.1426141, 0.075820066, 0.13850094, 0.013763155, 0.31527483, 0.034025002, -0.11699768, -0.44271287, 0.11615322, -0.16760714, 0.014489643, 0.08260449, -0.1886669, 0.08271277, 0.14275655, 0.16905613, -0.13913448, 0.22801338, -0.024465367, 0.07150517, 0.086164325, -0.10206088, 0.062607065, -0.00750644, -0.15456282, -0.17129086, -0.055585656, 0.0007646028, -0.028455881, -0.11520126, 0.020495558, 0.059436608, 0.0637238, -0.074833415, 0.056805506, 0.04103326, 0.112205796, -0.09468915, -0.15294157, -0.3074306, 0.14375944, 0.1304933, 0.056555763, 0.016915793, 0.07166744, 0.0042137387, 0.43685225, -0.122248136, -0.06609108, -0.13206641, -0.11455058, -0.08698279, -0.15356506, -0.07624584, -0.39125457, 0.012341515, 0.28382635, 0.078510486, -0.006437504, 0.272886, -0.024440033, -0.19427031, 0.005509615, -0.31766075, -0.27654117, 0.04509248, -0.05853042, 0.082820244, -0.1665561, 0.359738, -0.116775334, -0.103008516, -0.0023415585, -0.065879114, -0.23929006, -0.27419072, 0.21539803, 0.07312048, 0.047220003, -0.2544721, -0.0074070357, 0.055385247, 0.13682748, 0.005458221, -0.19979306, -0.09197561, -0.48826346, -0.54704833, -0.29268637, -0.08638076, 0.12456477, -0.0533774, 0.2265869, 0.16550308, -0.0060046366, 0.098335184, 0.014391814, 0.086250335, -0.0002999492, -0.056138698, -0.06806771, -0.22212245, -0.071783684, -0.17116223, 0.13715924, 0.1078204, -0.01231888, 0.28083268, 0.26131418, 0.12740499, 0.22022109, -0.05285843, 0.30558386, -0.22113688, -0.024106205, 0.016996874, -0.08677691, -0.21932733, 0.0627246, -0.36986217, -0.024018051, 0.090386875, 0.18020304, 0.26669633, -0.25164485, -0.22860713, -0.1727683, -0.04925253, 0.1146699, -0.060628936, 0.2983789, -0.12896863, -0.044534344, -0.35275862, 0.26548526, 0.16451089, -0.17442553, -0.19649422, 0.053290218, -0.039903075, 0.056023058, -0.15593913, 0.027643235, 0.097974755, -0.06410316, 0.18605506, 0.28327665, -0.044593275, -0.048143342, -0.13859208, -0.039226215, 0.13611758, 0.025615795, 0.14044368, 0.020931685, -0.007182233, 0.18546672, 0.07081013, 0.026932484, -0.19485855, 0.14616682, 0.2623676, 0.003533845, 0.24158426, -0.12197962, -0.13976042, -0.16323425, -0.1285849, -0.06869557, -0.002002705, 0.20833196, 0.1536236, -0.035813857, -0.06706754, -0.01109112, -0.036486574, 0.17986965, -0.056014806, 0.11918479, -0.3968872, 0.014897806, 0.06787784, -0.15773404, 0.011425034, -0.14797662, 0.04043607, 0.15428127, 0.05974881, -0.017546697, -0.055947196, -0.020783959, -0.19314237, -0.3093796, 0.19817156, -0.06639918, -0.332733, 0.19504915, 0.27100715, 0.29653427, -0.056707907, 0.14643116, -0.09368217, -0.018105075, 0.059607018, 0.18116789, 0.0894415, -0.033482537, 0.13103622, 0.24409087, 0.25537327, 0.07103394, -0.084522866, -0.03198347, -0.21004803, 0.29410538, -0.20429097, -0.07283806, 0.141434, 0.14186956, -0.16785198, -0.17454444, 0.20555747, -0.42365086, 0.109421976, -0.042788997, 0.021167284, 0.3271214, 0.07948067, 0.12457428, 0.018227765, 0.036415327, 0.019307299, 0.09816713, 0.08611565, -0.09088612, 0.0692251, 0.027844852, 0.035217296, -0.09174037, 0.019595943, -0.047601033, -0.16001096, 0.2407251, 0.35980007, 0.10212034, 0.13757242, 0.04469484]}, "content": "Uh, it's so interesting. And, uh, another kind of podcast we did was with Ori Ram on, uh, the spider algorithm, learning to retrieve without supervision, how, um, you look for overlapping terms to form the positives. And as you mentioned, the noise and the negatives. I've always been so interested in that kind of thing. So what, so what are you thinking currently about the positive negative sampling scheme? Is it, uh, you know, like just adjacent paragraphs are positives, and then if you do that at scale, it kind of like makes it all right.", "podNum": 33, "speaker": "Connor Shorten"}, {"_additional": {"id": "ef666de3-6e74-4cab-bd9e-b9de86264a3b", "vector": [0.05875256, -0.19553706, -0.0057815253, -0.2076705, 0.0822743, -0.20491147, -0.0786093, 0.11733129, 0.084055126, 0.0055900305, 0.20604777, 0.14440803, 0.14483517, -0.06024582, 0.067769356, -0.03139142, 0.10103402, 0.012148639, -0.34641206, -0.04803481, -0.38557547, -0.24250326, -0.035881046, -0.015236795, 0.005576402, 0.14361796, -0.055887967, 0.0071807667, -0.2186819, 0.045874126, -0.15752941, 0.1649415, -0.022224523, -0.10507514, -0.21391281, 0.029913783, -0.1362545, 0.2515188, -0.30135545, 0.17084232, -0.16168106, -0.09713954, -0.11459615, 0.4087254, -0.07506214, -0.089553006, -0.035618857, -0.17012958, -0.1632162, 0.38510373, -0.017722378, 0.04406606, -0.15448585, 0.069031596, -0.033947453, 0.13363767, 0.22839832, 0.026979024, -0.1329153, 0.18701848, -0.028594565, -0.2004315, -0.27676874, 0.32195503, 0.26269224, -0.10399399, -0.012322384, -0.16169196, -0.21326339, 0.12167035, -0.095812045, -0.15057085, -0.100287005, 0.019236077, -0.17591816, -0.07809275, -0.077284046, -0.020503435, -0.016128248, -0.2041254, 0.30561668, 0.16800869, -0.07627313, -0.01649821, 0.057627846, 0.065332785, 0.0047358214, -0.088571124, 0.054658897, 0.034398157, -0.100903556, 0.06133914, 0.105752215, 0.08087362, -0.024623508, 0.23410599, -0.007897049, -0.15859991, 0.4610878, 0.15600054, -0.24291888, 0.20481837, -0.20935977, -0.3368156, 0.12161491, -0.395364, -0.049185652, -0.022652369, 0.00809885, 0.17229821, -0.122418545, 0.18055892, -0.15250994, -0.11435743, 0.09317224, -0.18862595, -0.28960925, 0.09337236, 0.108524606, -0.18382856, 0.10751269, -0.20489733, 0.0014004376, -0.1318258, 0.16041589, -0.11503748, -0.11333571, 0.20615451, -0.15671177, -0.15551138, 0.17971542, -0.10637897, 0.28725687, 0.119791314, -0.14440551, -0.043952715, -0.09556584, -0.07236347, -0.1735587, 0.32818308, -0.09184784, 0.11867303, 0.13674805, 0.19128524, -0.36310583, 0.3521317, -0.11719863, 0.070105106, 0.17636982, -0.08879598, 0.15101881, 0.11895921, 0.28108746, -0.07442187, 0.08770813, -0.05983045, -0.1342478, 0.09687825, 0.115176976, -0.0827315, -0.35679308, -0.35186848, -0.23746368, -0.14142908, 0.28654227, -0.021273967, 0.10321735, -0.062090524, 0.051855832, -0.048741724, 0.068104886, -0.14903557, -0.30030686, -0.07325322, 0.08889726, 0.011692127, -0.17276135, 0.0644483, -0.056928467, -0.10763381, 0.12711738, 0.032364827, 0.0004000157, 0.24026756, -0.27017823, -0.19217496, 0.01781549, 0.10148239, 0.013168517, -0.13007295, 0.08189803, -0.08618232, 0.20420043, 0.13015036, 0.016632924, -0.42023602, 0.34516358, 0.27394295, -0.08846176, -0.008264141, -0.12181704, -0.09658186, -0.092230104, -0.34775215, -0.15956801, 0.16867694, 0.1935563, -0.198013, -0.06392263, -0.04651305, -0.027456423, -0.09189329, -0.29406232, 0.21335551, -0.056914322, -0.1570199, -0.28073224, 0.072288275, -0.3276217, 0.07725449, -0.2933357, -0.013716686, 0.06770092, -0.27692768, -0.54421574, 0.19371536, 0.09453458, 0.09507421, -0.08797117, 0.06677668, 0.39469013, -0.21492541, 0.037677027, 0.044069506, -0.21851969, -0.052939434, 0.14693648, 0.06416594, 0.015891302, 0.090156734, -0.03560456, -0.05568584, -0.26555443, -0.22990966, -0.048605252, 0.1233175, -0.004363528, 0.119947776, 0.11443953, -0.014683378, -0.25325114, -0.1853265, 0.08977009, -0.12904689, 0.16357335, -0.14655972, -0.2210697, -0.16301465, 0.027535796, -0.008213295, 0.2875563, -0.23071003, -0.08892415, 0.28756782, 0.25484008, 0.044995777, 0.109092966, -0.20144221, -0.18632352, 0.14226209, -0.0140594635, -0.039348222, 0.25619292, 0.07163413, 0.24825716, -0.0033732236, 0.21778841, 0.1411877, 0.0072697424, 0.10563697, 0.3382637, -0.2633807, -0.14694194, 0.023742106, 0.0055286316, -0.26036298, -0.15120211, 0.08943126, -0.10331522, -0.099658586, 0.06676774, -0.031642184, -0.11906195, 0.1559814, -0.05616904, -0.2004112, 0.12646449, -0.11826138, 0.26087758, -0.013507995, -0.17487699, -0.22747377, -0.014252772, -0.0024007857, -0.20953651, -0.14605173, 0.3401423, 0.27975976, -0.056059934, 0.06449616, 0.13795868, -0.018509533, -0.012072792, -0.17334767, -0.18966739, -0.073950805, -0.33051786, -0.00074049237, 0.14784072, 0.108957805, -0.067458585, -0.25720945, 0.44522342, 0.3577482, 0.16082902, 0.2871836, 0.16736947, 0.1808616, 0.088767394, -0.11811195, -0.0077437935, -0.04499329, -0.12591164, 0.0076212944, 0.20197363, 0.071754985, 0.07418899, 0.21250597, 0.08803641, 0.10717378, -0.023472283, 0.15273473, -0.035160005, 0.09933656, 0.029960614, 0.23391616, 0.040624507, 0.4139472, 0.17157961, -0.26522052, 0.23630163, 0.4289438, 0.09198687, -0.09334658, 0.35969925, -0.036887504, 0.08032761, -0.0011530519, 0.10499396, 0.13526568, 0.026221815, -0.015572578, -0.015213531, 0.48333272, -0.12110977, 0.2203848, -0.18915918, -0.039513417, 0.30338064, -0.015565509, -0.19615114, -0.06384362, 0.19937344, 0.068377554, -0.004222979, -0.06997225, 0.14263447, -0.13471207, 0.067183256, 0.22868295, 0.21673653, 0.056419592, 0.20069218, 0.048103794]}, "content": "It's more of the latter. You've got a model that's going to tell you for different... I think there's lots of literature out there that will tell you what does it mean to try to calculate user satisfaction from raw clickstream data. You have different formulations, and then you try, and for all of your different formulations, you try and figure out what does that mean for what does that mean for your more user-facing data? How do you take click data and correlate it with user data? Then how do you take the user data and then correlate it with your scores that you're going to get back from your more long-term studies?", "podNum": 32, "speaker": "Sam Bean"}, {"_additional": {"id": "ef7f6a6f-7f8a-4c09-909f-63711f22c075", "vector": [-0.25327536, -0.10337406, 0.10950599, 0.039582256, 0.0108553795, -0.15471882, -0.010094528, 0.0029188346, 0.28772506, 0.13956584, -0.058769222, 0.18229818, 0.22331423, -0.072999515, 0.42362615, 0.10572332, 0.19886303, 0.060128763, -0.42291656, 0.051862303, -0.045521554, -0.007853672, 0.036790337, -0.015805079, -0.017391475, -0.0022249173, -0.16107766, 0.09309375, -0.0960479, 0.012726471, -0.072203524, 0.27370325, 0.010491411, -0.097501874, -0.2190137, 0.15497093, 0.009203118, 0.15556067, -0.058976244, -0.016045097, -0.21115196, -0.12229007, -0.013593715, 0.16139208, 0.0648826, 0.06853948, 0.05748998, 0.15791598, 0.11591536, 0.011984034, -0.05605388, 0.056558352, -0.20243685, 0.13321018, -0.18670857, 0.08427345, 0.12318436, -0.037606362, -0.01252149, -0.14065225, -0.17417736, -0.12203041, -0.14504084, 0.28792667, 0.24710906, 0.03553709, 0.012462747, 0.08047617, -0.13501352, 0.12822734, -0.0017835125, -0.16602783, 0.17976649, 0.28878295, 0.09325057, -0.20450032, -0.06370649, -0.03513028, -0.019606007, 0.29591346, -0.018077517, -0.069707274, 0.15322305, 0.09112111, 0.03595, -0.022241531, 0.45956293, 0.16155456, 0.25437012, 0.06423222, -0.4167074, -0.07218569, -0.0059053204, 0.022593519, -0.04905875, 0.23623341, 0.06968355, -0.34893715, -0.021780336, 0.06608204, -0.09588636, -0.08774451, -0.10283742, -0.28190792, 0.21925603, -0.4116834, 0.07480467, 0.0888999, 0.094981104, -0.275323, -0.23379625, -0.00037396452, -0.08085789, -0.32530007, 0.002497236, -0.08165226, -0.015020758, -0.08266146, 0.11520165, -0.25079536, 0.10239595, -0.12465018, -0.22101806, 0.06982627, 0.033276763, -0.059323043, 0.0051626763, 0.08082408, 0.21525307, 0.08778038, 0.3016291, 0.09817809, 0.1657934, 0.05099565, -0.14864822, -0.22802621, 0.3236533, -0.009669145, 0.019107692, 0.083601445, 0.044656467, 0.44355083, 0.033436473, -0.09979239, -0.24448234, 0.23206525, -0.3075359, 0.011975735, -0.012285687, -0.0512802, 0.10007038, 0.075399846, 0.047001805, -0.13510941, 0.16553865, 0.019418437, -0.2386178, -0.028431946, 0.031724453, -0.0059245247, -0.15806174, 0.03369918, -0.07162967, -0.23005801, 0.09484122, 0.023962473, 0.06995379, 0.070585676, -0.13615601, 0.17350507, 0.18580566, 0.04408295, 0.12861602, 0.1520264, -0.17314346, 0.11286777, -0.46968707, -0.1055727, 0.0059774914, 0.21439666, 0.41950297, 0.29574645, 0.117426865, 0.28435287, -0.10691717, -0.10393157, 0.00010103484, -0.24368799, -0.111518286, -0.13724801, 0.057317227, -0.15545942, 0.14355741, 0.24510275, -0.15303011, 0.040608604, 0.1985306, -0.049842235, -0.052093882, -0.1018607, -0.20079434, -0.20080614, -0.11780595, -0.12444394, 0.0795019, -0.23836868, 0.27684674, -0.02668357, -0.038007833, 0.03147325, -0.11132839, -0.11977279, 0.041612666, 0.07980052, 0.07555706, -0.15983124, -0.22331262, 0.10834119, -0.3145311, -0.030142747, -0.046577413, -0.2155592, -0.06743785, -0.42357478, -0.13944848, -0.104715325, -0.12831871, 0.16424194, -0.018522976, 0.07912668, 0.1298703, -0.21375681, 0.25943264, 0.36659896, -0.19505192, -0.16394353, -0.17418504, -0.058408454, -0.103726685, 0.043488886, 0.12527123, 0.25087246, 0.15204154, 0.09737042, -0.1425335, 0.0776816, -0.1915033, 0.0895196, -0.012228708, 0.096189104, -0.12607299, 0.100403845, -0.018572474, 0.030000895, -0.43853316, 0.095625184, -0.41554558, -0.03683966, -0.23087563, 0.10433846, 0.20123978, -0.10066547, -0.058312196, -0.010305941, 0.17704262, -0.029013045, 0.09581035, 0.12848504, -0.2649454, -0.072190054, -0.27623647, 0.131649, -0.011070798, -0.021878982, 0.29462346, -0.101616204, -0.102910995, 0.064115204, -0.21337588, -0.34510228, -0.05488961, -0.2818674, -0.051376533, 0.415375, -0.025990771, 0.0348973, 0.07332488, 0.032272935, 0.07155663, -0.04275499, -0.011226535, 0.031319853, 0.20245206, 0.013929602, 0.07545414, 0.010305346, 0.059121866, 0.15824775, 0.037441906, -0.109642334, 0.16091558, -0.21167876, -0.33106557, -0.12556723, -0.09544867, -0.22770663, -0.0018308772, 0.09368938, -0.108134985, -0.18484522, -0.040402353, 0.13271229, -0.087928295, 0.08045056, -0.04307, 0.3220046, -0.13704632, 0.23060058, -0.26411417, -0.036107946, -0.12851678, -0.1287148, 0.0836533, 0.13834114, -0.13795124, 0.28758207, -0.0020422994, 0.015122798, -0.034391996, -0.41089854, 0.13004047, 0.09523249, 0.12428435, 0.08152031, 0.1937242, 0.15469052, 0.04080626, 0.03357848, -0.20771998, -0.011153299, 0.15960638, 0.12911743, -0.0504691, 0.046094894, 0.24123031, 0.08505104, -0.023884451, 0.19109069, -0.1463437, 0.069475144, -0.075143136, 0.1413501, 0.020852648, -0.0022792816, 0.2900728, 0.019955402, -0.17159027, -0.16660966, 0.14536409, -0.21351035, -0.03327975, -0.11518023, -0.1804832, 0.24245143, -0.08742628, -0.020473609, -0.06225356, -0.10999313, 0.036776442, 0.1859308, 0.1375753, 0.07638983, 0.13994096, 0.051115025, -0.027403673, -0.03859635, 0.05667405, 0.24376102, 0.12427885, 0.33160695, 0.35998356, 0.1808517, 0.2985858, 0.019728275]}, "content": "I think if I'm so I think there's two different like ways to use language models, I would say one is like leveraging their like reasoning ability, and their ability to like, you know, yeah, take ambiguity and decipher and decide what to do. And this comes into a lot of the action stuff. And then the other is generating text, right, generating prose generating poems. So for the latter, for like generating text, yeah, crank the temperature up, like get some like funky responses, go for it. But for like the part where you want to like reason about things, I almost always set like temperature to zero. And just because you want the single kind of like you want the best, most accurate response. ", "podNum": 36, "speaker": "Harrison Chase"}, {"_additional": {"id": "ef8adde8-22a8-4a14-b13e-46740be4b95b", "vector": [-0.08654109, -0.29375473, -0.22737174, -0.21362446, -0.11032349, -0.14223777, -0.04209235, -0.0009601389, -0.073192194, 0.09511974, -0.08954283, 0.019956222, 0.119175054, 0.06114191, 0.30702987, -0.17385368, 0.16735351, 0.0064429543, -0.51504964, -0.114325695, -0.22421499, -0.15370016, 0.09656488, 5.172814e-05, -0.0501781, 0.1469157, 0.048198257, 0.006901771, -0.020647703, -0.16194457, 0.028860962, 0.11776959, 0.017562997, -0.025717689, -0.2558327, 0.15172793, 0.039635997, -0.02049705, -0.017443603, 0.11571437, -0.15147631, -0.011333753, 0.043122817, 0.17339902, 0.042669218, -0.19183664, -0.21262182, 0.13379124, -0.044359695, 0.031131819, -0.13012268, -0.15988307, -0.14855154, -0.050861325, -0.042610932, 0.16655548, 0.22825484, -0.17688821, -0.2325963, -0.120037995, -0.17815538, -0.27764174, 0.009983242, 0.39272526, 0.104423575, 0.022803707, -0.10305554, 0.13803367, -0.043986548, 0.0006530459, -0.33905518, -0.080167264, -0.083515346, 0.20488508, 0.17034407, -0.34242436, -0.028787397, 0.07234635, 0.09642211, 0.044657916, 0.1286074, -0.15426502, 0.016368844, 0.09741351, 0.13314845, -0.056100618, 0.07678261, 0.017376833, 0.13885795, -0.03361483, -0.21358053, -0.060297552, -0.015915437, 0.07336741, -0.04245608, 0.2977508, -0.07569922, -0.2282302, 0.063486874, 0.19445544, -0.29937133, -0.073812, 0.27043846, -0.3112214, 0.09408894, -0.3295678, 0.06910897, 0.2017045, 0.22420765, -0.36716685, -0.08142796, 0.11291265, -0.02214512, -0.22031094, -0.113060415, 0.02977038, -0.02385728, -0.13757381, 0.24270351, -0.13406682, 0.01694446, -0.07159162, 0.114753015, 0.0025608465, -0.20868142, -0.14275283, 0.041639965, 0.115869105, 0.08497444, 0.13274913, 0.34681305, 0.12760384, 0.20265299, 0.12746428, -0.06438303, -0.23549564, -0.00953804, -0.05803524, -0.045353923, 0.10100848, -0.077875756, 0.28026947, 0.20647371, -0.21444617, -0.32402012, 0.38163927, 0.006796837, 0.21308236, 0.13013315, -0.11792924, 0.19514215, 0.03207009, 0.28216183, -0.03166965, 0.31264737, 0.004359767, 0.22263296, 0.19292492, -0.057078097, -0.17268418, -0.399346, -0.018563887, -0.09344254, -0.30210817, 0.23571275, -0.17630821, 0.029129574, 0.11084733, -0.02671217, 0.15242107, 0.052594554, -0.07618055, -0.11617417, 0.05907544, 0.06329535, 0.04593256, -0.24484313, -0.09814355, -0.039748635, 0.10895112, 0.102261424, 0.12066721, 0.33768404, 0.21676128, 0.06775071, 0.14008804, 0.11832747, -0.01873191, -0.13296568, -0.15112416, -0.1027483, 0.024969967, 0.078433916, 0.033015076, -0.13690338, 0.01728029, 0.3651241, -0.009750704, -0.16876042, 0.009798296, -0.20725274, -0.27763692, 0.031929784, -0.04609941, 0.10942855, -0.103583075, 0.20754349, 0.118016444, 0.03285284, 0.3675901, -0.11297711, 0.015089252, -0.15959601, 0.3750361, 0.13047145, -0.2464623, -0.25382367, 0.09045917, -0.24504389, 0.08283704, 0.043561082, -0.23160054, -0.11795471, -0.39783657, -0.22042775, -0.015999991, -0.3012732, 0.099479586, 0.09259092, -0.011024579, 0.19973011, 0.03469683, 0.023061475, 0.1340311, -0.11732615, 0.06489369, 0.29968575, -0.0484792, -0.09553999, -0.118362166, 0.1430021, 0.07207631, -0.002205994, 0.036366284, -0.000701389, 0.19061847, -0.28538087, 0.20872734, -0.09207579, 0.21754487, -0.3453801, 0.014153619, -0.0049454123, 0.06816455, -0.23185511, -0.013705048, -0.3133762, -0.1308624, -0.17316693, 0.28874356, 0.22170798, -0.25978962, -0.057573635, 0.09143108, 0.18620604, -0.12991051, -0.08347634, 0.13231356, -0.14356421, 0.039064806, -0.3876523, 0.23235567, -0.19601248, -0.009724389, 0.15733208, 0.1923759, -0.01650676, -0.43824112, -0.1850007, -0.27970645, 0.096014045, -0.23597403, 0.05585443, 0.2812147, -0.0726253, -0.113968164, 0.0613545, 0.16480295, -0.07570463, -0.20541453, 0.15514036, 0.10819212, -0.13608958, -0.042593878, -0.100864656, 0.009686717, 0.05348644, 0.35022733, 0.21094973, -0.045573354, 0.08046302, 0.024202948, 0.0017872687, -0.06668296, -0.35095534, -0.1013149, 0.1325049, 0.071379825, 0.19537659, 0.0346098, -0.07852273, -0.025105724, -0.12899013, 0.08045501, -0.21378247, 0.12207228, -0.17790239, 0.3308274, -0.087015264, -0.1679057, -0.15592088, -0.010535958, 0.29571834, 0.23216252, -0.23929888, 0.21897201, -0.09175851, 0.15916088, -0.091471575, -0.0644551, -0.06247887, 0.098454274, 0.081108846, 0.47621703, 0.25264814, 0.2261668, 0.17237973, 0.2231157, -0.04140194, 0.047369212, 0.26626503, 0.20169318, 0.04942469, 0.009738427, 0.036310192, 0.014483553, 0.101617955, 0.47999284, -0.049369976, 0.026076749, -0.19863081, 0.19780229, -0.23815763, -0.036551688, 0.264398, 0.09171019, -0.12663148, -0.18011115, 0.08976579, -0.24681987, 0.13601273, 0.066673845, -0.20426595, 0.44926977, 0.0055791833, 0.1876021, -0.03753103, -0.37803409, -0.010601468, 0.21639472, -0.14980076, -0.029640153, 0.14966016, 0.024574703, 0.1581592, 0.021885261, -0.032894295, -0.09432343, -0.051466405, 0.49884486, 0.45814493, 0.07773138, -0.252893, 0.050969232]}, "content": "Super cool. And so I want to kind of get into the applications of large language models. I think so like kind of transfer learning for some other task is a very popular one, say few shot learning. And then you've recently touched on a really interesting idea, which is language models as databases. You, you know, query the language model directly. Can you tell me more about your thoughts on that idea? ", "podNum": 26, "speaker": "Connor Shorten"}, {"_additional": {"id": "efa8ed4c-7ecd-44c7-8787-c32b61b84da4", "vector": [-0.05483333, -0.2992657, -0.115734145, -0.20595302, -0.070484646, -0.1330836, -0.13662986, -0.1423562, 0.054867815, -0.02780568, 0.055965155, 0.15620147, 0.1261938, 0.053937446, 0.4146784, -0.09442713, -0.060367852, -0.10595316, -0.46433964, -0.01473607, 0.033203445, -0.08191399, 0.03319218, 0.027397329, -0.031479567, 0.099168085, 0.058888037, -0.052743144, -0.11660088, 0.0010995489, -0.022227393, 0.22984251, 0.020726904, -0.04363924, -0.15128575, 0.1515043, 0.054462776, 0.13509262, 0.07250708, 0.03709014, -0.0761673, -0.08590172, -0.017181367, 0.1572387, 0.059870586, -0.09222997, -0.10305438, 0.04564076, -0.009695808, -0.017302303, -0.063558, -0.019871721, -0.081051804, -0.12705624, -0.071278594, 0.115877196, 0.086812, -0.0139633, -0.007325259, -0.0153889125, -0.10755279, -0.1389444, -0.09503617, 0.3650648, 0.22073969, -0.06928319, -0.03888109, 0.02740286, -0.07391305, 0.18219376, 0.0093225865, -0.16388454, 0.04213976, 0.15870807, 0.04307104, -0.14538616, 0.028950905, 0.050959717, 0.09490326, 0.049121358, 0.029327817, -0.17617097, 0.062145483, 0.11365857, 0.012922743, -0.05555603, 0.0777243, -0.06418329, 0.20946714, -0.07159516, -0.13477157, -0.25393626, 0.2149236, 0.16004431, -0.08036827, 0.17399783, -0.004973575, -0.11070491, 0.11223684, 0.004173206, -0.2321788, 0.03280854, 0.12180729, -0.34299397, 0.14504097, -0.2817909, -0.034382526, -0.0055480883, 0.18490526, -0.18731435, -0.13333769, -0.013872686, -0.0257483, -0.15481174, -0.08546051, -0.10134001, 0.097423315, -0.06347481, 0.026381532, -0.25061965, -0.027053643, -0.071940735, 0.064096816, 0.031871438, -0.0571559, -0.049100004, -0.008574546, 0.100868404, 0.13287817, -0.022637863, 0.116336115, -0.015952725, 0.13978997, 0.13661991, -0.054103665, -0.18519804, 0.12040459, -0.03426463, -0.029251596, 0.13248517, 0.097674906, 0.2681356, 0.09555734, 0.101154864, -0.27817735, 0.30188695, -0.1294181, -0.071580745, 0.13477018, -0.15679462, 0.15035263, -0.028123513, 0.15706408, -0.10881194, 0.04580773, -0.06690046, -0.023556635, 0.031755734, -0.075976, -0.035790514, -0.1868347, 0.14946267, 0.0016545699, -0.01255607, 0.3645561, -0.120639905, -0.05324802, 0.011966917, 0.06559711, 0.19683525, 0.16587137, 0.017428797, -0.0634795, -0.04023112, -0.15753561, 0.046831146, -0.24536161, 0.052624356, 0.029644955, 0.19399069, 0.07915378, -0.011312373, 0.14920378, 0.13165809, -0.08986597, 0.032101147, 0.08115203, -0.02839034, -0.08815412, -0.09934523, 0.0008505816, 0.112018645, 0.06788892, 0.11963929, -0.22756827, 0.02686866, 0.26383197, 0.08677383, -0.0865529, -0.07475381, -0.46142069, -0.056234982, -0.121247336, -0.1529834, -0.004242866, -0.20369828, 0.27080116, -0.09487221, -0.08478687, 0.2744345, 0.018898314, -0.057096213, -0.09347748, 0.2831688, 0.21695043, -0.119882904, -0.050763875, 0.097288206, -0.16787486, -0.023374751, -0.13131058, -0.17804374, 0.013206751, -0.38499367, -0.30169973, -0.11604421, -0.024212915, 0.018921671, 0.07059091, -0.08292176, 0.241188, 0.085943684, 0.18214582, 0.14713986, -0.11407556, -0.050892178, 0.23760845, 0.05594015, 0.007890427, -0.06846437, 0.05191635, 0.013683213, 0.034439415, 0.040148154, -0.015853278, 0.0028836513, -0.30688602, 0.17396535, -0.027013099, 0.12961055, -0.2537257, 0.0050742663, -0.054840036, 0.12626296, -0.25980684, 0.02111316, -0.18044113, 0.13340735, -0.18257818, 0.3478472, 0.22916679, -0.003132324, 0.04474796, -0.106524445, 0.015016838, -0.1382512, -0.13520433, 0.14951487, -0.16009709, 0.016551547, -0.14952232, 0.27447423, -0.113663495, -0.15635128, 0.14176708, 0.2406036, -0.10264754, -0.17190212, -0.32632977, -0.05344727, -0.110583946, -0.24720088, -0.11556401, 0.18156485, 0.021231746, -0.14786147, 0.15968433, 0.056252033, 0.16300015, -0.12840885, 0.015774338, -0.05171875, -0.014915747, -0.073949896, 0.05529143, 0.1032821, 0.017889706, 0.2622438, 0.22318082, 0.08903193, 0.030033613, -0.07413867, -0.14082772, -0.13520089, -0.080637045, -0.13103749, 0.04637971, 0.1448357, 0.16853482, -0.007403278, -0.054543853, -0.12518454, -0.063108586, 0.16429895, 0.07113408, 0.06352718, -0.15604633, 0.24186988, -0.11724408, -0.054573853, -0.029591788, 0.014377531, 0.10296432, 0.30217817, -0.070485726, 0.23479849, 0.1293092, 0.027227791, -0.08849191, -0.12762783, -0.12723587, 0.23625717, -0.17072237, 0.1830358, 0.025059203, 0.19839461, -0.011537606, 0.14470232, -0.112424485, 0.23240401, 0.15883239, 0.16234794, -0.083415724, 0.0811968, 0.14419423, 0.02181356, 0.0076057445, 0.30198023, 0.031969372, 0.07562325, -0.10789392, 0.15763724, -0.17100148, 0.046190966, 0.17543086, 0.10123852, -0.14059731, -0.09385194, 0.047775425, -0.311078, 0.13005161, -0.1020239, -0.2229278, 0.37136716, 0.08429923, 0.17746639, -0.12035977, -0.18253526, 0.0036104484, -0.059220158, -0.07284271, 0.013360659, 0.01786649, -0.121823475, 0.20983277, -0.10469956, -0.089534625, 0.009802458, -0.19474038, 0.3450687, 0.12464658, -0.0033325073, 0.31216964, 0.07872067]}, "content": "Yeah, absolutely. I think so. The idea of chaining is basically breaking up calls to language models in multiple steps. And not only calls to language models, but to other things, actually. And so I think actually most of the examples that I first added were like language model, and then other thing and then language model and basically chaining the results of them together in a way where you can you did some iterative stuff. And so to make this concrete with an example, one of one of the things that I first added was based on a paper by Off Press, self ask with search. So basically, you'd ask a question and the examples in this paper were kind of like multi hop questions. So it wasn't just like a simple answer. And these are cases where language models are known to kind of like not perform super well. And so the self ask with search paradigm is you first kind of like think about what intermediate questions you need to answer. So I think like the example used in the paper is like, what is the hometown of the current US Open champion? And so like, if we're if we're thinking about that intuitively, like what would we do as humans first would think about who the current US Open champion is, and then would figure out where his hometown is. And so basically, the idea of chaining was to break those down into exactly those steps. So the language model should hopefully know that it first needs to think about who the current US Open champion is, figure that out. And then it needs to think about where he's from and figure that out. And you could do that with, you could do that with a single passable language model. The thing that's, the thing that's interesting, and the thing that caught my attention was basically the idea of combining the language model with Google search. Because if you're asking about the current US Open champion, the language model was trained on data up to 2021, or something like that wouldn't know the information. And so basically, use a language model to ask the intermediate question, you then pass that question to a search API, you get back a result, and then you basically keep on going from there. And so the idea of the idea of chaining that really stuck out. And this is a little bit different than the sequential chains that you brought up. But I think it's, I think it's more interesting, to be honest. So I think it's the idea of chaining language models to determine to figure out what information they need to look up, getting that information from a separate, more, more accurate, more reliable, more up to date source, and then plugging that back in and letting it continue on its merry way. ", "podNum": 36, "speaker": "Harrison Chase"}, {"_additional": {"id": "efe84023-d758-491e-82e7-1bcf00b3f98c", "vector": [-0.061128195, -0.14753294, -0.1468439, -0.12468352, 0.16424233, -0.24298619, -0.12235661, -0.08796116, 0.020553002, 0.002279799, 0.0056976127, 0.3086305, -0.04316722, -0.02996438, 0.05793583, -0.09072739, 0.23595311, -0.2835163, -0.2751372, 0.016385376, -0.183267, -0.280064, 0.00887444, -0.07229823, 0.01314414, -0.016616708, 0.06883136, -0.0498633, -0.21298751, -0.09117229, 0.021799749, -0.03244512, 0.16690274, -0.054458886, -0.043607034, -0.04043306, 0.07518321, -0.061012216, -0.11229699, -0.15382917, -0.0053343787, -0.05615606, -0.09453422, 0.17262818, -0.035078898, 0.038257465, 0.10529397, -0.023019189, -0.07594645, -0.083778836, 0.06981938, 0.16252834, 0.09140141, 0.0084268795, -0.14982197, -0.016632142, 0.09718171, -0.038307954, -0.018947119, 0.15149388, 0.016314918, -0.26447636, 0.06629042, 0.12919745, 0.11540072, -0.016908, 0.13494647, -0.033882007, -0.1392812, 0.09519237, -0.31480125, -0.18873475, -0.070102386, 0.16546302, 0.13193718, 0.08826895, -0.0015760589, -0.1364033, 0.18873787, 0.112125285, -0.052837566, -0.13153745, 0.06990171, 0.06408048, 0.12782477, 0.025403515, 0.096795425, 0.038982447, -0.043348998, -0.22383621, -0.17665249, 0.06338355, 0.084018104, -0.095891945, -0.04524047, 0.12119204, 0.016897604, -0.13816951, -0.07483187, 0.04406369, -0.15629841, -0.06918161, -0.05489212, -0.17686409, -0.010879376, -0.26574916, -0.066281445, 0.24082747, -0.04361812, -0.116242066, -0.040158704, 0.12935078, -0.011937207, -0.07943069, -0.0018276365, -0.10388069, -0.3333569, 0.08519768, 0.16439037, -0.08688292, -0.07411239, -0.08130117, -0.06723309, -0.09859992, 0.2102043, -0.12324381, -0.073637746, 0.17067394, -0.01392076, 0.0718437, 0.009840276, -0.0979614, 0.089266255, 0.032148954, 0.03489677, 0.05482854, 0.29625168, -0.0030161096, 0.047092017, 0.18782467, 0.11273418, 0.44707444, 0.44003388, -0.02962493, -0.20462601, 0.30109736, 0.0048547625, -0.085509576, 0.119411446, -0.2536153, 0.113135055, -0.036037892, 0.32782406, -0.12243754, 0.05295002, 0.09429163, 0.037862696, 0.039232854, 0.02717433, -0.104620144, -0.06347547, 0.059551165, -0.1722123, -0.020159917, 0.027276527, -0.05798064, 0.02464218, -0.053762116, -0.09560663, 0.13374285, -0.19110389, -0.14083968, -0.053355537, 0.0035708195, 0.03625039, -0.0006826305, -0.1932416, -0.00477049, -0.030912243, -0.009889471, 0.063014165, 0.095127314, 0.11938198, -0.042689987, -0.066881925, -0.08361472, 0.16912372, -0.025646176, -0.17102379, -0.17308745, -0.14030105, 0.066581525, 0.07784498, 0.18961939, 0.19962558, -0.11405417, -0.054269675, 0.18480377, 0.016796803, -0.013840054, -0.23997395, -0.15841118, 0.00032946587, 0.14884087, 0.06905122, -0.055152982, 0.0026322557, -0.027709894, -0.14398627, -0.01601863, 0.059824053, -0.012864526, 0.062747315, 0.13360615, 0.089085385, 0.008321409, -0.19428696, 0.06398689, -0.04778719, 0.045645457, -0.08093832, -0.0039075, 0.055959035, -0.36432305, -0.20786195, -0.14623733, 0.025062026, 0.16101076, 0.017579647, 0.12831397, 0.21536787, -0.19848973, -0.00591382, 0.17256084, -0.11403766, -0.01023026, -0.027370827, -0.032122873, 0.14097081, 0.026571447, -0.08438233, 0.006115334, 0.013358326, -0.12392978, 0.08639669, 0.22092916, 0.03362062, 0.17631641, 0.23980089, 0.16620848, -0.30381247, 0.022083608, -0.051880993, 0.073231235, -0.28712428, -0.012574146, -0.21243599, 0.09779243, -0.03487761, 0.02086426, 0.11787264, 0.13345207, 0.238908, 0.09891635, 0.13877673, -0.019955708, -0.1336583, 0.06439122, -0.15365069, -0.11188898, -0.07921068, -0.0012287664, -0.116852134, -0.051004183, 0.19382854, 0.15014073, 0.081414185, -0.017249458, -0.24463741, 0.1917235, 0.10412278, 0.024790721, 0.08166473, 0.22830479, 0.14564413, -0.3477204, -0.06680623, 0.018924689, 0.1455852, -0.09909281, 0.18541737, 0.14520936, 0.04484228, 0.08039256, -0.012781982, -0.02601973, 0.05169772, 0.12841073, -0.031800948, 0.19311278, 0.057527836, -0.009958935, -0.08401509, -0.01928475, -0.06729823, 7.793307e-05, 0.19687222, 0.14879078, 0.21982563, -0.0355954, 0.11192072, -0.08006947, 0.019555748, -0.041511346, -0.17851768, 0.06941172, -0.27255446, 0.17788185, -0.15958212, -0.045214057, 0.058833104, 0.03143864, 0.066307016, 0.19355558, -0.002648995, 0.05007335, 0.09742656, 0.20585674, 0.10453167, 0.0193378, 0.31880772, -0.09106996, -0.13352624, 0.25418496, 0.233857, 0.24396963, -0.033802044, -0.034723748, -0.08693735, 0.057666443, -0.083140574, 0.10807798, -0.06251212, 0.19597128, 0.1409538, 0.10810516, 0.110745795, 0.2361703, 0.17043774, 0.014020116, -0.23444909, -0.10863787, -0.01979505, 0.06850496, 0.005269719, -0.019335411, -0.23294653, -0.117380954, -0.057717834, -0.085735835, -0.033043977, -0.24675174, -0.23743567, 0.25247496, -0.084713995, -0.07684956, -0.12627107, -0.12613659, -0.23261772, 0.23678255, 0.08985195, 0.032869514, 0.041849073, -0.06162418, 0.11483585, -0.22778936, -0.039764438, -0.23387638, -0.17095682, 0.22139367, 0.049944755, 0.08598335, 0.25597543, 0.031501338]}, "content": "Yeah, so, you know, the most obvious thing is power. You want to keep power on these things as little as possible. So it's obvious we want to make the machines as efficient as possible while also maybe paying the least amount to get them on there. But in addition to that, there's also the cost of the networking, of the bandwidth you pay. And, you know, we've heard this a lot from retail and manufacturing in that, you know, they don't want to send, you know, 200 cameras from every store out to AWS. They don't want to pay the ingress costs every day. And it would be much better if they could at least, you know, just send out the high level analytics every day instead of needing to process all of the data. And you need to process all of that in a data center hundreds of miles away. And also use that bandwidth of the store that their, you know, employees and customers would like to have good Wi-Fi at. So, yeah, it really is like a problem with more problems at every level. But, yeah, I mean, it's really from the case like, you know, you think about a camera or say like a, you know, a camera running at your front door, at your doorbell for, you know, to look at the delivery driver or to essentially replace your doorbell. Many people have these and they wouldn't really like every single thing being shipped out to the people that make them. And so each one of those cameras, I bet you 100% has a CPU attached to them, maybe with some, you know, video decoding stuff next to it. But the CPU has to be communicating that thing. And so if we can make the models and things that are useful for this data small enough and compressed enough, but still accurate enough to run on these devices at the edge and then the camera doesn't communicate with anything, even on your local Wi-Fi using that bandwidth, even outside of external bandwidth, unless there's a warning or something serious that should be looked at or every once in a while. That's just a better experience for everyone involved. And plus, the box that you have plugged into your wallet, integrated into your mainframe, you don't need to have that box. You don't need to have the compute there, have the power there, have it being noisy and things there. So definitely, we hear the asks every day. And that's why obviously a lot of people are interested in what we have to do. So, yeah, it's really just about figuring out the whole pipeline beyond just optimizing the model to make it easy to build these applications, fit them into smaller devices. That's part of the reason why the DeepSparse engine we focused on x86 CPUs to start with, so made by Intel and AMD, because those especially were the most common four years ago, which the company was founded at. But now ARM is running everywhere, both in the cloud, on the edge, on this MacBook I'm talking to you right now from. So we're working on ARM support right now and hoping to have an alpha by the end of this year and hopefully a demo at NeurIPS in December where we'll be presenting. So, yeah, looking forward to getting sparse networks onto more types of hardware. ", "podNum": 27, "speaker": "Michael Goin"}, {"_additional": {"id": "f0850fcb-a591-4589-8ef8-f5686bd978d6", "vector": [-0.06176796, -0.18568325, -0.18885574, -0.16632189, -0.10675565, -0.1956866, -0.010562809, 0.011308988, 0.16261233, -0.020548897, 0.026947083, 0.10328168, 0.068264894, -0.009178417, 0.1880048, 0.021376437, 0.09039219, -0.07770639, -0.44225693, -0.020064851, -0.18275663, 0.0019934974, 0.0060987854, 0.048742943, -0.052927323, -0.01588268, 0.03462895, 0.020489814, -0.107319996, -0.17233159, 0.04037252, 0.18876205, 0.017996, -0.1264161, -0.20821221, 0.16833511, -0.094042435, 0.07790261, -0.10140522, 0.003828189, -0.052808136, -0.037728556, -0.046582345, 0.2575006, 0.107081816, -0.051098645, -0.03367998, 0.014285343, -0.037414294, 0.13731755, -0.026454179, -0.038489036, -0.11506374, -0.10807366, -0.0969754, 0.14904273, 0.19033691, -0.048920643, -0.1776923, -0.111742355, 0.09180606, -0.099982485, -0.2574251, 0.42042023, 0.2785849, -0.15308607, 0.09041517, -0.13746403, -0.12195562, 0.24804643, -0.043910336, -0.17818442, 0.023424998, 0.050678108, -0.080484726, -0.036241043, 0.08725943, 0.008923407, 0.14075048, -0.0117797125, 0.031120082, -0.13896112, 0.08271792, -0.10510784, 0.16381857, 0.034594454, 0.04725487, 0.029597376, 0.050667454, -0.111396894, -0.13788842, 0.06262418, 0.056809384, -0.007360293, 0.019136472, 0.21109447, 0.008602431, -0.19960637, 0.012016914, 0.35469475, -0.23593983, -0.050674766, -0.18108578, -0.18687502, 0.0054610497, -0.3601672, 0.036294788, 0.05546397, 0.07814926, -0.05918803, -0.09426077, 0.004122898, 0.045211334, -0.007400646, 0.03183546, -0.0070934296, -0.11389352, 0.19627264, 0.10782812, -0.19609654, 0.040488984, -0.09885601, 0.09456722, -0.024523484, 0.045976218, -0.111440286, 0.09320391, 0.16687284, 0.09521967, 0.033148706, 0.1549884, -0.013970978, 0.13651098, 0.12946336, -0.15643139, -0.08200346, 0.06998209, -0.06968906, -0.11034789, 0.1365976, 0.0054193544, 0.075466074, 0.19995746, -0.11762413, -0.24694207, 0.27036205, -0.14281604, 0.005165693, 0.02061333, -0.0821621, -0.026486194, 0.06479538, 0.23329125, -0.075392984, 0.28174168, -0.024956537, 0.043416493, 0.12539431, 0.049922407, -0.09302306, -0.3455222, 0.14560534, -0.03668661, -0.055638652, -0.04129788, -0.11458524, -0.024868706, -0.008317068, -0.03304783, 0.1425541, -0.047061086, -0.07120822, 0.03708104, -0.027539283, 0.096127205, 0.053002376, -0.17109123, 0.028906388, 0.060606033, 0.1313247, 0.076364264, 0.09991694, 0.21747352, 0.19458623, -0.039601382, 0.025210602, 0.06197867, -0.008827152, -0.13579483, -0.1740786, -0.019695591, -0.10787888, -0.097223334, 0.17948364, -0.09872987, -0.120395064, 0.23382047, 0.0472534, -0.045279827, -0.0025621222, -0.26136088, -0.111080036, 0.07358622, -0.27674234, 0.16625771, -0.04759707, 0.23994526, -0.09088986, -0.12443841, 0.09326012, -0.08989216, -0.12619431, -0.22796373, 0.16439971, 0.0900101, 0.032858502, -0.09715418, 0.05997408, -0.17686963, -0.037466474, 0.06538995, -0.13431343, 0.015560198, -0.5141461, -0.22189103, -0.18799302, 0.034148216, 0.24809922, 0.08678382, -0.011648118, 0.17427503, -0.04285579, 0.010097554, 0.13484004, -0.08950838, -0.01788118, 0.026764024, -0.06486909, 0.0784322, -0.059796415, -0.08721342, 0.022904204, 0.080362566, 0.04574558, 0.102561906, 0.19048722, -0.059174012, 0.07870424, -0.032163512, 0.25573316, -0.37056118, -0.024899717, -0.111208506, 0.10283034, -0.18987732, -0.086649165, -0.32702342, 0.054834608, -0.23755118, 0.2501242, 0.41325644, -0.25470528, -0.15323947, -0.0783729, 0.11709391, -0.04937149, -0.120348774, 0.48419532, -0.14891787, -0.04528128, -0.07761718, 0.056563217, -0.005854557, -0.13121538, -0.042505246, 0.14754842, -0.0195161, -0.12236117, -0.26824912, 0.02192408, 0.16203105, -0.22783196, -0.054925226, 0.12939015, 0.14566705, -0.16064791, 0.046177924, 0.09590847, 0.06928971, -0.044422667, -0.0236655, 0.17636684, -0.15218356, 0.08093548, -0.07147865, -0.005571861, -0.03873856, 0.27178815, 0.16381502, 0.07499944, 0.07073784, -0.02323127, -0.15053669, -0.16156141, -0.1310717, -0.26414806, 0.10528262, 0.14596452, 0.24466376, -0.070267215, 0.1289398, -0.10243057, -0.018571496, 0.20657323, -0.0372358, 0.10444802, -0.15651342, 0.2051852, 0.15082881, -0.10027426, 0.05423159, -0.13260622, 0.1999814, 0.15276504, -0.08771722, 0.13362162, -0.12759237, 0.05664167, -0.15009525, -0.07736248, 0.12097857, 0.09021763, -0.013989227, 0.15153277, 0.2923768, 0.39596257, -0.019024948, 0.18262424, -0.25802764, 0.027521992, 0.042399805, 0.14272676, 0.14187172, 0.004524097, 0.059070002, 0.023467226, 0.13438919, 0.41510943, -0.024763325, -0.10064108, -0.12244605, 0.24123463, -0.085239224, 0.017668972, 0.1372345, 0.050919715, -0.10918023, -0.20527802, 0.2422106, -0.23370954, -0.011201566, 0.015587211, -0.14475203, 0.4089058, 0.058314867, 0.16481216, 0.08215465, -0.16063316, -0.16698098, 0.24112113, 0.00418401, 0.061026625, 0.1398311, 0.014797283, 0.047589142, -0.07480269, 0.019957947, -0.09212865, -0.19797942, 0.22768433, 0.24537587, 0.0825535, 0.33305413, -0.13801369]}, "content": "Oh yeah. Yeah. Incredible. I think that argument plays a lot into the like the fine tuning discussion of earlier. Like right now it's, I think like OpenAI, Cohere, they offer a fine tuning option and it's sort of like you give them your data. I haven't used it myself, so I can't speak from experience, but I think the model is like you give them your data, they fine tune the model, then you just pay a little more for inference compared to where like for you to fine tune Flan T5 on your data, where you might need to deal with like distributed GPU training. For most people, it might just, that tip, that scale might just be like, ah, it's too much effort. I can't be bothered with this. And then, and then on the other end is the inference side, which is another extremely interesting part of it. And yeah, like, like you need to host say like a four GPU inference for your very large model. And so I think this is a good transition also to talk a little more about the Weaviate module system and how it helps you host the model. So there's two options where you can use the OpenAI or the Cohere models. And there's also the kind of do it yourself in Weaviate, you have the module. Can you describe kind of the Weaviate module system a little more? ", "podNum": 35, "speaker": "Connor Shorten"}, {"_additional": {"id": "f0a35958-88ef-4ca6-ac53-4260d981b64b", "vector": [0.08913508, -0.24316688, -0.2513246, -0.06160872, -0.0448534, -0.281451, 0.05633216, 0.12525415, 0.123248614, -0.027518056, 0.03808021, -0.20794332, 0.079106666, 0.0052422336, 0.10767772, -0.03978446, 0.24942535, -0.3959496, -0.48227143, -0.054439753, 0.04436955, -0.08634466, 0.2835628, -0.03245705, 0.019254088, 0.15604138, 0.019480959, 0.06144151, -0.03267191, 0.10951429, -0.11917359, 0.21724884, -0.24501933, 0.050498754, 0.006388409, -0.06490073, 0.27375653, 0.13216205, 0.21850692, -0.15004066, 0.04169069, -0.14118795, -0.08633027, 0.22436865, 0.11199537, -0.11717046, -0.057340834, 0.107743494, -0.14701293, 0.04900905, -0.052000392, 0.042475563, 0.008702613, -0.021846198, 0.019479403, 0.33407542, -0.09659383, -0.37674752, 0.038705688, -0.025374083, -0.17328556, -0.096775584, -0.1480564, 0.31212524, 0.024278393, -0.23943852, 0.06952674, -0.052565794, 0.060870573, 0.14602827, -0.028220728, 0.16860159, 0.12247484, 0.20484304, 0.051690966, -0.24591632, -0.14349611, -0.24495691, -0.022680633, -0.07574312, 0.17815222, -0.15570611, 0.14846797, 0.040214967, 0.044255745, -0.1441282, 0.14783607, 0.028567856, -0.17365582, 0.11220639, 0.09254054, -0.332072, -0.03934136, -0.07839048, -0.1720138, 0.08902404, 0.027530998, -0.10012767, 0.2069738, 0.08295823, -0.2318997, 0.1877938, 0.11378326, -0.27688307, 0.20925407, -0.061209466, -0.17104441, 0.26204395, 0.10488064, -0.23311257, -0.07898921, -0.057123456, 0.12628235, 0.009616551, 0.0045130053, 0.29751334, -0.09971431, 0.13167115, 0.102425545, -0.41515675, -0.004420119, 0.18667828, 0.18258075, 0.061348666, -0.23785563, -0.36287597, -0.031863347, 0.06873894, 0.10941392, -0.060275882, 0.19669314, -0.28716257, 0.04899169, 0.21106325, -0.0002398466, -0.07003972, 0.08355582, 0.1545876, 0.04173139, 0.20119596, 0.23126121, -0.12849928, 0.009886702, 0.31275794, -0.34692582, 0.42161837, -0.1753928, 0.0020079017, 0.13672233, -0.12254154, -0.1101088, 0.3070279, 0.04450192, -0.29776827, 0.1604687, 0.05410178, 0.2560434, 0.17587441, -0.0866965, -0.038015902, -0.006084919, 0.10755392, -0.006051149, -0.04936382, 0.2563498, -0.29624787, 0.12696739, 0.24149363, -0.013992851, -0.004686743, -0.016920617, -0.010673776, -0.35601136, -0.17442979, 0.061095268, 0.027258754, -0.3576487, 0.034842875, 0.10511327, 0.061693143, 0.0748417, 0.13009554, 0.03528677, 0.41036168, 0.038833424, -0.15642491, -0.004658282, -0.055207953, -0.05161943, -0.012342031, -0.05628243, 0.071682625, -0.22477584, 0.1655547, 0.13400184, 0.036666244, 0.2461539, 0.17137511, -0.16305731, 0.082016975, -0.2153794, -0.47145614, 0.27397078, -0.16827095, 0.09847196, -0.10180948, 0.24142103, 0.04065148, -0.055323005, 0.3083499, 0.07311752, -0.13735513, -0.40458933, 0.1981514, 0.008639802, 0.036028873, -0.22235118, 0.13140686, 0.13388176, -0.14216201, -0.096942686, -0.38047504, -0.16559687, -0.1744793, -0.25379935, -0.06683117, 0.11292165, 0.24209975, 0.046665043, 0.0947145, 0.2602556, -0.020812811, 0.13684833, -0.13103501, -0.118887044, 0.08329087, 0.39645615, -0.16907735, 0.2666308, -0.081548445, -0.26639974, -0.059477285, -0.1831664, -0.1607423, 0.18532343, 0.18547, 0.0398057, -0.07701362, -0.09754494, -0.05409472, -0.32385662, -0.19773714, 0.25293228, -0.055782285, -0.08578292, 0.027712703, -0.23248559, -0.12059734, -0.15938565, 0.23708315, 0.46401563, -0.23456126, 0.05879384, -0.18475552, -0.35318127, -0.15874265, -0.32525852, 0.05031471, -0.2225734, -0.31870484, -0.11505651, 0.061021242, 0.23498785, 0.066438384, -0.2388186, 0.4772342, -0.08910457, -0.10568476, -0.29779246, 0.059304688, 0.14413561, -0.025795847, 0.066550374, -0.048638884, 0.21860717, -0.066048466, -0.23728119, 0.1263515, 0.11828601, -0.12845455, 0.26564908, -0.08397328, -0.20608915, 0.121316105, 0.14334385, -0.16616975, -0.049546733, 0.035177197, 0.3097146, 0.19633697, -0.035444528, 0.05495632, 0.095664896, 0.28031015, -0.011947673, 0.03290311, -0.01562338, 0.10110208, 0.12999022, 0.0814686, 0.019179633, -0.11125568, -0.27703825, -0.054907527, 0.0036349536, -0.30379346, -0.364987, 0.027205825, 0.091265164, 0.039590344, -0.037143275, -0.035077874, 0.057635475, 0.4350133, 0.04722212, 0.074946366, 0.060797676, 0.22226603, -0.13982372, 0.10374769, 0.0651455, -0.000688086, -0.091760695, 0.06762098, 0.26005566, -0.11509747, -0.16632263, -0.16588439, -0.06859153, 0.073849685, 0.071902655, 0.09316302, 0.04156066, -0.003249618, 0.04702093, 0.13005239, 0.16716766, 0.30222002, -0.0069327853, 0.051796224, -0.07353153, 0.11802477, 0.061720166, 0.0061297626, 0.05513959, 0.014375836, -0.009022455, -0.09973621, 0.05207437, -0.31764913, 0.218446, 0.113314785, -0.15761212, 0.58152276, 0.014204825, 0.18955405, 0.08308201, -0.037240934, -0.10572947, -0.14460583, -0.19179781, -0.23142515, -0.23672126, -0.2354778, 0.048333187, 0.025013095, -0.17975402, -0.14730702, -0.087165974, 0.24788094, 0.23921566, 0.16392992, 0.081911005, -0.16540207]}, "content": "I never made the connection to the counterfactual in the relevance judgment before. That's super interesting. Maybe this is too revealing of a question, but can you tell us about how you're thinking about collecting data at You.com?", "podNum": 32, "speaker": "Connor Shorten"}, {"_additional": {"id": "f0b83a7a-a557-4f3e-8142-04c5c944e1ba", "vector": [-0.17486432, -0.23220006, -0.107414216, -0.07910882, -0.017811246, -0.2187838, -0.12742376, 0.0050288364, -0.025914205, -0.063090056, -0.020620637, 0.2626555, -0.011494366, 0.054177623, 0.11635222, -0.027704138, -0.00811385, -0.18477361, -0.3999158, 0.070405126, -0.02131149, -0.22173502, -0.04483444, -0.15741825, 0.010674909, -0.017259713, 0.073305815, -0.0035713054, -0.09043883, -0.069146916, 0.08492957, -0.0017899722, -0.109900005, -0.031711567, -0.073654436, 0.017546296, 0.056744613, -0.010884967, -0.06852348, -0.05419567, -0.04730673, -0.054751165, -0.11251633, 0.13253582, 0.16097823, 0.019142354, 0.105212785, -0.05194163, -0.08372772, -0.07134394, 0.019010557, 0.072355546, 0.0693195, -0.030958548, -0.1800805, 0.18895322, 0.084994234, -0.109032355, -0.00030417647, 0.06920152, 0.07640089, -0.14039436, 5.088374e-05, 0.12480287, 0.19205423, -0.07564747, 0.17920679, -0.12985842, -0.04360352, 0.24906829, -0.12346305, -0.17370243, -0.17745522, 0.1558988, 0.094575204, 0.061793767, 0.044156156, 0.0051032957, 0.16712868, -0.11977045, -0.12828365, -0.067989744, 0.10035398, 0.08083273, 0.08574401, 0.15889776, 0.08706589, 0.0043487917, 0.07435403, -0.0041796286, -0.09029561, -0.04212506, 0.009256393, -0.03627553, -0.0026672445, 0.12718457, 0.07698584, -0.085589804, 0.12073268, 0.0635406, -0.3132862, -0.09344887, -0.20186621, -0.18021926, -0.025965925, -0.17609608, 0.011208973, 0.14441279, 0.01311357, -0.10456006, 0.106251985, 0.00012509245, 0.031234017, -0.010406097, 0.0020687962, -0.107396655, -0.18520851, 0.08510614, 0.09803918, -0.23320706, -0.071251, -0.08455303, -0.026686521, -0.01924457, 0.034147926, -0.07404419, -0.05165954, 0.20067716, 0.0051379083, -0.08415046, 0.057672724, -0.1368479, 0.10697174, 0.07493065, 0.019921333, 0.0902229, 0.21023011, -0.029875327, -0.20690168, 0.17946652, 0.030427694, 0.24576467, 0.24269524, -0.0030899025, -0.119915664, 0.25771338, -0.020408899, -0.05077611, 0.098602146, -0.24768955, 0.091423675, -0.026055861, 0.23526838, -0.100618705, 0.05876283, -0.042902973, 0.029103607, 0.068353236, 0.027795967, -0.061973296, -0.14813219, 0.22956577, -0.12850745, 0.1108437, 0.12899402, -0.0134966, -0.028818723, -0.031101722, -0.097671434, 0.0841157, -0.018694218, -0.048066963, -0.11026037, -0.04201152, 0.083753385, 0.033402596, -0.22759035, -0.03262865, -0.1186678, 0.11632978, 0.111931495, -0.012770299, 0.23248142, 0.07582309, -0.018353896, -0.07940348, 0.16020423, 0.065727286, -0.18129826, -0.111663304, -0.114819914, 0.04213337, -0.06589013, 0.30022126, 0.16010207, -0.08620854, 0.05867179, 0.010390878, -0.003357233, -0.09316094, -0.21246639, -0.11322452, -0.08718893, -0.055683702, -0.049508177, -0.012903841, -0.0070624314, -0.047853015, -0.10643742, 0.004218382, 0.052236933, -0.112785906, -0.022231108, 0.17036983, 0.06274904, -0.039832048, -0.14547954, -0.044283524, -0.2927854, 0.047239646, 0.019575702, -0.038053773, 0.031101897, -0.30992365, -0.25226736, -0.18863228, -0.005669933, 0.09208622, -0.028002001, 0.14795294, 0.10410693, -0.18983814, -0.09191789, 0.15908156, -0.028988391, 0.026285052, -0.05743513, -0.05311459, -0.06629916, -0.03498462, -0.1394299, -0.074022815, -0.11311112, -0.09415034, 0.023220686, 0.19973817, -0.059011348, 0.21295226, 0.204286, 0.12709051, -0.23144248, 0.028278247, -0.111612335, 0.11672142, -0.23414534, -0.023011617, -0.15374842, 0.08356525, -0.030556347, 0.15382284, 0.124041624, -0.08859573, 0.07990843, 0.0091746915, 0.18863249, 0.013348996, 0.010440895, 0.305268, -0.12150568, -0.06978673, -0.14680888, 0.05044057, -0.040247016, -0.02360661, 0.14433408, 0.12390745, 0.13740785, -0.1700213, -0.34246385, 0.15515769, 0.17128867, -0.086463, -0.071010545, 0.16104746, 0.108676106, -0.2842722, 0.10436616, 0.10309912, 0.082362644, -0.21274465, 0.11396783, -0.05255922, 0.019210592, -0.09231393, 0.10166602, 0.032767236, 0.14784773, 0.03839683, 0.08701217, -0.005685106, 0.11281654, 0.041763432, -0.1637474, -0.12922525, 0.027628768, -0.018422388, 0.30333894, 0.19854827, 0.1526565, -0.14480571, 0.057919208, -0.076207146, 0.012161149, 0.093478106, -0.104834475, 0.12481398, -0.2254163, 0.21404456, -0.004927721, 0.0855496, 0.068184644, -0.08167225, 0.1329607, 0.12093064, -0.07520515, 0.07037825, 0.0017152359, 0.23287916, -0.043790866, -0.0018451475, 0.21259883, -0.0017821866, -0.07233295, 0.16934897, 0.14070891, 0.2518705, -0.036284607, 0.102712415, -0.1357594, 0.10338883, -0.08824724, 0.13403879, -0.018194875, 0.30233628, 0.12755024, 0.06245905, -0.024000851, 0.2636559, 0.04338725, 0.008718332, -0.139198, 0.061158225, 0.12872015, 0.09151834, 0.15043184, 0.08072747, -0.15627283, -0.031940494, 0.015682507, -0.19593318, -0.04198756, -0.11739716, -0.11222954, 0.24172892, 0.03218567, 0.0094401855, -0.19125637, -0.12207663, -0.03854387, 0.21895418, -0.05105239, 0.11782085, -0.0028154575, -0.09786312, 0.11245056, -0.1748107, -0.07332842, -0.18359432, -0.24647382, 0.3000434, 0.04718573, -0.043122154, 0.2606066, -0.05574161]}, "content": "Yeah, that's also a great question. And the podcast that I mentioned with Yanif Vaknin from GSI is one example where the ANN index can become its own entity because GSI is basically, GSI offers an APU component, right? So associative processing unit. So think of it as the same, you know, system in the family of processing units like CPU, GPU, and it's kind of like next stage in a way targeted specifically at neural search, but not only that. And so in principle, Weaviate or like Qdrant or Pinecone, what have you, or Elasticsearch could be basically that computation layer. So in some sense, like a middle layer, which receives the data, it knows where the data is, it knows everything about relations between objects and so on, but it doesn't need to, so like on certain scale, it could also do the vector search for you, right? So for example, using quite efficient HNSW algorithm or product quantization or something like that. And I know that you guys also implemented diskANN, is that right? So like, I mean, so this is when companies will concern themselves with the cost issue and they say, Hey, for our use case, it seems like, you know, RAM is way too expensive, can we actually move closer to the disk and we have plenty of SSDs that are cheaper. And diskANN, which I think is kind of like a derivative from Zoom paper, essentially basically moves closer to the disk. It does that expensive sorting of full precision vectors as the last step, but everything before that happens on other layers, like with lower granularity of vectors. And they also solved the problem in HNSW. And again, sorry, Yury Malkov, but like he might disagree for sure. But like in that paper, they claim in diskANN paper, they claim that thousand nodes in the HNSW graph that they have built were unreachable from any point, from any entry point. And so they have fixed this problem. So they increased the connectivity of the graph. And so, you know, these fundamental issues being solved and you can then focus on things like, okay, how do I quantize my vectors? To what extent? And this again, is a trade off between granularity and sort of like later issues that you will have, right? So for example, with precision and vectors overlapping to the single point, so you need to disambiguate them in some way. And there are ways to do this, but it's also may become expensive in some cases. So this is interesting that I think, and this was also one of the questions on my keynote as well. Is there a place for hardware companies and maybe startups even to appear on this scene? Of course, we know that Nvidia and Intel are working on this. They've been competing heads on on billion scale ANN competition challenge last year. But also of course, GSI does it. And I think, yes, of course, building a hardware startup today may sound scary, but at the same time, I think this could be very interesting to tap into. And so maybe in the future, already today, you know, like there is a connector between Elasticsearch, OpenSearch and GSI hardware. So basically the way I think about it is that in Elasticsearch, you can compute facets, right? So you can build, I don't know, nightly job that builds facets and then displays them in some dashboard or sends them to the users. So all of this computation could happen in Elasticsearch, but that other expensive computation with neural search could happen outside. So you don't need to kind of like suffer from the fact that now you need to balance between these two fairly expensive processes at scale. But you could kind of like distribute them, you know, how we do with vacuum cleaners, we charge them and then they go around the house and clean, right? So they don't use the electricity and you can use the electricity for some other purpose. So exactly the same idea I think may kind of like enter the scene at some point. ", "podNum": 34, "speaker": "Dmitry"}, {"_additional": {"id": "f1668d81-58c8-4d43-b051-0feeca0fd343", "vector": [0.0057066083, -0.1137787, -0.020056482, 0.15636945, -0.18514518, 0.266915, 0.16012785, 0.04826267, 0.37785658, -0.1501493, 0.048487436, -0.24731971, -0.23024017, -0.31082198, -0.02991773, -0.007566457, -0.13097824, -0.06866058, -0.16357133, 0.067738585, -0.23205455, 0.08803499, 0.22212233, 0.1588159, 0.011885952, 0.07538078, 0.20006616, 0.21267734, -0.076276205, -0.20029207, 0.03890889, 0.100499295, 0.18300389, 0.061547652, -0.18099451, 0.067281805, 0.028429626, 0.20726013, 0.07749518, 0.20018435, 0.10188817, -0.31521234, 0.056577366, 0.054932225, -0.23326081, 0.20933151, 0.06517262, 0.16941631, -0.07565609, 0.1495312, -0.27117956, -0.18984957, 0.019067386, -0.13341217, 0.20839463, 0.36670828, 0.2581458, -0.00092041, 0.11324647, 0.12650138, -0.2879679, 0.075363, -0.15254137, 0.11052289, 0.08625036, -0.17008787, -0.11661342, -0.4158758, 0.11081669, -0.28367776, 0.3891752, 0.16892004, 0.3458718, 0.39587355, -0.25933483, 0.26633623, 0.14868777, 0.1298737, -0.12484669, -0.099066846, -0.5435787, -0.07565192, 0.06831031, 0.3187054, -0.009948738, 0.24029934, -0.16791435, -0.12826486, -0.317893, 0.020620385, -0.37904716, -0.35703668, 0.20726961, -0.23350339, -0.16529812, -0.114554524, -0.32623506, 0.045624956, -0.11024493, 0.045209438, -0.34484503, 0.18643244, -0.08938399, -0.01579243, -0.071093954, -0.12467349, -0.061268315, -0.45349193, -0.07304583, -0.39108682, 0.14023584, -0.35854158, 0.06911876, 0.02506428, -0.10004797, -0.42749107, -0.09953899, -0.33090854, 0.25761673, -0.3953559, 0.069677986, -0.01901566, 0.031405922, 0.06304679, -0.1575674, 0.014006391, -0.0011676786, 0.18821077, -0.005931037, 0.18153806, 0.24459894, 0.09631598, 0.20597422, 0.28777525, -0.23356192, 0.022180334, -0.2956027, -0.117227614, -0.016324488, -0.05818346, 0.17722054, -0.45157647, 0.0034760188, 0.37412068, -0.29368928, -0.12441557, 0.21394987, 0.0766216, 0.13737766, 0.060768485, -0.037246216, -0.13315886, -0.1246474, -0.055430952, 0.19835448, 0.17197125, 0.19069906, 0.1673808, 0.0789511, -0.1335723, 0.27672258, 0.02738121, 0.15847336, 0.15958895, 0.2621535, -0.3281146, -0.07487044, 0.5046608, 0.22653838, -0.05732957, 0.1261835, 0.1721979, -0.24523906, 0.09745004, 0.20213227, 0.015909756, 0.076703854, 0.012337712, 0.07320918, 0.041084707, 0.04220748, -0.08441806, -0.014799923, 0.1221073, -0.044407096, 0.17419378, 0.07500446, 0.007831355, -0.086912274, -0.056189287, 0.10926321, 0.16672511, -0.0011045238, -0.026763678, 0.1374098, 0.07385779, 0.30900434, 0.062281113, 0.2573212, 0.081239805, -0.39891148, 0.10584024, 0.068668686, 0.022163382, 0.21382909, -0.31709656, 0.22988218, 0.05411281, -0.13509572, 0.11198726, 0.100185305, 0.19967239, -0.3160981, -0.17232464, 0.026374483, 0.17614557, -0.4958538, -0.039195146, 0.4872695, 0.18278234, -0.024388095, -0.052063704, -0.15770303, -0.27337125, -0.09914578, -0.4256768, -0.15024911, -0.10166112, 0.32132867, -0.12600763, -0.03019393, 0.08630297, -0.096598536, -0.059099097, -0.03714652, -0.22368823, -0.0019031564, -0.39192805, 0.32388774, -0.0041489997, 0.12673993, 0.17204107, 0.13769846, 0.12471061, -0.038936466, 0.26504374, -0.13026676, 0.16941105, 0.10926744, -0.030288747, -0.07374332, 0.3456228, -0.39533076, 0.23954195, -0.3818191, -0.1278648, 0.0025897026, 0.11202305, -0.14438339, 0.1282974, 0.08094136, -0.60397124, 0.26086333, -0.1695233, -0.24574499, -0.17992868, -0.11252313, 0.32010743, 0.11743241, 0.16337399, -0.11329324, 0.45147768, 0.27737087, 0.0822785, -0.21307267, 0.29737648, -0.19718842, -0.11929532, -0.17409934, 0.040730447, 0.07666338, -0.26463294, 0.14115302, 0.3044531, 0.017494997, -0.19188766, 0.19641109, 0.08280731, 0.02701812, -0.16896398, -0.013914435, 0.03985106, -0.36182097, -0.0536751, -0.034110997, 0.16128127, -0.33607593, 0.24699058, -0.28573903, 0.1005316, 0.17683165, -0.19175929, -0.10841375, -0.053451598, -0.23169716, -0.1568258, 0.03729687, 0.124833934, 0.120500356, 0.02491499, -0.094792284, -0.01376763, 0.112578504, 0.2114289, 0.100378, -0.10561779, 0.054018322, -0.16713774, -0.14183468, -0.1292063, 0.010981222, -0.27434883, -0.06808189, 0.11873119, 0.081145175, -0.10390204, 0.005313683, 0.104038976, -0.17037785, 0.31543058, -0.23840587, 0.1172976, -0.19816256, 0.1150769, 0.54904795, -0.08720686, 0.11723312, 0.32340696, -0.31654486, 0.17610669, 0.27258983, 0.2783091, -0.002427702, -0.28402734, -0.14718829, -0.13154608, -0.018495044, 0.11554965, -0.14628984, -0.07092035, -0.010084535, 0.31214568, 0.19580905, 0.015399876, -0.1516881, 0.069312856, 0.02875945, 0.3116655, 0.016207328, -0.255761, 0.09931476, 0.15639435, -0.14109878, 0.23122038, -0.012759875, 0.07613439, -0.061873868, 0.1077865, 0.046451014, -0.18748927, 0.11256764, -0.09081578, -0.1416703, -0.20306663, -0.23837478, 0.0632673, 0.061986685, -0.21340483, -0.13652004, 0.027522514, 0.47196102, 0.14194247, 0.29364797, 0.0425358]}, "content": "Fun fact, one of my daughter's name is Ann, A-N-N, but it's not, it's a pure coincidence. We have that name in the family. And although she was born after ANN benchmarks, so maybe it was consciously influenced. ", "podNum": 25, "speaker": "Erik Bernhardsson"}, {"_additional": {"id": "f171fe77-6c8b-45c3-a930-945f60449d7b", "vector": [0.009235904, -0.23936898, -0.13755944, -0.2963889, 0.14110148, -0.05522452, -0.023456633, 0.030470148, -0.111180045, -0.003631195, -0.13154237, 0.04133864, 0.02488669, 0.13902438, 0.1938628, -0.18056327, 0.12428864, -0.07953119, -0.41589543, 0.01487489, -0.17370585, -0.05612053, 0.09541121, -0.054746382, -0.07791205, 0.18830632, 0.047810145, 0.085467674, -0.14049582, -0.04840808, 0.07230224, 0.16782607, -0.01660864, 0.02760908, -0.1400093, 0.21658267, 0.1490738, 0.067895725, 0.062362354, -0.027060896, -0.05696035, -0.27053648, 0.06514107, 0.05366093, -0.008226812, -0.1924009, -0.05861532, 0.0789907, 0.121707186, -0.021437509, -0.046805836, -0.15659223, -0.004455168, -0.1763179, 0.064919904, 0.34893253, 0.33693033, -0.4666935, -0.006390389, -0.29631117, 0.03570228, -0.013138557, -0.08357517, 0.51876515, 0.45154032, -0.35033053, 0.13025762, -0.07139204, -0.06595148, 0.1486826, -0.022501092, -0.010695279, 0.067565545, -0.122060075, 0.056421444, -0.15742965, -0.034435943, -0.17835127, -0.05967386, -0.0054908693, 0.34525573, -0.31067127, 0.005116582, -0.19573042, 0.034130357, -0.091261335, 0.06461659, -0.17675151, 0.009768166, 0.02419826, -0.13374835, -0.039533637, -0.0063339993, 0.08424596, 0.054281287, 0.23788247, 0.0028753802, -0.37261146, 0.13366982, 0.079221845, -0.26424775, -0.08921318, 0.26147103, -0.29523027, 0.0825851, -0.13456361, 0.0017892634, 0.018267598, 0.049482152, -0.15642297, -0.04105856, 0.07093527, -0.0530835, -0.08786373, -0.04850825, 0.10358391, 0.15004364, 0.17440172, 0.13018857, -0.18394063, 0.048328124, -0.07410283, 0.44589368, 0.10427643, 0.048608787, -0.19617337, -0.0930471, 0.16997875, 0.17483155, -0.028423242, 0.17023557, -0.045558758, 0.15429209, 0.19797567, -0.16655773, -0.09137611, 0.23873132, -0.008289352, -0.17451473, 0.18756571, 0.06670283, -0.051791124, -0.013718299, -0.29973924, -0.19135074, 0.14779739, -0.26464862, -0.012788668, -0.0030689612, -0.08967192, -0.0089306235, 0.092140965, 0.19821012, -0.10134863, 0.435211, -0.03231822, 0.09266303, 0.14503677, -0.013925375, 0.102268055, -0.23504522, 0.31107736, -0.05811237, -0.17246234, 0.11130407, -0.20035525, 0.23281588, 0.12671375, -0.14463475, 0.03258626, 0.027681718, 0.07761086, -0.1629127, 0.10872649, 0.103716284, -0.093344584, -0.25389177, -0.08596615, 0.23963092, 0.028043482, 0.046247743, 0.10128754, 0.13201925, 0.25623327, 0.081566356, -0.24508221, 0.0679156, -0.14232117, -0.12722614, -0.25360602, -0.17196727, -0.15420276, -0.096648276, 0.061675355, 0.071354106, 0.02167992, 0.35269302, 0.32523304, -0.12656301, 0.08395317, -0.057698667, -0.42326438, 0.07542879, -0.15107605, 0.15893623, -0.18571775, 0.23717642, 0.24728452, -0.24498506, 0.23143134, 0.036791638, -0.23001924, -0.28280282, 0.31787363, -0.06071085, 0.12150641, -0.31640297, -0.1296506, 0.025543384, -0.044267647, 0.29778177, -0.23191816, -0.24672516, -0.42970192, -0.28603423, -0.16849577, -0.19269323, 0.1868268, 0.13549235, 0.0024274364, 0.0035247316, 0.1850429, -0.13694146, -0.06890802, -0.008507654, 0.016088871, 0.10220155, 0.04047386, -0.06516574, -0.13813463, -0.11669676, -0.13881776, 0.055650484, 0.1234909, 0.2722101, 0.13632509, -0.13731015, 0.12909499, -0.18808344, 0.14758849, -0.3209928, -0.1539226, 0.10995264, 0.061042853, -0.08372542, 0.020662103, -0.4143212, 0.024930976, -0.022266317, 0.54813236, 0.3381091, -0.44867364, -0.048265237, -0.13270904, -0.1595129, 0.033379976, -0.24879569, 0.21819276, -0.20375992, 0.008495089, -0.019489955, 0.24958782, -0.20993634, -0.10943008, -0.11944729, 0.30532897, -0.2637493, -0.2977953, -0.21739927, 0.00686732, 0.11247124, -0.037572913, 0.00073532015, 0.07001309, 0.13102464, -0.061884336, -0.11923452, 0.24786106, 0.12280149, -0.11861337, 0.1123062, -0.16442586, -0.3924924, 0.13668033, 0.12464306, 0.021181332, -0.19490242, 0.343407, 0.2549101, 0.06104334, 0.37090743, 0.06170705, 0.068556316, -0.25726414, -0.13660787, -0.17302813, 0.06294608, 0.17088234, 0.11687949, 0.11527615, 0.16533257, -0.18415123, -0.047939967, 0.112647355, -0.1167641, -0.06376944, -0.29987976, 0.22784224, 0.08046279, -0.1656464, -0.08039722, -0.027528675, -0.028181523, 0.2745642, -0.039641418, 0.074524984, -0.08084734, 0.09024418, -0.09182452, -0.08299074, 0.15966834, -0.041085653, -0.09095311, 0.24995351, 0.3946916, 0.31489456, -0.15542507, 0.1831297, -0.10583943, 0.10496919, 0.23218584, 0.27415508, 0.09575838, -0.09658858, 0.04289186, 0.12261157, 0.0041018496, 0.36649978, 0.043888636, -0.04179006, -0.2660063, 0.3168344, -0.3274893, -0.015055678, 0.15469676, 0.26489213, -0.24664152, -0.19517572, 0.022399556, -0.15104057, 0.13136524, 0.18426228, -0.04615176, 0.47415042, 0.006059807, 0.24543495, 0.25852326, -0.027005646, -0.09686863, 0.17631473, -0.007550884, -0.0062629245, -0.0015014037, 0.016739365, 0.1200638, 0.007938313, -0.09795198, -0.007863719, -0.08616565, 0.2421174, 0.40047348, 0.12775546, -0.17404449, -0.07199612]}, "content": "Yeah, I mean, it's super interesting. I think there are so many applications for doing this vector analysis, this way of bubbling up the keywords and then having that be kind of like the layer above it that lets you see the clusters. I think that's just brilliant. Could we kind of, from my understanding, could we get into the two, could you explain to me what dynamic topic modeling is? ", "podNum": 28, "speaker": "Connor Shorten"}, {"_additional": {"id": "f184c50f-2d31-454f-b6cc-674055b9938a", "vector": [0.029789481, -0.23350054, 0.020311486, -0.087756, 0.08735092, -0.079229765, -0.017682774, -0.049977846, -0.053504005, -0.08842416, -0.10798004, 0.17064665, 0.115100294, -0.067678966, 0.1100591, 0.0021275238, 0.10929643, -0.11165974, -0.21365784, -0.0851102, -0.21827398, -0.0003270169, -0.018056571, 0.15516278, -0.05350278, -0.01919484, 0.04485593, -0.05213459, -0.13634904, -0.11427662, -0.09396818, 0.26501527, 0.028047062, -0.10625394, -0.17120664, 0.082449146, -0.034341726, 0.16535486, -0.03388749, -0.0066617103, -0.020320559, -0.006779726, -0.2494189, 0.23251744, -0.029835165, -0.042319085, -0.06200423, -0.12823412, -0.22411375, 0.090571664, 0.053502444, 0.057367537, -0.11920445, -0.07111678, -0.1418759, 0.0020567332, -0.0011775424, 0.01306929, -0.0577573, 0.20108826, -0.17112152, -0.18502161, -0.19106871, 0.2430959, 0.24197999, -0.1400911, 0.09834234, -0.18296233, 0.1637148, 0.27391478, 0.05477694, -0.014961916, 0.07163059, -0.05459649, -0.13152009, 0.13109149, 0.023478605, 0.14825805, 0.15308097, -0.18060175, -0.083697535, -0.22512522, 0.018424181, -0.03561137, 0.05989128, -0.06118892, 0.022608899, -0.1492505, -0.02948442, 0.0029737432, -0.28572047, 0.059753414, 0.11100017, 0.23180875, -0.10722436, 0.09795616, 0.07969354, 0.043931413, 0.14456919, 0.16458896, -0.13278167, 0.13264997, -0.25428367, -0.32889122, 0.2317225, -0.4028873, 0.11099622, 0.056835447, 0.15511608, -0.081301145, 0.0892732, -0.030720238, 0.15370196, -0.13106014, -0.20437314, -0.022105807, -0.080596074, 0.045505006, -0.10793789, -0.12766896, 0.11580184, -0.03863193, 0.10281893, 0.047616366, -0.02051801, -0.0363246, 0.19838336, 0.05439783, 0.01380921, 0.0079106055, 0.011534497, -0.16460969, 0.11724989, 0.18637396, -0.08592716, 0.076700315, 0.10837261, -0.042072993, -0.047996666, 0.11032485, -0.049422886, 0.23379885, 0.06271919, 0.071840525, -0.34025148, 0.21822408, -0.18359585, -0.09910155, -0.0013831446, -0.14976451, -0.1456808, -0.060257077, -0.13420354, -0.019888438, 0.13749163, 0.10871644, -0.09749638, 0.14318654, 0.16229482, -0.1173638, 0.020436311, 0.1929767, -0.06535446, -0.136306, -0.11497478, 0.14536926, -0.022481136, -0.01813914, 0.026427537, 0.035599668, 0.047834523, -0.13328244, -0.044705514, -0.32962707, -0.23917937, -0.16099499, -0.2760559, 0.16441253, 0.26675206, 0.106226355, 0.05151677, 0.346158, 0.04739752, 0.12606998, -0.1403951, -0.03526282, -0.032841105, 0.023833137, -0.034235667, 0.07869686, -0.051746737, -0.12255509, 0.11518869, 0.4441929, 0.09810626, -0.19248536, 0.02995296, 0.1533175, 0.12387541, -0.035479713, -0.37860695, -0.07283328, -0.044624504, -0.1468911, 0.12977408, -0.010245779, 0.32261625, -0.20379357, -0.017175328, -0.0028930337, -0.06800668, -0.21724886, -0.2636296, -0.02442069, 0.20364834, -0.07045012, -0.2587675, -0.027489522, -0.04246544, 0.11428436, -0.045453295, -0.14565592, 0.14796662, -0.39507473, -0.20476876, 0.084005736, 0.2713649, 0.13927917, -0.06384599, 0.14824447, 0.24231394, -0.0118675865, 0.036046345, 0.20247267, -0.0021716526, 0.048357803, 0.053569388, 0.062939756, -0.15469654, -0.11322167, 0.042128786, 0.027915753, 0.014453479, -0.05588989, -0.11330853, 0.29141024, -0.30132115, 0.13031739, -0.12081347, 0.07478221, -0.17676431, 0.20129403, -0.14324169, -0.048601083, -0.059513077, 0.07851921, -0.29069087, 0.13212581, 0.042479943, 0.16997057, 0.412064, 0.23674814, -0.037429634, 0.049161118, -0.1480875, -0.06684482, -0.004231583, 0.24070011, -0.19221596, 0.036495697, 0.124743655, 0.03842117, -0.029100109, 0.024328133, -0.078434825, 0.17915465, -0.099508554, 0.12072807, -0.3105914, 0.13907799, -0.09961682, 0.0100395065, -0.05428575, 0.09339164, 0.18103988, -0.1990555, 0.04778086, -0.3366876, 0.14199041, -0.10301396, 0.22947489, 0.22256207, 0.20470777, -0.0436539, 0.10406678, 0.046511933, -0.044518426, 0.2883619, 0.12763213, 0.02872784, -0.08407772, -0.013939362, -0.10186866, -0.001627644, 0.2097493, 0.022793094, 0.020068819, 0.08348672, 0.35739163, -0.029182533, -0.009519119, -0.20735452, -0.12003748, 0.13284145, 0.007465901, 0.0647432, -0.16710846, 0.02696408, -0.11201322, 0.0026212765, -0.07366197, -0.06420908, -0.022488063, 0.24392682, 0.26631168, 0.01020916, 0.034217976, 0.04059387, -0.2678451, -0.12398104, -0.060915112, 0.11181237, -0.21018924, 0.004995265, 0.1359487, 0.028263513, -0.22462872, 0.066751845, -0.11078678, 0.08559911, -0.021193987, 0.20499586, -0.12064301, -0.0039408305, 0.15378049, 0.11198001, 0.17718421, 0.067520306, 0.10187609, -0.030101262, 0.13805033, 0.21293728, 0.024524901, 0.049977522, 0.110089794, 0.062481306, -0.091011986, 0.08894923, 0.19621018, -0.12576708, 0.021749372, -0.15889402, -0.09101173, 0.32259226, -0.2436975, 0.04196951, 0.033102397, 0.0092414105, -0.010116263, 0.3338524, 0.0809799, -0.08245573, -0.036325704, 0.017938381, 0.121487014, -0.31400576, 0.03971601, -0.2516032, -0.21132293, 0.12649494, 0.04650014, 0.09819372, 0.18541142, -0.08509045]}, "content": "Yeah. Makes a lot of sense. At Spotify, an incredibly important one stage in the pipeline was just removing tracks that the user had already listened to, which kind of makes sense. If you're recommending music, you obviously don't want to recommend tracks the user has already listened to. That was the last step in the pipeline. We basically used Bloom filters for that, because it's very space efficient, as we would recompute Bloom filters every night and then use those binary representations to filter out the candidates very quickly. So, we didn't have to... Actually, it wasn't the last stage. We would generate candidates, remove everything that was already in the Bloom filter, and then re-rank the resulting ones. And Bloom filter also has false negatives. Bloom filters will occasionally flag something as belonging in the... I guess you should call it false positive, but from the user's point of view, it turns into false negative. They will sometimes think that... Sometimes, because the Bloom filter is approximate, we would think that, okay, the user had already listened to this track, but actually they didn't. It was just a false positive. So, we would then remove that, turning it into false negative, where the user wouldn't actually get that recommendation, because the Bloom filter thought that the user already had listened to it. But yeah, I'm just mentioning as one example of one stage in this multi-stage pipeline that I'm talking about. And I think everyone's pipeline will look a little bit different, depending on the use case. ", "podNum": 25, "speaker": "Erik Bernhardsson"}, {"_additional": {"id": "f18c30f0-5963-4c5e-bc85-0e87e02572d0", "vector": [-0.15170011, -0.3693133, -0.08997834, -0.2644989, -0.021820927, -0.17976713, -0.13640057, -0.26955378, 0.00066075474, -0.08283814, 0.048029773, 0.043338545, 0.010764204, -0.014987186, 0.42963755, -0.027475122, 0.3898877, -0.30432206, -0.15778387, 0.13431482, -0.45276928, -0.24467663, 0.156334, 0.07122694, -0.035775546, -0.144787, -0.29796505, -0.20641777, -0.29100657, 0.32999668, 0.16589513, 0.28012276, 0.01358214, -0.16642836, 0.016297594, 0.048780687, -0.027214646, 0.045111507, -0.0033298582, -0.10314967, -0.1525295, -0.18264377, -0.17235751, 0.2762622, -0.043958683, -0.099114805, -0.15123509, -0.0010899752, 0.02424613, 0.12369442, -0.034812767, -0.39324075, 0.16223852, -0.22177476, -0.19517751, -0.047769334, -0.108738735, 0.13187504, 0.19753551, -0.18184753, 0.29564795, -0.122146204, -0.15587807, 0.48105744, -0.05630661, 0.05401147, 0.022540234, 0.011904392, 0.25323007, -0.42991662, 0.13312113, -0.2513188, -0.2570312, 0.45119148, 0.11013489, -0.038980752, 0.096243195, 0.0072866455, 0.05120813, -0.16272482, 0.14403245, -0.24116296, 0.19337225, 0.038567774, -0.1084744, -0.1336264, 0.24249154, 0.09549202, 0.021609299, -0.15080464, -0.12571333, 0.1213963, 0.2820034, -0.118178815, -0.2866648, 0.2071952, -0.032624878, -0.14836983, 0.16499697, 0.12418704, -0.3008685, 0.086844146, 0.28018835, -0.64849424, -0.14526302, -0.22006357, -0.014232032, 0.031885948, 0.38117927, 0.0494128, -0.17144608, 0.053421427, 0.0805524, -0.120096765, -0.02994959, 0.035038896, 0.04899458, 0.100012414, 0.2700845, 0.17135274, 0.112503946, -0.11971316, 0.06617792, -0.031416066, 0.29863325, 0.06444789, -0.26341516, 0.5305675, 0.25488952, 0.27258703, -0.012319237, -0.01251135, -0.16961989, 0.19287238, 0.07150496, -0.14422914, -0.02996856, -0.23401292, 0.14963353, 0.29622018, -0.051665504, 0.23046862, 0.29249817, -0.19753975, -0.13920039, 0.12829922, 0.034057006, -0.12708876, -0.17669389, -0.2357298, 0.11128125, 0.19655669, 0.16425775, -0.15474212, 0.2654704, -0.039106257, 0.2386319, 0.2160708, -0.047735624, -0.14184573, 0.051885515, -0.06843634, -0.022176914, 0.088489965, 0.08205965, -0.30125648, -0.19835937, -0.049919963, -0.13754384, 0.044325233, -0.05900159, -0.13841084, -0.07285253, 0.04146246, 0.20481478, -0.11652905, -0.1647448, 0.28472185, 0.007853895, 0.13792582, -0.1719948, 0.22284248, -0.009124661, 0.2917535, -0.14511642, -0.09464545, -0.08482167, -0.15422323, 0.15433758, -0.17228708, -0.032152228, -0.15080304, 0.067578115, 0.16462824, 0.46949375, 0.1408025, 0.21834695, 0.09290897, -0.015676424, 0.04346315, -0.46854272, -0.36465004, -0.15341543, -0.1507703, -0.008129567, 0.18858416, 0.40949565, -0.0074667446, 0.08377786, -0.089629106, 0.16763294, 0.12258307, -0.15202919, 0.040840484, 0.22169535, -0.07389739, -0.22275063, 0.15460636, -0.05093217, 0.22874257, -0.33598617, -0.025084198, 0.3259002, -0.39286077, -0.34808224, -0.6578084, -0.23791778, 0.30060697, -0.18533649, 0.09854029, 0.029648492, 0.12150359, -0.10687557, 0.21213046, -0.41374245, 0.00830696, 0.45270777, 0.0984083, -0.39427602, 0.02323623, 0.19945641, 0.24235399, -0.008292405, 0.04301745, -0.088366814, 0.38000938, -0.24556631, -0.013832025, -0.005321687, -0.101225525, 0.09867625, -0.29964307, -0.12845846, -0.12411792, -0.3625533, -0.024243126, -0.68363297, -0.055905193, 0.14648621, 0.30412668, 0.24938089, -0.0228636, -0.10783261, 0.11845251, -0.053607248, -0.10608477, -0.2923439, 0.07324119, -0.14657937, 0.14739467, -0.22485173, 0.2295115, -0.06779936, 0.03861701, 0.18831292, 0.41101277, 0.02191212, -0.22712392, -0.23189712, 0.20929289, -0.026651677, 0.04745796, -0.043174975, 0.49188685, -0.17978561, 0.15284221, -0.18462995, -0.052015655, 0.061406493, -0.1644203, 0.22027326, -0.13500524, -0.30364013, 0.03487669, 0.26328242, -0.20954132, 0.013588004, -0.2432973, 0.17687783, 0.32421666, 0.47266454, -0.3030339, -0.16435015, -0.19874194, -0.0988856, 0.10807903, 0.22769964, 0.15599282, 0.18365839, 0.20049308, -0.23088065, 0.008922301, 0.047653656, -0.078258604, -0.1402352, 0.029480144, -0.48058534, 0.107485786, 0.08728747, 0.092741765, 0.20950228, 0.21159996, 0.03597727, 0.37307215, 0.2108019, 0.2673368, -0.11856296, 0.061262578, -0.02698955, 0.042006694, 0.03522998, -0.33301073, -0.25761065, 0.058953695, 0.27823883, 0.073088795, -0.11628342, 0.16444549, -0.23427114, 0.1846348, 0.013318868, 0.27319995, 0.23159502, 0.11610341, -0.14703605, 0.050141588, -0.1812112, 0.12410037, 0.1944544, -0.12712185, -0.10350992, 0.24181321, -0.36410788, -0.1764318, 0.21527544, 0.16283756, -0.14401971, 0.1174354, 0.090259895, -0.45596662, 0.31735724, 0.033739083, 0.053988315, 0.35029367, -0.1107118, 0.18490486, -0.015633352, -0.33272102, 0.015787333, -0.3600313, -0.15354508, -0.45272863, -0.023362016, 0.06856397, 0.27111349, 0.047586557, 0.029105166, 0.053208157, 0.02677092, 0.550429, 0.084588036, -0.05796461, -0.17042959, 0.19323301]}, "content": "There seems to have been quite a bit of buzz about hybrid search in the community as well. I think in our Slack community, I often see people requesting this feature or asking when it's going to be available or being excited when they hear that it's going to be available soon. ", "podNum": 31, "speaker": "Parker Duckworth"}, {"_additional": {"id": "f433a48a-cbed-4a07-97c8-3e89b95a5077", "vector": [0.025717363, 0.2829584, 0.6214154, -0.13415569, -0.1727823, -0.24156222, 0.39979833, 0.095440626, -0.15243162, -0.0872475, -0.07185898, -0.6471761, -0.17655776, -0.017892607, 0.15451154, -0.09075548, 0.40211958, -0.16188103, -0.57591444, -0.37246042, -0.649292, 0.10830939, 0.16746193, -0.016388534, 0.056450997, -0.14458558, -0.049087353, 0.36466065, 0.11796866, -0.037722766, 0.07101588, -0.34633762, 0.313725, -0.04705922, -0.04533865, 0.47194535, 0.0120367855, -0.055008467, -0.20101517, 0.009105988, 0.01837704, -0.6301768, 0.33084455, 0.078905165, 0.25723207, -0.23170681, 0.15847093, 0.17481524, 0.28600347, 0.4699927, 0.26981196, -0.2245762, -0.1631977, 0.21643917, 0.09382436, 0.20798412, -0.19979618, 0.024205446, -0.1073544, -0.25948143, 0.17071566, -0.16388783, -0.040611938, 0.46777523, -0.36773258, -0.22332986, -0.1818514, 0.31469506, 0.06301795, 0.36153743, -0.0504352, 0.1806745, 0.06909289, -0.14650893, 0.332806, -0.18440537, 0.2251852, -0.013271422, -0.20072392, -0.022328138, 0.34910685, -0.3322337, -0.19851267, -0.4535495, 0.048992567, -0.24392532, 0.07343885, 0.25318143, -0.2805328, -0.013576083, -0.3905253, 0.48885393, -0.28423417, -0.23578787, -0.34673354, 0.040827915, -0.02261639, -0.1923455, -0.44075888, 0.22338167, 0.23010336, 0.21708307, 0.44053704, -0.16475236, -0.30480242, 0.13480556, -0.13873623, 0.276919, 0.18006541, -0.2807623, -0.086115114, -0.119838744, -0.14674357, -0.025482485, 0.20091549, 0.28765824, -0.020133063, 0.14276403, 0.73138416, -0.4237893, 0.14408262, 0.17358467, 0.103105776, -0.25412646, -0.2975744, -0.5614816, 0.28442484, 0.26195854, 0.11247885, 0.39999536, 0.18349272, 0.63899827, 0.1713112, 0.5007035, -0.33811772, -0.47975302, -0.40792, -0.25361603, 0.07142645, -0.12051884, -0.05918941, 0.07539785, -0.017634846, -0.45967987, 0.17686343, -0.14831485, -0.06799415, 0.14435646, -0.2997115, -0.018932693, -0.45427024, 0.39139068, 0.41853368, -0.0042396933, 0.45153868, 0.15854777, 0.27178645, 0.044746358, 0.016252995, -0.14898592, 0.022304453, -0.14559223, -0.07122902, -0.37639937, -0.03997786, -0.21635035, 0.19378263, 0.10528638, -0.06799735, 0.16171314, -0.18385193, 0.15544537, 0.097193964, 0.37976444, 0.31331915, 0.12638447, 0.43891394, -0.19389603, -0.043928508, 0.10992835, 0.2954421, -0.0672731, -0.049384676, 0.17176276, -0.004432529, -0.029180065, -0.20866668, -0.043944053, -0.07630089, -0.28497365, -0.08358814, -0.39124346, -0.52296734, 0.035420418, 0.22156551, 0.2757408, 0.29872224, -0.17941101, -0.060670204, 0.20345762, -0.05368407, -0.42388958, 0.43446892, -0.16429628, 0.22964294, -0.07061883, 0.5160404, 0.09337431, 0.37866884, 0.203149, -0.24412182, -0.21138349, 0.63454425, -0.059069186, 0.051713005, -0.2581606, -0.12760255, 0.2507033, -0.09106597, -0.054749012, 0.4146496, 0.1693322, -0.04636781, -0.55758595, 0.102413654, 0.042622466, -0.35292402, -0.11124195, 0.38393265, -0.03221231, 0.4489028, 0.45067596, -0.040749222, -0.07313669, 0.30203572, 0.03404759, 0.1461381, -0.14393559, -0.028499, 0.14636321, 0.10021895, 0.06968707, -0.16766267, 0.120733626, 0.39986813, 0.6286372, -0.20950818, 0.046374872, -0.526643, 0.67053694, 0.06146851, -0.33064365, -0.50428045, 0.1755876, -0.36625186, 0.40984753, -0.7218542, -0.08585673, -0.044618193, 0.17325017, 0.05392532, -0.50990933, -0.15686381, -0.3171479, 0.030712023, -0.21131621, -0.12972756, 0.26234338, -0.3159753, -0.061573144, -0.13861544, -0.060231417, -0.079892784, 0.17886665, -0.67448694, 0.045435764, -0.42088473, -0.027965367, 0.0925713, -0.009991031, -0.043164894, -0.09863976, 0.5064503, 0.3076952, -0.73591334, -0.2199435, 0.4162288, 0.039541814, 0.065437794, 0.00272239, 0.08678785, 0.24537729, -0.31225133, -0.02087692, -0.49346286, -0.15920451, -0.41143987, 0.49742758, 0.110412285, -0.40340498, 0.27294183, -0.2639665, 0.009077072, -0.16093338, 0.018679008, 0.1237395, -0.1818969, 0.35456973, 0.13704005, 0.024036199, -0.051198184, 0.14483568, 0.14071718, 0.013790578, 0.101539396, -0.05052612, -0.22062624, 0.25761414, 0.037604008, -0.2977718, 0.030337982, 0.13508165, -0.2185356, -0.09351644, -0.056629073, 0.49760953, -0.2134169, -0.34700584, -0.072946616, -0.29025042, 0.29898015, 0.07973139, 0.10637665, 0.055511806, 0.35320392, 0.32125592, -0.15590306, 0.08636426, -0.11443723, -0.0470474, -0.19456916, 0.34627447, -0.08861687, 0.38711402, 0.14789417, -0.08221158, 0.13360974, 0.43580806, -0.121509045, -0.051837765, 0.019602776, 0.2190333, -0.22792304, -0.257773, -0.13218139, -0.23316285, 0.17315105, -0.19418783, 0.24632692, -0.43766838, 0.26005968, -0.08841024, 0.11416526, 0.3351929, -0.27013576, -0.016587986, 0.4493519, -0.047073826, -0.29848522, 0.21375737, -0.27238497, -0.19787833, 0.18341446, 0.056203566, 0.07394467, -0.23288956, -0.30809945, 0.3675036, 0.20511195, 0.14634757, 0.28269294, -0.10678822, -0.30075544, 0.10281978]}, "content": "Thanks for having me, guys. Really excited to be here. ", "podNum": 36, "speaker": "Harrison Chase"}, {"_additional": {"id": "f49bcf54-3f42-48d6-a8dd-a3157cdf2bbc", "vector": [0.007988121, -0.2100957, -0.23117016, -0.114784114, 0.26237085, -0.16356272, -0.21192808, -0.05171561, 0.036051612, -0.020520758, -0.0018547096, 0.04599322, -0.18026605, 0.2876697, 0.19019793, -0.020624017, -0.23501235, 0.22209476, -0.20653701, -0.046594538, 0.09047411, 0.065079056, -0.003291878, 0.23057456, 0.012968316, 0.33022675, 0.14076763, -0.15271546, 0.07444826, -0.09188331, -0.13019322, 0.28331983, -0.07388041, 0.046557013, -0.17126748, -0.023710381, 0.019878017, 0.104215406, 0.063289575, 0.2122252, 0.0928859, 0.033262655, 0.08617718, 0.00013150343, 0.043569036, -0.050693598, 0.033618562, 0.034630623, -0.0118841175, -0.04865333, -0.17186895, 0.17245927, -0.2667578, -0.20105337, -0.090907015, 0.43985063, 0.27905175, -0.47969761, 0.107810624, -0.35424688, -0.04316994, 0.12102339, 0.08345242, 0.2131012, 0.1611032, -0.44232395, 0.039507482, -0.027187973, 0.111124754, -0.03086646, 0.14459325, 0.19173254, 0.02427826, 0.19101816, -0.0871887, 0.090477966, -0.09095308, 0.41322917, 0.14151122, -0.08970399, -0.11470616, -0.26698077, -0.0018165085, -0.24637394, 0.12121927, 0.1375723, 0.050322738, -0.07505398, 0.10863612, 0.19178581, 0.11976617, -0.33678204, 0.31226435, -0.041822474, 0.052718077, 0.17081583, 0.09478938, -0.21840611, 0.21608569, 0.02305264, -0.48650065, -0.011795939, -0.05919441, -0.20395875, 0.014929584, -0.1338869, -0.12533659, -0.0987756, 0.3455936, -0.0981884, 0.06836038, -0.03305873, -0.064654574, -0.2171014, -0.09833157, -0.22078301, -0.106693916, -0.09182226, -0.16856152, -0.035998784, -0.07452201, -0.1900495, 0.0115915835, 0.19344115, -0.026461894, -0.06030524, -0.21760987, 0.109685585, 0.18823022, -0.024216032, 0.16364881, -0.09668526, -0.1517357, 0.07918077, 0.025981318, -0.13822259, 0.14814089, -0.37747666, -0.26334685, 0.18368076, 0.15329967, -0.074480414, -0.16965485, -0.0810491, 0.105040066, 0.50041956, -0.12781471, -0.01469684, 0.04786674, 0.061283443, -0.3041549, 0.02174469, -0.025920318, 0.1266674, 0.022824792, -0.08250239, -0.06290874, -0.0733285, 0.07066948, -0.11342755, -0.06820475, 0.34451473, 0.30585086, 0.022262994, 0.25259504, -0.14106923, -0.03742427, -0.17803594, 0.07386594, 0.09598183, -0.12928306, -0.05332542, -0.14774412, -0.19732976, 0.005792198, -0.08380478, 0.022860037, -0.3560501, 0.056698617, 0.30884597, -0.029652514, -0.14592797, -0.09855301, 0.07108527, -0.042547222, -0.17602858, -0.009816924, -0.27298644, -0.055310193, 0.042676974, -0.15437621, -0.08315997, -0.11255589, 0.19953413, 0.27836764, -0.22950412, 0.37841174, 0.18323936, 0.17947151, -0.15934645, -0.26136357, -0.08683677, -0.16242217, 0.08776341, 0.11376014, -0.11467523, 0.08353137, 0.10867757, -0.22950868, 0.22800647, 0.13768871, -0.09203872, -0.034167502, -0.05292888, -0.17047174, 0.14802168, -0.17538144, -0.039666116, 0.117695205, -0.10793516, 0.0031144836, 0.05791719, 0.1738267, -0.2648277, -0.09877073, 0.0021208879, 0.06493927, 0.018357502, -0.28463852, -0.04732982, 0.08651607, 0.004305978, 0.24304079, -0.12342972, 0.029839737, 0.033831045, -0.16933657, -0.004255278, 0.25864902, -0.17074643, -0.2090819, 0.0215483, -0.2788636, -0.034031913, 0.056759153, 0.07651767, 0.086911626, -0.1435763, -0.10836802, 0.15523447, -0.061717376, 0.15744148, 0.06974053, -0.21851243, -0.12358198, -0.07469218, -0.26452804, -0.09768032, 0.030581336, 0.11811859, 0.37255862, -0.11476803, 0.10348446, 0.17245613, 0.09857006, 0.282732, 0.0049777273, 0.13167825, 0.15496702, -0.19400582, -0.002476335, 0.32730606, 0.321588, -0.06809872, -0.0127345165, -0.091727205, 0.15865313, -0.18375115, -0.13082987, 0.2885296, 0.07855478, 0.07665774, 0.14171161, 0.27113736, 0.19564289, -0.27197668, -0.06522911, 0.042304363, 0.06764572, 0.16735715, -0.013809231, -0.22747083, 0.11158414, -0.35135394, 0.19285788, 0.32750562, 0.047286227, 0.074215196, 0.18689275, -0.061562594, 0.21585678, -0.32764924, 0.28685233, -0.2554798, 0.057259344, -0.1700815, 0.08313802, 0.2713257, 0.02094573, -0.45088416, 0.02156954, -0.20835052, -0.043168053, 0.012205853, -0.12392857, 0.0318499, -0.083977185, 0.27450314, -0.12478461, 0.012703263, -0.27321598, -0.013120956, -0.18198553, 0.32256627, 0.24910587, 0.112199396, -0.15144183, -0.096373744, 0.086316235, 0.027675515, -0.06231624, 0.08866093, -0.1004225, -0.1610813, 0.16853292, -0.20035252, -0.21307716, -0.04599989, -0.01146712, 0.12014747, 0.052176192, 0.07263007, 0.033942867, 0.23771721, 0.11495438, -0.21671079, 0.061926316, 0.53860873, 0.33287537, -0.099545866, -0.16676694, 0.22511855, 0.1370433, 0.22239636, 0.19191688, -0.06425588, -0.003766041, -0.04769604, -0.057230603, 0.19572335, 0.14600265, 0.05011565, -0.34989583, 0.28429174, 0.05974513, -0.09647271, -0.20765857, -0.05508975, -0.07914205, 0.005087581, -0.09244595, 0.14298825, -0.02301112, -0.06991758, -0.083043605, -0.23368697, -0.07183197, -0.16078152, -0.065609924, 0.03145915, 0.27281535, 0.13782217, 0.14900698, 0.05877241]}, "content": "Yeah, absolutely. So currently, the only way to update an object's reference vector is by updating that object itself, the parent object, which holds the references. So let's say object A references object B and C, and object A's vector, reference vector, is the centroid of B and C's vectors. If B or C are updated, A's reference vector does not change. Right now, we don't have any sort of back channel mechanism that allows that information to reach the object which references those vectors. And primarily, it was because this is our first iteration. And this is something that could be very computationally heavy if, for example, we have tons of these reference vectors around. So currently, the only way to update an object's reference vector is to update that object's set of references directly. So that can be done either just by posting an entirely new object, or I guess you could say putting a new object with the same ID and a new set of reference vectors, or deleting some references from that object, or updating that object's references one at a time. But basically, the only way to update an object's reference vector is to mutate that object's set of references on itself. Whereas updating one of its references directly is not going to affect that parent object's reference vector. ", "podNum": 31, "speaker": "Parker Duckworth"}, {"_additional": {"id": "f4d365c7-bb07-4631-9349-93c341ae3d48", "vector": [0.03467368, -0.24446112, 0.14844011, -0.12687649, 0.024818279, -0.24817576, 0.031118577, -0.063023955, -0.0034328713, 0.0031279968, -0.011106739, 0.19793887, 0.012451727, 0.09581853, 0.143002, 0.06876317, -0.08822825, 0.061538827, -0.43166178, 0.07411108, -0.21439151, -0.19938883, -0.09741609, -0.054354955, 0.100239165, 0.09665665, 0.06219294, 0.124038, -0.17706929, -0.2548428, 0.030921806, 0.059664503, -0.06684827, -0.09629214, -0.2088962, 0.10413959, 0.1265892, 0.1614225, -0.014176806, -0.051623855, -0.0633668, -0.12496855, -0.03510885, 0.06751358, 0.20592524, -0.045150682, 0.04505947, 0.07618182, 0.09732885, 0.0490386, -0.09785847, -0.08677825, -0.080907635, -0.14889778, -0.028240824, 0.2736552, 0.042318735, -0.19605511, 0.0699076, -0.11067619, 0.015715128, -0.14007626, 0.008798582, 0.3316138, 0.09154899, -0.114319235, 0.036135588, 0.006002223, -0.19158201, 0.39137468, 0.0836792, -0.09052482, -0.09956506, 0.105908036, 0.009823146, -0.015829904, -0.0019281344, -0.039972547, 0.18050931, -0.005673078, 0.054734316, -0.15341048, 0.060952675, -0.0049627963, 0.02277125, 0.15067768, 0.12568833, -0.022016348, 0.024931269, -0.04152243, -0.18131672, -0.1673266, 0.114417784, -0.08305756, 0.06751338, 0.1613242, 0.0014712445, -0.17248885, 0.2767386, 0.22281808, -0.22362314, 0.0058331285, 0.04448807, -0.25483057, 0.12065572, -0.31008542, 0.04290231, 0.17986612, 0.16869827, -0.058980282, 0.051574554, -0.1403639, 0.087305136, -0.0744487, -0.11566744, -0.107450694, -0.088824816, -0.004920009, 0.10780848, -0.12082553, 0.04738575, -0.055527844, 0.016047098, 0.11276931, 0.085614435, -0.17100558, 0.052069083, 0.15895277, 0.0450151, -0.1402905, 0.13922223, 0.108930476, 0.009476349, 0.08930757, -0.15195486, -0.18057366, 0.15694429, -0.08377039, -0.17096035, 0.12287531, -0.041302238, 0.2352394, -0.004618377, -0.023128092, -0.20903173, 0.32792267, -0.1790122, -0.12215971, -0.043290522, -0.11832443, -0.07291997, -0.043151543, 0.12868379, -0.069323726, -0.0033281567, -0.03694682, -0.045173645, 0.13094057, 0.085840724, -0.09453847, -0.13947569, 0.20340219, -0.14629522, -0.051413104, 0.16961005, -0.05585128, -0.019389553, 0.102450326, -0.0017657517, 0.101589866, -0.02822969, 0.05536578, -0.16673212, -0.06525841, 0.09923913, 0.09901638, -0.33717954, 0.022998063, 0.08742934, 0.21873647, 0.2346225, -0.116244815, 0.12512909, 0.104093954, -0.15512697, -0.16570126, -0.108617336, -0.027124979, -0.03184445, -0.04741406, -0.18399511, -0.20432658, -0.2209641, 0.19370931, 0.08066773, 0.08191419, 0.1598265, 0.18410748, 0.05502153, -0.15345325, -0.21215044, -0.26289904, 0.012666774, -0.1544065, 0.06474197, -0.10288096, 0.24375857, -0.15001403, 0.085698135, 0.11354945, -0.032039836, -0.18358608, -0.12114592, 0.16550703, 0.10207908, -0.05582714, -0.10518217, -0.0076425225, -0.22806548, -0.105654806, 0.12286728, -0.18437234, -0.08050404, -0.41943437, -0.22382955, -0.20189776, -0.029068576, 0.06931226, -0.07016988, 0.12101161, 0.21428986, -0.04027665, -0.10893812, -0.0705558, -0.08216092, 0.0437536, 0.236894, 0.04004858, 0.009862349, 0.02994591, -0.07942683, 0.07750251, -0.088405125, -0.051785592, -0.039321702, 0.24460569, -0.06874654, 0.23941547, 0.053826854, 0.24023151, -0.03425722, -0.058548823, -0.099793404, 0.17477871, -0.33771828, -0.1033343, -0.13294595, 0.026403433, -0.0667281, 0.2573171, 0.26811025, -0.48293668, -0.1256032, -0.13560891, -0.017135562, -0.03482041, 0.02864784, 0.4217489, -0.27938163, -0.05578828, -0.13482378, 0.42787057, 0.029774101, -0.041441694, -0.20136207, 0.18266536, 0.055919334, -0.19370651, -0.29246366, -0.008659225, -0.02049773, -0.12817653, 0.0016489984, 0.36629546, -0.2530511, -0.2501715, 0.14333183, 0.033667102, 0.23117314, -0.094134994, -0.07652196, 0.032471474, -0.07161444, 0.03299444, 0.070629306, 0.05892927, -0.112907745, 0.09130271, 0.15520155, 0.05882937, 0.15180624, 0.12369562, -0.069446996, 0.0055634486, -0.20844914, -0.039658014, 0.11829099, 0.22730307, -0.04014952, -0.048407637, -0.1632373, -0.01902596, 0.014691136, 0.039227314, 0.09871011, -0.030571736, -0.06505536, 0.24866089, -0.16940606, -0.050733045, 0.041550353, -0.09330578, 0.15444954, 0.3788276, 0.04353781, 0.24031228, 0.06540109, 0.29375032, -0.10966594, -0.113521, 0.14507268, 0.038304005, -0.048859347, -0.012803879, 0.39558455, 0.09943154, -0.11228268, 0.06462002, -0.17588198, 0.13985734, 0.10421822, 0.23820038, 0.100624554, 0.1476778, 0.12228987, -0.02479236, 0.059089467, 0.23201369, -0.034618285, 0.15127765, -0.07699618, 0.24636087, -0.14530528, 0.045030385, 0.13948837, 0.14361873, -0.15783082, 0.047276426, -0.011245831, -0.31666878, 0.07730239, -0.16034321, -0.07819299, 0.3261022, -0.010987119, 0.11037895, 0.07117885, -0.11609611, 0.07660121, 0.05792077, -0.011201653, -0.01635342, 0.06415269, -0.09251904, 0.1243824, -0.25433385, -0.14699964, 0.0064259814, -0.09927239, 0.31121007, 0.2756736, 0.21484247, 0.119658, -0.05174208]}, "content": "Yeah, totally. And I'm kind of curious about the evolution. I mean, this may be a side topic, but I feel like 10 years ago, you would just start with something like Elastic doing inverted indexes and that would be like, you would productionize that and then you would have search. And then now today it feels like, okay, you start with maybe inverted indexes or you start with vector databases. And then at some point, you start adding features and you start breaking it up into a multi-stage pipeline. You have both vector and inverted indexes working in conjunction. Then you throw in a bunch of other features too. And then you throw in extra boost on top of that or whatever. And you have this three, four stages of candidate generation, candidate re-ranking, filtering. I'm kind of curious what do you see in the world of search and relevance today? Is that sort of an accurate way to think about it? ", "podNum": 25, "speaker": "Erik Bernhardsson"}, {"_additional": {"id": "f50c7e1b-80c2-48ce-9643-d1400968f976", "vector": [-0.1432557, -0.16138776, -0.15892793, -0.08255128, 0.03384057, -0.08158275, -0.22648527, -0.055693824, 0.035923153, -0.05552295, 0.08336958, 0.31628457, 0.007427998, 0.043744516, -0.09686039, 0.009867981, 0.015288119, -0.06623473, -0.36817658, -0.08460035, -0.28404483, -0.18104522, 0.066919886, 0.055495437, 0.049840104, -0.02941216, -0.062249463, -0.13780385, 0.0036897883, -0.16506803, -0.0803385, 0.11911268, 0.17138664, -0.06291076, -0.21702771, 0.15056233, 0.023304507, 0.053931028, 0.0022300628, 0.17840588, -0.047908414, -0.08833635, 0.009700798, 0.24696408, 0.024936134, -0.070779525, -0.013772565, 0.030767934, -0.09233272, 0.009512088, -0.11105454, -0.021637117, -0.08435779, -0.19281168, -0.17763722, 0.021285558, 0.16519068, -0.20787911, -0.13359867, -0.07735517, 0.014479951, -0.1313447, -0.15016031, 0.17509834, 0.1956691, -0.033618517, 0.1993823, -0.078257605, 0.057581123, 0.23218834, -0.090767406, -0.08772946, -0.14271708, 0.20129903, 0.061516415, 0.021305284, 0.0851252, 0.052355994, 0.27509865, -0.14949994, 0.06678152, -0.22812462, -0.020533362, -0.008267127, 0.11241906, 0.056803767, 0.12732685, -0.04772179, 0.057074174, -0.10770872, -0.0025463253, -0.08419, -0.21506216, 0.061949283, 0.005550111, 0.19931006, -0.0484309, -0.113622665, 0.090899944, 0.1472176, -0.17978501, 0.02552496, -0.06662507, -0.28886476, 0.0051399157, -0.32985705, 0.05068575, 0.015698822, 0.086455755, -0.044850465, -0.023484739, 0.08832252, 0.027437864, -0.08484244, 0.031716965, -0.09579583, -0.13385527, 0.14287086, 0.15962537, -0.04113723, 0.039591987, -0.070254065, 0.038649667, 0.006595582, 0.11864074, -0.02538529, -0.14468601, 0.15146375, 0.12901416, 0.011639136, 0.086849935, 0.021363484, -0.039297532, 0.012957598, -0.027031137, -0.17806017, 0.16362369, -0.12560613, -0.12654114, 0.14495362, -0.06701548, 0.2470658, 0.16819067, -0.053941205, -0.2693394, 0.4219738, -0.117656924, 0.049417406, 0.0937778, -0.26711163, -0.028809175, -0.12394655, 0.12865083, -0.13798182, 0.18074572, 0.016416607, -0.14201598, 0.11697838, -0.011342374, 0.012794063, -0.22485264, 0.10738852, -0.099444024, -0.05900428, 0.23215295, -0.07224588, 0.12453336, 0.0057254606, 0.01271087, 0.22138298, 0.0073741623, -0.15635215, -0.058871713, 0.023463702, 0.09699001, -0.062319618, -0.30448166, -0.14206485, 0.083312094, 0.06704364, 0.10177094, 0.015197317, 0.19015016, 0.12342099, -0.03035408, -0.12340107, 0.0116587365, 0.035288844, -0.14243759, -0.01708941, -0.143338, 0.024631897, -0.015451002, 0.18661563, -0.021719927, -0.106860794, 0.15507841, 0.23486663, -0.11161349, -0.013631525, -0.31525233, -0.2196184, -0.054771762, -0.093130864, 0.18122125, 0.02210758, 0.13091016, -0.12997216, -0.029322254, 0.079439275, -0.08213651, -0.09210988, -0.1626019, 0.13784473, 0.050955057, 0.08548278, -0.15316233, -0.08423405, -0.11052365, 0.10575806, 0.0072829477, -0.13896278, 0.081296176, -0.3480709, -0.2810701, -0.134227, -0.010978865, 0.12827396, -0.012909998, 0.13967969, 0.13088162, -0.057807896, 0.13331245, 0.034384865, -0.090563335, -0.062908195, 0.029328054, -0.04094005, -0.041400325, -0.11787518, 0.011753957, -0.08898715, 0.03630979, -0.03338072, 0.19469655, 0.21136844, -0.06329735, 0.15974554, 0.111647904, 0.1518727, -0.33349743, 0.12455561, 0.029340573, -0.034474824, -0.22638261, -0.102735974, -0.30796805, 0.071811564, -0.12020281, 0.12742777, 0.35048044, 0.0009853789, 0.037475713, 0.052796077, 0.10468087, -0.008842236, -0.1894592, 0.08583134, -0.03669851, -0.0008248985, -0.036119502, 0.054730106, -0.09098697, -0.0015498797, 0.1290073, 0.22640155, -0.04864417, -0.14905557, -0.36448845, 0.015405816, 0.028095583, -0.16698422, -0.0061953664, 0.25906953, -0.078628525, -0.21277778, -0.03391498, 0.012038956, 0.037801918, -0.08721167, 0.0762096, 0.16574514, -0.10093864, 0.07463055, 0.06206874, 0.20943831, 0.01913237, 0.15364252, 0.05165465, 0.08927217, -0.02473274, -0.10122287, -0.096720405, 0.069829844, -0.18551011, -0.1127891, 0.22833018, 0.18024914, 0.08378526, 0.118075885, 0.11306689, -0.05732413, 0.057477806, 0.12500149, -0.11692328, 0.025218954, -0.14514428, 0.21013296, -0.06636556, -0.028284142, 0.013507959, -0.019114703, 0.08810071, 0.33231083, 0.010773703, 0.10914441, -0.14509709, 0.14530696, -0.06407525, -0.13518311, 0.03275441, 0.054179084, -0.14087512, 0.22421199, 0.38578022, 0.27001622, -0.047803666, 0.21030188, -0.1370452, 0.0330321, 0.1473989, 0.21117818, 0.055606145, -0.11217579, 0.13258366, 0.023958752, 0.03448126, 0.493752, 0.0015423888, 0.032438964, -0.07475234, 0.10384619, -0.014517072, -0.019512461, 0.2698279, 0.09317809, -0.098423995, -0.055948537, 0.0019197116, -0.10420524, -0.09646335, -0.07672265, -0.06713832, 0.37676743, -0.025659444, -0.00079745176, -0.053082686, -0.18590386, 0.0070433007, 0.1411837, 0.1391146, 0.04765905, 0.059271455, 0.018503005, 0.07163364, -0.0731913, -0.048788965, -0.14989604, -0.21545963, 0.24903512, 0.01601739, 0.037840206, 0.18842779, 0.083746314]}, "content": "Yeah, so, yeah, great pulling out all the results. There's a lot to go through. We're coming up with new results every day. But I especially find that first example you brought up really interesting. And this was actually research that we did in collaboration with an Intel research lab. So Intel themselves are interested in sparsity, even if they don't have, you know, inference acceleration for it. They're still interested in the research. It's another form of compression alongside quantization. And so actually, Intel research labs over in their Israel base have been working on greater and greater sparsity, achieving greater and greater sparsities and contacted us for for using our engine as a sort of runtime for these models they're producing. And they published this paper called Prune Once for All. And so it's basically this idea that, you know, what we call sparse transfer learning. But the essentially the idea that you can actually prune your pre-trained upstream model. So just like you would take a BERT base from Hugging Face that's been pre-trained on Wikipedia or some large text corpus in a sort of unsupervised fashion. Then you take this pre-trained model and fine tune it for your specific task on a much smaller set of data. So what we found out with them is that you can actually sparsify these models in the pre-training stage. So now you have a sparse architecture that's pre-trained and you can just maintain the sparse architecture we found of it and fine tune it onto all your data sets and results that they publish and results that we publish in our research lab as well is that the sparse transfer learning generalizes quite well across a variety of data sets. And sparsity can actually help the generalization of models, which is really interesting to think about in that maybe your first intuition isn't that. But the intuition we've kind of come across is not having, you know, those millions and hundreds of millions extra parameters means that the model has to make each parameter count a lot more and take a sparser, more general representation in order to maintain the accuracy of the whole model. So it's really interesting, this dynamic play of, you know, maybe starting with dense models that work with too many parameters that work really well with our very stochastic methods of training where we throw more data at it. But then getting to a good base accuracy and then working on sparse architect, finding sparse architectures to, you know, go through the step of optimization before we just consider deploying these dense models. So, yeah, in the case you brought up, yeah, we were able to get a BERT large model to 80 percent sparsity with quantization and get its speed to the same level of a distilbert model, which has, I think, eight times less parameters, maybe even 10 times less parameters. And at maintaining essentially the same accuracy of the original BERT large model, just staying within, we usually target 99 percent of the dense models accuracy as a as a as a place for sparsity to keep us. And, yeah, getting that 8x improvement on BERT large to keep its accuracy much higher than distilbert, but get to that same latency. So, yeah, really opening up what size models we can or what accuracy models we can really consider for deployments nowadays. ", "podNum": 27, "speaker": "Michael Goin"}, {"_additional": {"id": "f540aeb3-9bba-4c6b-a290-6a084909ff7a", "vector": [0.34598646, -0.23081411, 0.056482032, -0.070529416, 0.018743522, -0.28429642, -0.26032016, 0.06994768, 0.17745626, 0.07351625, -0.25204387, 0.16337334, -0.094722115, 0.12499677, 0.021687005, -0.09913057, 0.2407311, -0.6614476, -0.79383874, -0.00052289385, -0.30959994, -0.11008613, 0.09151185, -0.0015108697, -0.074569136, 0.133688, -0.1403929, -0.025510358, -0.1579752, -0.21234588, -0.066782795, 0.23322529, 0.21194836, 0.0032713674, -0.31178293, 0.19662581, 0.12939732, 0.100980036, 0.10602876, -0.2096639, 0.14345463, -0.12562642, -0.10994039, 0.29448557, 0.15964134, -0.03821902, 0.13726646, -0.10221893, 0.38162258, 0.027428307, 0.09487927, 0.21009691, 0.21205348, -0.27782652, -0.31180865, 0.14843528, 0.24171783, -0.08027992, 0.19636776, 0.012206234, 0.006058164, -0.03594479, -0.0047925226, 0.43440995, 0.3001021, -0.18305774, 0.39646807, -0.056250148, -0.098427035, 0.4065608, 0.071459725, 0.20116794, 0.14983204, 0.0008331593, 0.11214463, -0.06025246, 0.06526306, -0.12762049, 0.1980367, -0.13255273, 0.1644464, -0.40525308, 0.15711126, 0.1081092, 0.12807092, -0.08595912, 0.041631706, 0.008966688, 0.1336154, -0.027773827, -0.3186519, 0.022316277, 0.026498102, 0.122720495, -0.2292226, 0.24245816, 0.13263458, 0.043313097, 0.11062762, 0.31778756, -0.16957079, -0.04574956, 0.11725092, -0.20773411, 0.09439945, -0.3256712, 0.16957363, 0.33195367, -0.1054233, -0.066308305, -0.116530664, -0.08536336, 0.058490943, -0.12317601, -0.03143675, 0.09912011, -0.08106896, 0.0999082, -0.18985042, -0.08091361, -0.1354482, 0.083447486, -0.14205989, -0.06600155, -0.02057993, -0.26656795, 0.15213908, 0.14343111, 0.032826353, -0.26190987, 0.04399464, 0.07291044, -0.15895927, 0.09368602, -0.24618937, -0.22500522, 0.3599133, -0.14324373, 0.061173566, 0.10186974, -0.04753317, 0.25208247, 0.2732786, -0.29561704, -0.229091, 0.22877331, -0.11605477, 0.032847553, 0.14471367, -0.35218242, 0.0050104577, 0.026063979, -0.034903843, 0.03296038, 0.15246996, 0.108146615, 0.07571904, 0.16588151, -0.04522977, 0.092228115, -0.0015879348, 0.12011351, -0.08420405, -0.10743263, 0.2170845, -0.19127023, 0.22892961, 0.027597137, -0.13492054, 0.27315116, -0.20554256, -0.010222621, -0.0075475825, -0.019721625, 0.20353524, -0.16679323, -0.4654718, -0.0043531824, 0.010591201, 0.19215, 0.11028585, 0.111937724, 0.13819303, 0.32808897, -0.09948384, -0.3917457, -0.05585231, -0.21467659, 0.06129162, -0.2766521, -0.03388636, -0.015524822, -0.16233774, 0.026400186, 0.09751121, 0.2981423, -0.120994225, 0.4406799, -0.027812999, 0.05727236, -0.48651412, -0.83956665, -0.042818237, -0.06560554, 0.47014248, -0.105677456, 0.10630384, 0.09840515, -0.010861531, 0.014655262, 0.07492737, -0.12542705, 0.2900406, 0.12485109, 0.04775232, -0.0896948, -0.3376348, 0.22436917, -0.28469592, -0.11529869, 0.27947676, -0.15070666, -0.21521251, -0.53649646, -0.01679536, -0.11190415, -0.027858146, 0.16048105, 0.09332944, 0.0703277, 0.06229963, 0.17724907, -0.0025692526, 0.18500756, -0.1388894, -0.16671142, 0.034298748, -0.051531777, -0.21236068, -0.17691015, 0.3183628, 0.28241587, 0.2985198, -0.2379709, 0.22828661, 0.16181728, -0.13707732, -0.036715966, -0.24662267, 0.41342306, -0.25602043, 0.068566695, -0.4572659, -0.046645816, -0.45365372, 0.08635063, -0.41838056, 0.058462758, -0.16544616, 0.46635178, 0.30550063, -0.006781101, -0.18721491, -0.33879992, -0.016273845, -0.1307332, -0.19764477, 0.4679673, -0.06143526, 0.16239122, -0.18814035, 0.2081975, -0.027552176, -0.042635456, -0.27276853, 0.22022662, -0.15462396, -0.08883411, -0.41920075, 0.19170693, 0.10629849, -0.13758579, -0.12144542, 0.27799428, -0.033957407, -0.096870854, -0.19362995, -0.009794474, 0.29429802, 0.0075327232, 0.17238116, -0.17747104, -0.106672265, 0.19806367, 0.049831554, -0.20566076, -0.33422923, 0.41448358, 0.034116242, 0.20524819, -0.08464526, -0.10445381, 0.02646378, -0.055547938, -0.08386702, -0.23599751, 0.025867209, 0.09234251, -0.0230298, 0.02294048, 0.28638062, -0.15627427, 0.11761419, 0.094294526, -0.031239722, 0.020661507, -0.30429894, -0.010575935, -0.12963772, -0.25878808, 0.04298064, 0.17452411, 0.008100912, 0.11181277, 0.25649643, 0.303512, 0.028564803, 0.5079804, -0.004093237, 0.07787842, 0.060353436, 0.029668195, 0.03650153, 0.120552674, 0.6271534, 0.250648, -0.23574531, 0.05432343, -0.25974274, -0.28695554, -0.013410948, 0.17626758, 0.20588057, 0.13325074, 0.22753976, 0.12744337, -0.02251447, 0.53228736, -0.16262124, 0.13696042, -0.25152037, -0.26221398, -0.20034575, -0.028598689, 0.14321627, 0.07408759, -0.28197503, -0.08190207, 0.07135421, -0.19511285, 0.15824679, 0.21221425, 0.054865725, 0.70100814, -0.04282596, 0.055713113, -0.12088942, 0.3660307, -0.09415982, 0.07213813, -0.039717592, -0.09268507, -0.02216909, 0.09514388, 0.23810463, -0.28066137, -0.12361398, -0.01997633, -0.1667414, 0.29863805, 0.032041047, -0.10105528, 0.036007322, -0.17980394]}, "content": "Yeah, I love where we are in the field right now. We have models that we can train to memorize data. We have retrieval augmented models. We have the ability to fine tune models we already have. We can prompt models. We can do in-context learning. We can have the models use external tools. And we can actually literally train the models to use the external tools or we can prompt them to use the external tools. Probably one or two of these are going to stand the test of time. I have no idea which and I love it. I absolutely love it right now. This must have been how it felt in 2015. For those of us, the 99% of us who weren't in this field in 2015, when vision models were just exploding and every week it was a whole different way of doing things. VGG, ResNet, Inception, these were all such different models that were trained in such different ways. Adam was floating around at that time. You had different optimization strategies. Batch norm pops up, layer norm pops up. It's just this whole sea of ideas and it was hard to know what the best thing would be. DenseNet, Wide ResNet, like it was just an area of even more diversity and just completely different paradigms for interacting with these models. It is a great time to be in the field. Like, I don't know, people keep complaining like all the cool stuff was done. This is the cool stuff. Like, this is why I'm here because we have no idea what the right answer is and there's so much science to do. And for the people who sit down and systematically develop ways to measure this and systematically develop real-world scenarios, and honestly, that's a lot of our work at Mosaic. Unfortunately, it uses a lot of customer data and we can't release that data, although we try to find ways to share the findings and we can reproduce it on public datasets. But what a time to be in this field. So much happening. ", "podNum": 26, "speaker": "Jonathan Frankle"}, {"_additional": {"id": "f6bf6ef4-7f39-443c-a9d4-9351b0fa2f60", "vector": [0.014475013, -0.20709565, -0.01788597, -0.15736146, 0.06774063, -0.20367746, 0.11348638, -0.051536143, 0.19004822, -0.009739438, -0.008158534, -0.035731446, -0.027595175, 0.050196666, 0.21846518, -0.022512265, 0.1325554, -0.28772554, -0.4489385, -0.11208836, -0.07569478, -0.0426248, 0.07283442, 0.018284164, 0.027952638, 0.14134431, 0.08948923, -0.09078146, 0.014568223, -0.16117628, 0.039737612, 0.016177887, 0.19193982, -0.12377702, -0.19406521, 0.2052406, 0.027377646, 0.13425085, 0.08345117, -0.025468586, -0.055574328, -0.18485293, 0.007969823, 0.16995049, 0.08733188, -0.108194105, 0.052574456, 0.08677719, 0.06037975, 0.04170254, -0.057030655, -0.07614958, -0.12752104, -0.023572836, -0.099621475, 0.29013765, -0.020562783, -0.16362812, -0.041586693, -0.019602148, 0.08219189, -0.15682317, -0.33894745, 0.42453688, 0.13160352, -0.16214912, 0.11242672, -0.0029841168, -0.095728755, 0.11526176, -0.11852359, 0.07737477, 0.17249078, 0.31234264, -0.016964197, -0.09529218, 0.11785264, -0.08368373, -0.022001065, 0.096122, 0.12706257, -0.12711301, 0.12563094, 0.056936882, 0.030181725, 0.00594467, 0.069412425, 0.036270477, 0.04718689, 0.0052002342, -0.20689575, -0.19137341, -0.08132699, -0.080834836, 0.011984808, 0.09348118, 0.13334084, -0.15517613, 0.14361967, 0.20774606, -0.28250563, 0.040876925, 0.06688066, -0.26344573, 0.18514441, -0.17415778, -0.22788298, 0.017026303, 0.17649211, -0.19326091, -0.21697989, -0.043040358, -0.039872732, -0.07318154, -0.0072041787, 0.00632916, -0.257588, 0.13550825, 0.2627058, -0.080919474, -0.16638577, -0.004765434, 0.17652318, -0.05252981, -0.068719536, -0.1272715, -0.033229835, 0.11200753, 0.09041263, 0.012675338, 0.03677202, -0.11871269, 0.04058972, 0.21539727, -0.073597096, -0.10306139, 0.22229508, -0.073061034, -0.023253197, 0.051863577, 0.055629835, 0.2102835, 0.2208556, 0.22824307, -0.29954702, 0.19736663, -0.09022569, -0.13650773, -0.041202333, -0.042950854, -0.102840245, 0.11537505, 0.20390612, -0.2843654, 0.16480953, 0.056636818, -0.0078090504, -0.01581952, -0.006202247, -0.08976676, -0.12637822, 0.0810076, 0.0063249175, 0.044870846, 0.18812883, -0.08915619, 0.024345076, -0.07550901, -0.021482337, 0.036251795, 0.006182663, 0.03460209, -0.054819375, 0.07070126, -0.018733954, -0.084189504, -0.31096086, 0.007387638, 0.021397565, 0.099998415, 0.19501823, 0.14535853, 0.04353058, 0.14939094, -0.11246318, 0.06893581, -0.073193945, -0.09303036, -0.076997474, -0.07351892, -0.0048111435, 0.054731786, -0.09996843, 0.17951332, 0.061831888, 0.09565169, 0.33994174, 0.23900083, -0.049361125, 0.087331936, -0.33871162, -0.3933014, 0.04796544, -0.17180856, -0.06673093, -0.12977374, 0.24615073, 0.1571932, -0.11838827, 0.052907135, 0.061066426, -0.05450497, -0.21466175, 0.17641056, 0.081530534, 0.03529861, -0.06269137, 0.06056874, -0.09909411, 0.015709171, 0.038689617, -0.11100167, -0.21080604, -0.35733956, -0.15853386, -0.3969261, -0.023534467, 0.12507747, -0.031518728, 0.05108382, 0.115374945, -0.12455693, -0.05342312, -0.01978235, -0.10838395, 0.04856652, 0.12891024, -0.0275903, -0.104949884, -0.06344878, -0.0022965325, 0.03747428, 0.052516654, -0.04681102, 0.053410728, 0.16378118, -0.0067570014, 0.072898336, -0.017024254, 0.07145497, 0.00093021896, -0.0461993, -0.11481346, 0.18718052, -0.20858388, 0.02392721, -0.3664201, -0.017041767, -0.13685586, 0.3703727, 0.1914288, -0.21454735, -0.0632969, -0.15851192, -0.14629507, -0.054231238, -0.055029076, 0.25267246, -0.23104028, -0.06968758, -0.07396543, 0.14779536, -0.10126791, -0.095598355, -0.07870025, 0.17153975, -0.04364171, -0.14654239, -0.22360715, -0.10509882, 0.03510553, -0.12020303, 0.09994564, 0.10697679, 0.0013065841, -0.040978115, -0.1162385, 0.26375893, 0.12102996, -0.0046522506, 0.046127476, 0.051219586, -0.08233962, 0.0932797, 0.10230432, -0.06668226, -0.20186353, 0.13353641, 0.086592026, 0.16759768, 0.12973571, 0.015350513, -0.2069089, -0.04656494, -0.027635189, -0.17050326, 0.18620555, 0.21041828, -0.013245352, -0.09914678, -0.04628169, -0.10865905, 6.962288e-05, -0.039924547, 0.05948762, -0.008532667, -0.36606637, 0.13328366, 0.005230214, -0.073832706, 0.04505643, -0.13216044, 0.014041752, 0.09489497, 0.019656219, 0.13612227, 0.023614176, 0.16675851, -0.19017084, -0.122425005, 0.03810611, 0.0008649519, -0.12344522, 0.19553408, 0.30069295, 0.2466038, -0.104028106, 0.16503018, -0.023380736, 0.11546144, 0.17214952, 0.12881607, 0.1685204, 0.11620012, 0.14424247, 0.03371283, 0.049511034, 0.2011342, -0.035829205, 0.11364363, -0.20254852, 0.20942344, -0.024637211, 0.05022101, 0.41026413, 0.10770546, -0.14214958, -0.21203712, 0.1136515, -0.14904614, 0.118621744, -0.11121697, 0.038568884, 0.2667813, -0.038278297, 0.17108892, 0.122635245, 0.0031467136, 0.045940172, 0.06874147, 0.047096148, 0.047989447, 0.048044033, -0.023068625, 0.009934182, -0.062194638, -0.21087813, -0.06946564, -0.118839905, 0.19224419, 0.16395494, 0.29117888, 0.32715222, -0.09269677]}, "content": "Exactly. And I find it very interesting, because nowadays, you sometimes see these, these interviews on like these YouTube channels, like with like language philosophers and those kind of things. And there's also kind of like, you know, an interest of mine. And then and then these, these, these philosophers always, you know, they make sure that everybody understand that the machine does not have semantic understanding of what something means. But from my perspective, I look at this very different because I understand I get, you know, where they're coming from. But the point is just being able to parse the question, right, and put that into context and then know from what, you know, where in this case, in vector space, where the context is stored, that you can retrieve that information, what we, you know, in the industry, I guess, call semantic search. That is what makes it so exciting. I really think that even even developers, right, so even developers might sometimes not be aware, extremely hard to parse a question, and to know where to find the answer, even if you have the answer. ", "podNum": 30, "speaker": "Bob van Luijt"}, {"_additional": {"id": "f70403c4-fe21-4ee1-8bda-84b4669a1dd2", "vector": [-0.10422936, 0.103390485, -0.0070554325, -0.32234234, -0.29805493, -0.55379707, 0.5449694, 0.10519109, 0.061469346, 0.120277315, 0.08811074, -0.1451106, 0.1163468, -0.00807786, 0.6420343, -0.29486546, 0.45990255, -0.41412628, -0.3765297, 0.0070721307, 0.19951636, -0.018110447, 0.05297174, -0.03349853, -0.14990072, 0.03206483, 0.28638664, 0.07840176, -0.023459474, 0.2050092, -0.120049685, 0.35536638, 0.20068324, -0.04167919, 0.00088541594, -0.008993365, 0.0010704984, 0.07795073, 0.10373322, 0.016045477, -0.30117476, -0.033251192, -0.20581979, 0.27601284, 0.15141317, 0.069288716, -0.13708143, -0.16427584, -0.37668946, 0.098735295, 0.20000239, -0.1133223, -0.16980574, -0.18479595, 0.080526166, 0.18092133, -0.18836397, -0.3201893, 0.058517054, 0.15226738, -0.33094317, -0.377136, -0.22585243, 0.57232374, 0.1488731, -0.07056898, -0.22163007, -0.19267613, -0.033356655, -0.20237477, 0.000756586, 0.17131545, -0.12851769, 0.7116883, -0.23143178, -0.22039357, -0.15370725, 0.043801084, -0.06432993, 0.04286321, 0.15702982, 0.19872992, 0.21424113, 0.25513816, -0.010408057, 0.10830616, 0.20086221, -0.045634456, 0.016242929, 0.16449225, -0.21561594, -0.44321334, 0.35896376, -0.14161152, 0.19220008, -0.14418818, 0.39480674, -0.2849601, 0.100833096, 0.13810705, -0.31366304, 0.25294554, 0.17823437, -1.0171632, 0.26016897, 0.121776, -0.14890593, -0.24752009, 0.22518225, -0.30792025, -0.14233224, -0.11910761, 0.1776879, -0.0994454, 0.064242505, -0.36551526, -0.056957535, -0.22556159, 0.22351836, -0.23096858, -0.24115068, -0.1209363, 0.3433902, 0.25713208, 0.084765136, -0.20084344, -0.024669329, 0.3416762, -0.12685566, 0.055982247, 0.17052396, -0.14482597, 0.10851864, 0.6165876, 0.07466212, 0.16582683, 0.25408798, -0.602762, 0.38593483, -0.12894453, 0.16619223, -0.09036248, 0.59000784, -0.057540312, -0.5204146, 0.058127925, -0.2450124, -0.09598866, 0.12955327, -0.03808466, 0.15471764, 0.338026, 0.22021239, -0.30472642, -0.05397413, -0.24550064, 0.18205975, 0.036140695, -0.26113746, -0.36774877, -0.3842569, 0.0004013258, -0.21258624, 0.26381087, 0.51333165, -0.017279372, -0.22261342, -0.20325635, 0.20611142, -0.097002156, 0.61833984, -0.01753547, -0.3865885, -0.0108392285, 0.08232788, 0.09743618, -0.3909448, -0.065645, 0.19865085, 0.3143108, 0.14384344, 0.00031705698, 0.17079163, 0.33915973, -0.34109986, 0.06411021, 0.045333903, 0.05917001, -0.08727155, -0.06852623, 0.23614897, 0.03307942, -0.29382586, -0.15049471, 0.045792583, -0.42458338, 0.61440635, 0.18759501, -0.0017741522, -0.25561354, -0.2836074, -0.170662, -0.4825526, -0.104234986, -0.28729993, 0.082710996, 0.07217242, 0.25994927, 0.062390216, 0.053319126, 0.20203772, -0.07090936, -0.1907794, 0.085612595, 0.37281087, -0.3402214, -0.1126366, -0.049485985, -0.16416635, 0.23255341, -0.33027425, -0.0874426, -0.24378665, -0.18811826, -0.48377702, -0.23950027, -0.24499795, 0.010964714, -0.1973671, -0.0846861, 0.4078767, -0.56475836, -0.14008439, -0.30775502, 0.0157836, 0.11059417, -0.2088662, 0.057686456, -0.068685755, 0.1013928, -0.48594716, -0.21040927, -0.14360647, -0.1077128, -0.43506333, -0.24043585, -0.01729064, 0.015979877, 0.057839546, 0.20020658, -0.027938223, 0.12439789, 0.011807416, 0.27966505, -0.01763521, -0.025022909, -0.42013437, 0.15612055, 0.13295814, 0.30463713, 0.35580623, -0.14472598, 0.3072052, 0.37985075, 0.20295687, -0.02131032, -0.29629904, 0.15412782, -0.23231994, -0.00923574, 0.11487996, -0.1546768, 0.0062117577, 0.28153232, 0.3692581, -0.20194645, 0.055397544, -0.062244203, -0.31033498, -0.2807856, 0.2511881, -0.24338071, 0.31420383, 0.09140242, 0.25508055, -0.17284262, 0.077119194, 0.07776148, -0.026931727, -0.20203704, -0.0998446, 0.10232743, -0.22395055, -0.06891786, -0.009116226, -0.4793632, 0.07487787, -0.01949551, 0.33395365, 0.3950907, 0.14280006, -0.33343527, -0.08229713, -0.16769011, -0.06444185, -0.13135685, 0.3257631, 0.39206308, 0.18182932, -0.21476126, -0.25476652, 0.15351248, -0.20573863, 0.115664095, 0.19718112, -0.11907576, -0.63736075, 0.15847613, -0.095021166, 0.09374352, 0.03331713, -0.3865765, -0.01905353, 0.073386565, 0.17349075, -0.0008772391, 0.28633535, 0.09145605, -0.19607174, -0.016777348, 0.06077821, 0.21018255, -0.6161262, 0.3023909, 0.18885313, 0.08203992, -0.07381832, 0.2881045, -0.2420952, 0.2310379, 0.45605257, 0.071483076, -0.3032456, 0.31754097, 0.09473114, 0.18544105, 0.24618672, 0.12201887, 0.11047897, -0.081669666, -0.05296946, 0.83234453, -0.16094674, 0.23450682, 0.42213684, 0.30611053, -0.19267575, -0.044841148, 0.20784847, -0.31520292, -0.07023097, -0.033648353, -0.32789442, 0.17296521, 0.2999847, 0.22248429, 0.00341745, -0.16807927, -0.08562278, -0.04681216, -0.4937559, 0.08681237, 0.0029034703, 0.07432774, 0.040000368, 0.25559828, -0.021434458, -0.07576369, -0.13288118, 0.102560826, 0.10490995, 0.37797797, 0.21289699, 0.070602775]}, "content": "Giving it semantic understanding of those question of, of that question, regardless of how the user has maybe typed it, or, ", "podNum": 30, "speaker": "Marco Bianco"}, {"_additional": {"id": "f8731e92-fad9-429d-8aa9-bdfc6669bb39", "vector": [-0.09522511, -0.34048355, -0.020033414, -0.12477247, 0.061110474, -0.17025378, -0.18383357, -0.2371963, 0.03550151, 0.038936913, -0.1383001, -0.043301858, 0.002844213, 0.05353105, 0.09205565, -0.122530386, -0.022228593, -0.2318143, -0.27704352, -0.1400184, -0.33053067, -0.06770025, 0.12938425, -0.18135588, -0.009294826, -0.15135357, 0.02139568, -0.22033194, -0.0761261, -0.1975031, 0.018340638, 0.06881218, 0.27086362, -0.18192133, -0.10417144, 0.30340302, 0.15679486, 0.16285643, -0.10842087, -0.09366105, -0.16339041, -0.27224904, 0.055737235, 0.29124656, 0.082362704, -0.030888354, -0.20747359, 0.00012794137, 0.09568648, 0.29054508, -0.18547091, -0.02150647, -0.20908244, -0.11693306, 0.0068412735, 0.443994, 0.0495549, -0.19386107, 0.05099389, -0.2650716, 0.19272396, -0.18181874, -0.1504716, 0.42836547, 0.239642, -0.44932, 0.066229716, -0.05728998, -0.059583426, 0.10539516, -0.09537168, 0.027939523, -0.13902017, 0.059782755, -0.04933121, 0.0013470917, 0.1174142, 0.048865966, 0.23963948, 0.09728756, 0.2910344, 0.018138273, 0.07762793, -0.1010896, 0.15820992, 0.065627284, -0.09603731, -0.00038325787, -0.11073257, -0.15582758, -0.20374379, 0.08883475, -0.013193721, -0.12978205, -0.26227054, 0.12375023, 0.103228346, -0.10280661, 0.03592047, 0.17213736, -0.21358648, 0.08281879, 0.12177746, -0.37038365, -0.072944954, -0.049996797, 0.07697783, -0.049377233, 0.2717428, -0.015256423, 0.04001504, -0.047805645, -0.1957639, -0.091117844, 0.076157734, -0.107668184, -0.11313794, -0.063088804, 0.38527012, -0.20473619, -0.07611142, -0.0071285097, 0.10095503, 0.018846583, 0.023972208, -0.07167147, 0.021472627, 0.3974251, 0.16645983, 0.085388504, 0.16659467, 0.25538552, 0.04082285, 0.5587425, -0.097699925, -0.0975691, -0.095846936, -0.20779987, -0.20549455, 0.17845753, 0.043619644, 0.109666586, 0.24607217, -0.22355452, -0.23504214, 0.34080258, -0.028803343, -0.15974858, -0.009576289, -0.05728385, 0.0283275, 0.22199659, 0.34466138, -0.13756593, 0.19694903, 0.091172054, 0.001673922, 0.04735887, -0.18733943, -0.11327702, -0.18952629, -0.052399576, -0.07969842, 0.049029432, 0.049883723, -0.2461224, -0.045816623, 0.14619379, -0.04533879, 0.24846315, 0.015863245, -0.18413708, -0.12478489, 0.15942766, 0.45643076, 0.13357067, -0.065390244, -0.22223756, -0.21835606, 0.21298702, -0.2227809, -0.12448709, -0.04134104, 0.14020915, -0.03501947, -0.07897997, 0.07184575, 0.084249735, -0.08755558, -0.23369098, 0.2827825, -0.2648397, 0.06498746, 0.1930465, 0.2108315, 0.0010177076, 0.32079735, 0.20243068, -0.14976497, 0.08248667, -0.30031824, -0.14683856, 0.05145408, 0.011821856, 0.3267458, 0.04868993, 0.36196208, 0.10216274, -0.23757736, 0.29170656, -0.06667791, 0.077791624, -0.043915592, 0.08521165, 0.064515516, -0.08860054, -0.29146448, -0.0011193783, -0.08462283, 0.08382684, 0.13759416, -0.11544261, 0.044160504, -0.5094604, -0.17877884, -0.20506644, -0.25435323, 0.17534237, -0.11827888, -0.024809424, 0.19963056, 0.0182767, 0.0030420185, -0.0092722, -0.18124115, 0.1905229, 0.33640575, -0.13386457, -0.1399781, 0.037221845, -0.0979632, 0.0513389, -0.076589845, -0.042180218, 0.0775568, 0.4640891, -0.27589047, 0.105006084, 0.008637859, 0.3032301, -0.050716896, -0.19694662, -0.077298746, 0.0905803, -0.2326457, -0.04937448, -0.5967949, 0.025703121, 0.10988432, 0.3270852, 0.4274358, -0.45154732, -0.01149826, 0.2909318, 0.11117146, 0.07170625, -0.18601857, 0.36419645, -0.07123451, 0.06718485, -0.21336114, 0.2969559, -0.07688694, 0.015127095, 0.023732007, 0.027709147, -0.31714743, -0.46093592, -0.21381643, 0.20091712, -0.15666614, 0.109110214, 0.22178932, 0.3376801, -0.24388297, -0.06332777, 0.19309059, 0.076664306, -0.013185014, 0.009955007, 0.18605722, 0.13235487, -0.19679616, -0.102063105, -0.017839188, -0.19485271, -0.10560063, 0.19403933, 0.19380042, 0.12926592, 0.41822988, 0.049872342, 0.07758175, 0.016021565, -0.0617209, 0.006825817, 0.08086318, 0.21457565, 0.34024882, 0.1784766, 0.051183987, -0.18694636, -0.051594473, -0.003701818, -0.23877983, 0.013757631, -0.22169471, 0.2479461, 0.07940567, -0.1396047, -0.14903235, 0.1861997, -0.12077544, 0.23417926, -0.033491153, 0.1938178, -0.067189604, 0.20282733, -0.10916519, -0.037063442, 0.056392603, -0.09629257, -0.18836531, 0.13655552, 0.46701312, 0.50414795, -0.12206547, 0.13977423, -0.3367811, 0.15306869, 0.16929641, 0.41824397, 0.02651813, 0.13471714, 0.10653184, 0.09276756, 0.009083457, 0.36737698, 0.018332684, -0.19781883, 0.028819486, 0.17994568, -0.21675155, -0.016722614, 0.120521784, -0.05100728, -0.1979997, -0.016081354, 0.071913466, -0.36016375, 0.077856496, 0.15239416, -0.08260794, 0.30457973, -0.30702108, 0.15046461, 0.025662955, -0.23941024, -0.24919085, -0.090905525, -0.11798908, -0.16363533, 0.18617174, 0.12833667, 0.15070328, -0.22846103, -0.20015153, -0.013675732, -0.020655084, 0.26740116, 0.054476857, -0.045184202, -0.1178904, -0.13216773]}, "content": "Yeah, thanks for the warm welcome, Connor. Super excited about what we're enabling here together, particularly in vector search and partnering with Weaviate. Yeah, we're pretty new to the space. In general, we have a lot of experience in computer vision and natural language processing in terms of question answering, classification, your usual sort of NLP. But the whole space of vector search, information retrieval, things like this are really exciting to us and seems to be a lot of space for optimizing the future of databases.", "podNum": 27, "speaker": "Michael Goin"}, {"_additional": {"id": "f8ba56f2-69e2-42b5-8785-50b4c2d372ef", "vector": [-0.093361385, 0.084011614, 0.13162196, 0.2496539, -0.09011422, -0.41686088, 0.26912963, -0.08293767, 0.13487245, 0.049423434, 0.117676206, 0.27258646, 0.08550008, -0.05759139, 0.20212899, 0.030111, -0.22621834, -0.10044831, -0.55749154, 0.070640355, -0.28055972, -0.048255365, -0.124062344, 0.0863839, -0.05400289, 0.15787846, 0.023735378, -0.09482433, -0.19302318, -0.06822451, -0.080194116, 0.082149535, -0.09258139, -0.0820446, 0.034996353, 0.21903409, -0.2034755, 0.19622698, 0.07092989, 0.01182162, -0.09899114, -0.15786205, 0.020530462, 0.07601546, 0.24290323, 0.033086315, -0.123814054, 0.057250194, 0.11266973, -0.05640896, -0.24751222, -0.10290759, -0.2716485, 0.028063498, -0.23073119, 0.038264647, 0.15883148, 0.16837409, -0.011334043, 0.21416126, 0.1827265, -0.29363552, -0.24769878, 0.29667675, -0.13578206, -0.25058863, -0.14371905, -0.30224213, -0.035254613, 0.23659407, 0.19959933, 0.056891132, -0.064042345, 0.15538505, 0.12900716, -0.3206737, -0.078676745, -0.12161702, 0.005336974, -0.14623061, 0.14589176, 0.04809706, -0.008932751, 0.27315912, 0.028301097, 0.1001067, 0.057484936, 0.07242789, 0.046004087, 0.0033986159, 0.011905596, -0.29111275, 0.14178994, -0.0950916, 0.11661197, -0.19457063, 0.008593418, 0.043582216, 0.0888403, 0.17291933, -0.16114585, 0.025645602, -0.18030466, -0.606721, 0.02161349, -0.39000982, -0.012301954, 0.009474313, 0.098431274, -0.040162295, -0.123107046, -0.015398295, 0.045419365, -0.03557177, -0.008901933, 0.06778866, -0.29470834, -0.038540855, -0.13896698, 0.04430806, 0.15317953, -0.06191747, -0.12234378, 0.059172496, -0.23414622, -0.58074766, 0.05210854, 0.18467039, 0.07075459, 0.06599893, 0.17026643, 0.14338477, 0.07284614, 0.06152008, -0.083128095, -0.102105424, 0.23287827, -0.25765038, 0.1322105, 0.17359054, 0.18822071, 0.25289094, -0.028164383, 0.033454966, -0.36711103, 0.06879285, -0.0097988155, -0.111259855, 0.109342955, -0.002870623, -0.058999933, 0.023986673, 0.14662364, -0.07106561, 0.047286626, -0.077755444, -0.019141467, 0.20229504, 0.039541952, -0.14996967, 0.025599282, 0.05208948, -0.07752973, 0.24070385, 0.36287957, -0.22844777, -0.019146172, -0.013453557, 0.087773725, -0.04080691, 0.18819991, -0.042970788, -0.13461226, -0.012308247, -0.23197463, 0.17156678, -0.26323497, -0.00061585754, -0.07350582, 0.2471538, 0.34558523, -0.03271194, -0.020976596, 0.1996986, -0.24417612, 0.1635899, -0.15326118, -0.15095484, 0.14150672, 0.071072415, -0.2228597, 0.35387003, -0.11297324, 0.12836309, 0.034385137, 0.13689235, 0.22010282, 0.11264023, -0.31589746, 0.13173, -0.39743227, -0.00066529214, -0.02304265, -0.2531232, 0.04654541, 0.11108016, 0.25677297, -0.20844519, 0.0782876, 0.11287716, -0.2594178, 0.010428701, -0.07978809, 0.17079523, 0.07115061, -0.13199429, -0.23048909, 0.3070101, 0.051687337, -0.13002208, -0.0074106194, -0.31344873, -0.16731066, -0.37163013, -0.27453032, 0.03877613, -0.037470505, -0.11788549, -0.06933208, -0.07236716, 0.056478225, -0.077662334, 0.11365685, 0.09636294, 0.04651559, -0.121059015, 0.14846295, -0.014943078, 0.16573048, 0.18835917, -0.0887835, -0.20816916, -0.3547826, -0.2521554, -0.054732993, 0.17992781, 0.013829565, 0.20354393, -0.003723044, 0.21748899, 0.015473945, 0.20437698, 0.037018277, 0.10573842, -0.23080353, -0.0859025, -0.26709807, 0.17305624, -0.030736273, 0.11794312, 0.24988444, -0.24988805, 0.061067812, -0.4044279, -0.18781304, -0.062453207, 0.04812385, 0.3071473, -0.2295519, -0.11332169, -0.05755074, -0.12464453, 0.062553085, 0.105460264, 0.039148767, -0.11220011, 0.039404884, -0.24560314, -0.29003835, -0.14951351, 0.13019723, -0.30463153, 0.15700188, 0.10549645, -0.24435583, -0.13761678, 0.17588748, -0.18823756, 0.052550875, -0.20894864, -0.0140002575, 0.20506668, -0.064978786, -0.13793187, -0.101929806, 0.21337786, -0.08078867, -0.04996749, 0.08613159, 0.07956701, -0.07479221, -0.09302816, -0.25623292, 0.031394295, 0.0052335747, -0.23551284, 0.23774362, 0.12391202, 0.28122795, -0.012123937, 0.073118426, 0.11605352, -0.09922732, 0.16195753, 0.2443777, -0.10082383, -0.19294417, 0.18598568, 0.06993475, 0.042906024, 0.12338628, -0.08524554, -0.00029922184, 0.25817478, 0.42303935, 0.09227347, 0.08398999, 0.16568977, -0.1685092, -0.34977204, -0.29547882, 0.0069410587, 0.1626947, 0.25482878, 0.23567948, 0.33960938, -0.20543444, -0.058021106, 0.03629429, -0.053076632, 0.17414877, 0.12192188, -0.048281733, 0.1604825, -0.0056952685, 0.20260996, 0.048290286, 0.33753505, -0.10965591, 0.024847025, -0.027079191, 0.5006074, -0.056004632, 0.08961208, -0.064940006, -0.1715414, 0.30530393, -0.046183236, 0.41206104, -0.30287746, 0.08128041, -0.048837252, 0.08693666, 0.58613867, -0.16586019, 0.0130146835, -0.21145406, 0.1255118, -0.18880835, 0.083045386, -0.09446332, 0.115162075, 0.06610222, 0.17245784, 0.36091724, -0.22528416, 0.19959645, 0.09139108, -0.2863622, 0.32225716, 0.16563937, 0.29077643, 0.15216216, 0.1101415]}, "content": "Yeah, I sort of brought this up accidentally. But one of the questions I have written down to ask you about, and I think we'll come back to the technical questions after this is so you're also a psychologist. Do you use this in your work? How have you found like, has this kind of been inspired by that? ", "podNum": 28, "speaker": "Connor Shorten"}, {"_additional": {"id": "f8ecf769-e659-49d8-923a-7b42c8899a00", "vector": [-0.16802667, -0.2467922, -0.17869811, -0.24644244, -0.10722524, -0.10384765, -0.01961328, -0.2295208, -0.060716867, 0.1440239, -0.21180134, -0.051904127, 0.15399295, 0.106808335, 0.39303312, -0.06602889, 0.13501143, 0.17276736, -0.22303161, -0.093728766, 0.12750597, -0.074647054, 0.0042026658, -0.08409476, -0.002998989, 0.04035845, 0.008083995, -0.104544304, 0.15725851, -0.002277147, -0.017424352, 0.17377934, -0.23835653, 0.036493804, -0.3125227, 0.12383825, 0.03617671, 0.16057621, -0.08522098, 0.19001722, -0.15260679, 0.13669503, -0.042413823, 0.30650067, 0.075114235, -0.21736868, -0.11034613, 0.053533383, -0.15910701, 0.09873622, -0.17396298, -0.07918112, -0.064913645, -0.061566014, -0.07519996, 0.18892239, 0.07652648, 0.065663084, -0.24727252, -0.07989535, -0.058996093, -0.08840405, 0.0015227795, 0.15006106, 0.11236234, 0.008478823, 0.011307012, 0.2868427, 0.17939943, -0.29057595, -0.3004762, -0.20285441, -0.07312189, 0.34996164, 0.028846262, -0.11411061, 0.031210355, 0.2048778, 0.17161289, -0.055707626, 0.14071408, 0.20298848, 0.16689509, 0.15108538, 0.14835942, 0.053387772, -0.07496297, 0.08664087, 0.157842, -0.20925316, 0.082966566, -0.13120876, 0.055010654, -0.039732825, 0.013207387, 0.333404, -0.04291905, -0.13835508, 0.30629689, 0.0005241819, -0.24987887, -0.051505327, 0.03661601, -0.17792828, 0.069638595, -0.33662787, 0.30373687, 0.15304092, 0.2640205, -0.11126651, -0.0017522797, 0.21378367, -0.097278744, -0.4570399, -0.06875602, -0.20783527, -0.18927588, -0.10986477, 0.05018942, 0.009236637, -0.059330683, -0.12450875, 0.19808036, 0.16740385, 0.21464323, -0.002121672, -0.017826578, 0.089668445, 0.09182915, -0.080683075, 0.33061922, 0.030064486, 0.36180633, 0.069752835, -0.023769341, -0.19915316, 0.047911614, -0.18525797, -0.13441749, 0.07100559, -0.2793241, 0.35563368, 0.28498214, -0.0006489977, -0.27648062, 0.22523688, -0.0065375865, -0.0149986, 0.04986763, -0.26111615, 0.2300264, 0.01819386, 0.41921037, -0.0018389132, 0.022499781, 0.17842902, -0.030776918, 0.10115517, 0.018743183, -0.49982843, -0.31736454, 0.06914663, -0.05088763, 0.19218546, 0.14075318, -0.044206016, -0.044287607, 0.059982616, -0.067938864, -0.02052156, 0.036965374, -0.11614452, -0.014802802, -0.001454588, 0.028062448, 0.05454693, -0.21289578, -0.18148819, 0.036722876, 0.13120894, -0.12305196, 0.11328517, 0.40364236, 0.28066078, -0.07270321, 0.12522966, 0.07564948, 0.1686644, -0.07016976, -0.052065976, 0.15540415, 0.08222854, 0.08872695, -0.08267416, -0.15942341, -0.19634388, 0.41588295, 0.041047513, -0.30578953, -0.075690016, -0.1671915, 0.03186895, -0.12674208, 0.033605013, 0.030048305, -0.06487108, 0.32255894, 0.011244565, -0.31600198, 0.097475946, -0.040850352, 0.14009899, -0.08368747, 0.20399599, 0.317189, -0.21234052, -0.22489642, 0.07565953, -0.26537108, 0.040682387, -0.14069164, -0.20280105, 0.07130836, -0.2891637, -0.40156657, 0.07755849, -0.11720787, -0.10841916, -0.15196198, -0.032963343, 0.26895374, -0.10376882, 0.13061471, 0.12464223, -0.12030806, 0.103520334, 0.1580254, -0.061614543, -0.08880688, 0.070530385, -0.07266507, -0.05560199, -0.1562692, 0.17327425, -0.18662521, 0.156529, -0.32501748, 0.23972711, 0.069950595, -0.01174017, -0.21931255, -0.20063116, 0.25228316, 0.120593145, -0.24349281, -0.08925127, -0.1922915, -0.13039598, -0.13297045, 0.08579551, 0.34310263, -0.23578647, 0.0075501325, 0.12371822, 0.26142353, -0.065103725, -0.06854144, 0.23596379, -0.1476289, 0.11251032, -0.2646246, 0.1591369, -0.10807453, -0.22387598, 0.38404262, -0.010884784, 0.071313456, -0.3928119, 0.0242324, 0.049356595, -0.0833867, -0.09196529, 0.12687804, 0.11637058, -0.0686218, -0.11849602, -0.03133776, 0.19933842, 0.019207947, -0.18312623, 0.043590292, 0.025226686, -0.14016406, -0.056553055, 0.04766106, -0.17942455, -0.0028343871, 0.09748679, 0.25116706, 0.057317365, 0.16859588, 0.026193626, -0.15940292, -0.07839257, -0.1296891, 0.055693936, 0.08803072, -0.07189472, 0.3338353, -0.18225673, 0.10224037, -0.0949908, -0.10660875, 0.12503558, -0.0803221, 0.03938829, -0.47518027, 0.25438565, -0.024128946, -0.08341622, -0.14807202, -0.14646606, 0.13329417, -0.043318458, -0.069795065, 0.25254598, -0.0068013947, 0.17398095, 0.0035376213, 0.18852001, -0.016197994, 0.17107385, -0.30405664, 0.19680268, 0.12619407, 0.111816294, 0.052493356, 0.18399088, -0.11400973, 0.049006995, 0.11493481, 0.17323413, -0.16549933, 0.114354834, 0.15224215, -0.12231485, 0.02664198, 0.3233017, 0.11922906, 0.10470439, -0.19723246, 0.20293413, -0.1549663, -0.07065955, 0.062477216, 0.08108331, -0.22445475, -0.2364538, 0.047187515, -0.20125599, 0.16559878, 0.118217394, -0.008661497, 0.021754395, 0.12961623, 0.18598995, -0.08471927, -0.29283288, 0.13930082, 0.0040808953, -0.18900995, -0.20378126, 0.13042429, 0.064517155, 0.05385112, 0.07462801, -0.10955179, -0.15776357, 0.14585027, 0.2808705, -0.044521555, 0.11682047, 0.20114613, -0.03330896]}, "content": "Yeah, that's something that I thought was so exciting when I first saw LangChain is how the language model can control the database, like you just said, with the writing the GraphQL queries out or writing the SQL queries, writing graph database queries. So can we talk about that kind of orchestration layer where you say tell the language model, hey, you have like in Weaviate land, you have this class, you have this class, you have this class, this class contains like Weaviate blog posts, this documentation, this is the code base. And so it like chooses which information source to traverse. Maybe you can also talk about like SQL or like the Google search API or just other APIs, like all sorts of external data sources and how that's interfaced in LangChain. ", "podNum": 36, "speaker": "Connor Shorten"}, {"_additional": {"id": "f93f7388-3427-4e8d-9fb6-46eca49ec63a", "vector": [0.031382762, -0.17454347, -0.2029298, -0.39232343, -0.076636836, -0.087083966, -0.11409508, -0.11321195, 0.04560974, -0.074935466, 0.059681997, 0.1347607, 0.10423495, 0.0556524, 0.24074131, -0.22476241, -0.5001057, 0.014087083, -0.52315474, -0.027014561, -0.27388805, -0.172082, -0.17187113, 0.23940516, 0.2256518, 0.22674206, 0.19212225, -0.17396776, 0.08370667, -0.06639346, 0.110700466, 0.4643221, 0.12764981, -0.04094438, -0.027811928, 0.10627857, -0.049655158, 0.2551503, -0.03937667, 0.050670274, 0.083628505, -0.1908071, 0.05319847, 0.10339442, -0.05965262, -0.16612737, -0.14742509, 0.1615998, -0.013176125, 0.2520717, -0.079903685, 0.23759763, -0.13743365, 0.107719265, -0.0074111056, 0.22944161, 0.034423716, -0.087981, 0.21908906, -0.015575735, 0.09545139, 0.09980655, -0.20548129, 0.30094123, 0.4352471, -0.22830208, 0.41775405, -0.027805915, -0.06836789, 0.28947404, 0.024004277, 0.056310814, 0.044399798, -0.024818586, -0.11749771, 0.12125264, -0.14821681, 0.12938514, 0.19089383, -0.039777283, -0.035423867, 0.12741946, 0.123583116, -0.27465358, 0.06163915, 0.085392036, -0.010640956, -0.12219862, 0.051141575, -0.1651434, -0.16388337, -0.0742461, 0.107381605, 0.116601676, -0.064849176, 0.05534981, 0.036872927, -0.1086788, 0.42917717, 0.19669275, -0.5068824, 0.12917642, -0.1929703, -0.231857, -0.24744613, -0.32767072, -0.10235119, -0.0843412, 0.028827986, -0.0067569315, 0.11560178, 0.022359671, 0.12089094, -0.29078567, 0.021614747, -0.07257798, 0.3096535, 0.1001028, 0.16275573, -0.18771403, -0.09068155, -0.18677619, 0.10403642, 0.23528443, 0.06574455, -0.07691704, -0.17090325, 0.10799094, 0.25613484, -0.15784277, 0.2912755, -0.08481336, -0.12762244, 0.080773324, -0.04068345, -0.10960932, -0.09242259, -0.26199234, -0.22522113, 0.4237463, 0.27100143, -0.054367065, -0.019961556, -0.18465778, 0.16954316, 0.33731955, -0.32613537, -0.25231257, 0.068031706, 0.14246148, -0.14401142, -0.02178484, 0.2777006, -0.1791017, 0.11509201, -0.042111117, -0.0038990278, 0.03144818, -0.21262625, 0.006090381, -0.22904198, 0.22811852, -0.031327493, 0.21471691, 0.05191475, -0.04091332, 0.026203651, -0.11350468, 0.07479262, -0.07020416, 0.07910663, -0.31423575, 0.094011, -0.06009484, 0.08166202, -0.1633516, -0.43677086, -0.22841913, 0.33458617, 0.26830238, -0.044135038, 0.022147443, 0.13781057, 0.033086494, -0.04427255, -0.2962197, 0.11791256, 0.19473583, -0.14197093, -0.16723216, -0.24372962, 0.0013878942, -0.13818982, 0.112016544, -0.038763024, -0.27462327, 0.29340982, 0.23312777, 0.08143541, 0.028015593, 0.07379554, -0.0010959373, 0.027081054, -0.09143393, -0.01635819, -0.03057051, -0.0736648, -0.04281756, -0.47314563, 0.35705194, -0.0029745707, -0.35136178, -0.15551142, 0.03786367, -0.00410347, 0.07676257, -0.20716405, -0.2625073, -0.3021417, -0.19940199, 0.43082416, -0.06623436, 0.3545042, -0.18915077, -0.2599075, -0.19214147, -0.023431746, -0.09820987, -0.20459747, 0.099684134, 0.2449174, -0.057616208, -0.22304398, 0.056882963, 0.07581225, -0.15335214, 0.11454132, 0.117115736, 0.13185617, -0.13642132, 0.006547812, 0.032601472, 0.12292981, 0.063027464, 0.026294492, 0.028518293, -0.041739773, 0.11619435, 0.033229694, 0.014310252, -0.14514618, -0.12863442, 0.14384204, 0.031518638, -0.14845593, -0.363006, -0.27329242, 0.013140885, 0.02829549, 0.18555732, 0.12606953, -0.3543714, -0.12056307, -0.1525386, -0.18191257, 0.004429452, -0.21361032, 0.2094585, -0.050400145, -0.023555683, 0.07090756, 0.3491117, -0.1477746, -0.25966626, 0.030611925, 0.13274187, -0.14525896, -0.23724726, -0.13222557, 0.3342896, 0.017998217, 0.10083717, -0.13722154, 0.257992, 0.11082592, -0.27036875, -0.09556878, 0.0985977, 0.29662558, -0.2539933, 0.03730607, -0.25538027, -0.1180611, 0.054229103, 0.14620084, 0.4460283, -0.034332197, 0.17654794, 0.27142137, -0.061625786, 0.10915134, -0.20338668, 0.01118667, 0.15012012, -0.2316609, -0.23937692, 0.05363561, 0.35281304, -0.049752727, 0.10506859, 0.53932124, -0.06924906, 0.07906949, 0.07603884, -0.09195622, -0.10801881, 0.174941, 0.16941875, 0.05937533, 0.103620015, 0.1012387, -0.08827024, -0.25248888, 0.09888455, 0.044580594, 0.00387422, -0.011400097, -0.021473626, -0.039970577, 0.03137734, 0.03919063, -0.05132282, -0.17250137, 0.083381996, 0.12576233, 0.11746376, -0.1340927, -0.04985289, -0.09441385, 0.114652, -0.023428086, 0.11369252, -0.15578109, 0.20938362, -0.00043973574, 0.19165097, -0.070870414, 0.32166666, 0.14481431, 0.11845463, -0.14120787, 0.036167964, -0.048120644, 0.022255043, 0.113617234, 0.1361562, 0.07880534, 0.08461485, 0.027802292, -0.056596655, 0.09581291, 0.0018736736, 0.0032784012, 0.3774396, -0.0071030236, -0.07683733, -0.25011408, -0.106749654, 0.018666433, -0.229787, 0.0035071534, 0.27780598, 0.108169965, -0.05710085, 0.0852522, -0.38669997, -0.22397202, -0.032115996, 0.11087112, 0.12727192, 0.03617616, 0.036681354, 0.22477251, -0.035524085]}, "content": "So essentially, what we're doing is we have with the CTF-IDF from those 5,000 topics, we just have a topic term matrix with some scores. And within that topic term matrix, we're essentially comparing which ones are most similar to one another. And we iteratively merge them. And at each step of merging, we get another layer and get another layer, and get another layer. And because we've already done the clustering, whenever you combine two topics together, the only thing you have to do is recalculate the CTF-IDF representation. You don't have to do anything with the clustering whatsoever. Because the CTF-IDF is based on the documents, not necessarily on the clusters. That's just split. And if we know which splits to combine, we just recalculate the CTF-IDF representation, and you have your new higher abstract cluster. ", "podNum": 28, "speaker": "Maarten Grootendorst"}, {"_additional": {"id": "f959aa47-5cc5-48f6-9e2e-e7a21fd256f6", "vector": [0.020414114, -0.28205544, -0.1716206, -0.2520069, -0.011732072, -0.031667642, -0.07254313, -0.12184777, -0.15388292, -0.11592104, -0.11296251, 0.3528088, -0.0074184425, 0.019764792, 0.17935747, 0.10778695, 0.018836461, 0.20510243, -0.3343752, 0.111638725, -0.2840663, -0.25171238, 0.09660317, 0.007396847, -0.0449068, 0.024258923, -0.0052333986, -0.05804584, 0.024892472, -0.28003824, 0.24865966, 0.19545105, 0.07978216, -0.13357256, -0.3115301, 0.1923916, -0.0719432, 0.033661027, 0.14053386, 0.05353833, -0.11199945, 0.12617503, -0.038018618, 0.18064006, 0.03186164, -0.15361162, 0.048254143, -0.0895309, 0.11487807, 0.070148036, -0.21067661, -0.13200913, -0.21952415, -0.16193536, -0.0015518377, 0.27838033, 0.16635956, -0.1923737, 0.21090567, -0.26686257, -0.008878561, -0.008129694, 0.27012452, 0.17331904, 0.12340507, 0.052060984, -0.23463306, -0.15209845, 0.08488591, 0.16809419, 0.12858184, -0.058469325, -0.35934806, 0.30329546, -0.20994484, 0.20617975, 0.015289194, 0.009734721, 0.32721597, -0.08677482, -0.057698525, -0.16635099, 0.19810337, -0.1187823, -0.040315382, -0.10854836, 0.17646691, 0.042157307, 0.38462752, 0.022439297, -0.0776034, 0.079767585, 0.17023861, -0.18901148, -0.19745009, -0.07915065, 0.13962077, -0.023558974, 0.14770591, 0.13116227, -0.30393845, 0.039554507, -0.055013284, -0.46286064, 0.02528253, -0.048860867, 0.13015151, -0.01948256, 0.20649432, -0.10474562, 0.017633121, 0.0632525, 0.025803946, -0.0923467, 0.018934172, -0.00040038954, 0.015906617, 0.030857503, 0.5195667, 0.011224825, 0.21318379, -0.04770293, 0.18052588, 0.2493537, 0.031554975, -0.05979731, 0.10322767, 0.22685313, 0.052204862, 0.08675474, 0.04694601, -0.021294706, -0.039846025, 0.1584131, -0.042753767, -0.14180252, -0.12191938, -0.066914275, -0.10504728, 0.19124448, -0.11421354, 0.23344275, 0.12823427, -0.016697958, 0.1861411, 0.1581055, -0.25569734, -0.13263088, -0.07106823, -0.08498673, -0.20613499, -0.047993846, 0.042932954, -0.034130093, 0.14446168, 0.21610874, -0.06283203, 0.07779836, -0.16782641, -0.1068801, -0.0037939325, 0.1273303, 0.0746413, 0.08165922, 0.31472573, 0.111076884, -0.13070863, -0.08644365, -0.144785, 0.13407071, -0.021852488, -0.11534759, -0.3154268, -0.016742498, 0.057758257, -0.109406576, -0.29834124, -0.057118, -0.006399635, 0.17211524, 0.042796124, -0.1366622, -0.0026313225, -0.09113189, -0.1830166, -0.015623879, 0.093128495, -0.019364404, -0.06473943, -0.0014847845, 0.004364945, -0.31287736, -0.06613799, 0.15554184, 0.064458504, -0.11963738, 0.26449597, 0.1425706, 0.03064309, 0.14008053, -0.093080774, -0.5349477, -0.14080635, -0.20144084, -0.22662151, -0.11648847, 0.23347397, 0.09466124, 0.09459446, 0.118165866, 0.13712329, -0.27512047, 0.017788082, -0.0045433007, 0.123027675, -0.25442255, -0.15915462, 0.103087805, -0.30890998, 0.17946163, 0.112203896, 0.0090552755, 0.106872834, -0.2727838, -0.5406799, -0.29135066, 0.044196285, 0.048823055, -0.2680965, 0.113109425, 0.081890866, -0.26424912, -0.14404991, -0.008455407, -0.10774453, 0.05414157, 0.14864463, -0.05978132, 0.15201998, -0.132048, -0.09564556, 0.25974673, -0.08146448, -0.20414892, -0.1429757, 0.15800525, -0.32884827, 0.26377207, -0.0127249295, 0.37144148, 0.25798795, -0.045659732, 0.019810192, -0.09336842, -0.1486714, -0.4476276, -0.36303923, 0.21138445, 0.15233353, 0.28498673, 0.17494813, -0.19347924, -0.08287934, 0.2501436, 0.11757034, 0.0029709972, -0.047970258, 0.10301451, -0.08371983, -0.025753833, -0.23084402, 0.44202566, 0.20327161, -0.07688641, -0.11404513, 0.113470465, -0.0008831471, -0.31316674, -0.29253232, -0.05672766, -0.039170004, 0.15220371, 0.018264584, 0.21807197, -0.1466181, -0.2935537, 0.09626137, 0.17607175, 0.16919668, -0.20652476, -0.06715157, -0.040240437, -0.21443105, -0.08112918, -0.0025833957, 0.022694826, 0.10922083, 0.23974176, 0.21137322, -0.0574269, 0.40723425, -0.04284889, 0.044785038, -0.13507701, 0.0724107, -0.06331611, 0.198428, 0.06902824, 0.21762665, 0.2819968, -0.29044858, -0.055400223, 0.068148784, 0.083680674, -0.012933869, 0.13924697, -0.1469793, 0.16042626, 0.08483645, -0.12676722, -0.14894816, -0.036628965, 0.1681574, 0.25542602, 0.22830585, 0.27499613, -0.095936336, -0.23198505, -0.14781637, 0.11475773, 0.1497342, 0.012764687, -0.29985464, -0.01610738, 0.03536421, 0.039795823, -0.13536915, 0.011120122, 0.017218862, 0.17987083, 0.2128472, 0.04359877, -0.08030586, 0.12053747, -0.072141096, 0.035293184, 0.20850363, 0.27849764, 0.30744144, 0.029843621, -0.06603139, 0.24454753, -0.19341235, 0.12101443, 0.16560419, 0.112817824, -0.01664503, -0.022258678, -0.05521983, 0.0551973, 0.073819175, 0.026507676, -0.03433263, 0.24940355, 0.023070198, 0.05529482, 0.107245535, -0.2985351, 0.14204907, -0.031335935, -0.1281665, -0.13700281, 0.062588535, 0.20525663, 0.061717972, -0.15213148, -0.014351644, -0.15689537, -0.22898035, 0.11913605, 0.26911038, -0.13238034, -0.45963478, 0.14398497]}, "content": "There's a few, I kind of want to stay on this idea of, well, I think we could go into like the kind of the prompting and ChatGPT and that idea of instructions and intent and the interface around it. But I kinda want to stay on this like multi-vector search, like vector re-ranking. Have you had a chance to see the ColBERT idea and do you have any thoughts on it? Just kind of, you keep token representations to re-rank in a vector search way?", "podNum": 33, "speaker": "Connor Shorten"}, {"_additional": {"id": "f9ba6444-23c8-42f4-aa60-784e32ba4077", "vector": [-0.13785264, -0.17175885, -0.06783701, -0.2814006, -0.18988635, -0.26030105, 0.2163706, -0.10689352, 0.3322711, -0.019781534, 0.08180821, 0.10179281, 0.1736525, -0.031687357, 0.25205615, -0.15590267, 0.18987438, -0.06861643, -0.38320208, 0.09636879, -0.018609885, 0.0394244, -0.072751366, 0.070646524, -0.14273046, 0.18615629, -0.18295762, 0.010120871, -0.26927498, -0.09483846, 0.02411087, 0.129941, -0.1293687, 0.017706892, -0.034460533, 0.25213918, -0.037213452, 0.15831342, 0.05817065, -0.060092967, -0.1268406, -0.23076093, -0.03980405, 0.25587866, 0.08276356, -0.015190957, -0.30524692, 0.12632711, 0.12676847, 0.268999, -0.47904873, 0.041142117, -0.21129641, 0.068390496, 0.035845697, 0.23408268, 0.04336348, -0.009949063, 0.046893563, -0.017721135, 0.008252693, 0.03632799, -0.104086585, 0.52617913, 0.17738661, -0.16737448, -0.08816514, -0.034325145, -0.22030199, 0.11185168, 0.016032908, 0.050593942, -0.14257213, 0.38018343, -0.09375657, -0.216925, -0.13369736, -0.23965648, -0.008227094, -0.042538676, -0.015210842, -0.014680086, 0.1707869, 0.20302288, -0.017904226, -0.038597852, 0.11746281, 0.021521544, 0.06371136, -0.06775439, -0.20978256, -0.047564067, 0.19409122, -0.11173771, -0.05224924, 0.08012618, 0.10559632, -0.11051275, 0.027860288, 0.18877085, -0.20418473, 0.1541848, 0.13627106, -0.2161013, 0.18996848, -0.23015557, -0.027848912, -0.10234165, 0.15384671, -0.13246043, -0.1478482, -0.09552646, -0.049754124, -0.093143545, -0.10264838, -0.11699935, -0.0963403, -0.032662515, 0.21805666, 0.04566342, 0.12287205, 0.054771375, -0.13864078, 0.05933496, 0.09969795, -0.02829588, 0.3069922, 0.30486393, 0.2578397, -0.10877134, 0.1856469, -0.035391834, 0.124902025, 0.20877972, -0.08883851, -0.12820938, 0.02272916, 0.0017770742, -0.15976723, 0.0445593, 0.024741996, 0.34615973, 0.10760689, -0.03175724, -0.12551016, 0.24894355, -0.3531497, -0.072944045, 0.016822016, -0.15698071, 0.12470341, 0.037341494, 0.21726467, -0.17768486, -0.034894086, -0.010027586, 0.021270577, 0.1507648, -0.0836283, -0.05312594, -0.04595999, 0.062364034, -0.08160741, 0.15661262, 0.4134751, -0.16376059, 0.040606346, 0.0058283363, -0.11285812, 0.016347235, 0.22954069, 0.016610546, -0.1546189, 0.113073446, -0.059399452, 0.20636797, -0.29659933, 0.041379094, 0.040763944, 0.15786538, 0.2156249, -0.0067238105, -0.040766086, 0.28925487, -0.08260869, -0.0020587624, 0.012259777, 0.058570694, -0.06120289, -0.068336114, 0.22695579, -0.030156007, 0.1171598, 0.13914603, -0.1270829, 0.016034098, 0.47446626, -0.042761546, -0.06329835, -0.12255322, -0.3386407, -0.1483657, 0.09656938, -0.20465536, 0.053641178, -0.17872572, 0.248596, -0.10297286, 0.027539002, 0.117598906, 0.07822869, -0.0077944356, -0.13419299, 0.08243991, 0.26522493, -0.2996257, -0.19960038, -0.039966483, -0.1721987, -0.07022188, -0.07931433, -0.3134651, 0.042385694, -0.5790844, -0.24090913, -0.14777882, -0.11001497, 0.12416671, 0.058255617, -0.023503779, 0.12983909, 0.1574763, -0.026349844, 0.17034769, -0.021927407, -0.1649449, 0.095486455, -0.15842314, 0.20153429, 0.119285464, -0.0062256753, 0.15021794, -0.0068196654, 0.14008152, 0.013899376, -0.10681914, -0.0899213, 0.28222755, -0.011710887, 0.15984164, -0.14449015, -0.1413636, -0.1648237, 0.09620782, -0.19785385, -0.16388364, -0.2703289, 0.111387916, -0.11812262, 0.0019218752, 0.13894515, -0.20610772, 0.12066181, -0.16146684, 0.050483108, -0.117644906, 0.089991175, 0.33970943, -0.23599075, 0.0020160154, -0.25958556, 0.20963442, 0.10045109, 0.012577199, -0.001364014, 0.0075368765, -0.058382757, -0.173667, -0.18574388, 0.028312255, -0.11184185, -0.32406545, 0.035149254, 0.20366056, -0.12850651, 0.037241243, 0.098305635, 0.3280601, 0.29763204, -0.17282374, -0.014479555, -0.09972217, -0.20453465, 0.014239424, 0.050995704, -0.24090184, -0.07375173, 0.22922008, 0.319614, 0.008434581, 0.1143453, -0.09043976, -0.14780974, 0.11425937, 0.03380924, -0.026313467, 0.12596186, 0.21912558, 0.08185238, -0.032888982, -0.03462339, 0.13431108, -0.24571748, 0.20586975, 0.11855213, 0.081651226, -0.22200894, 0.070854716, -0.15160629, -0.15413383, -0.03503566, -0.18171372, -0.06442689, 0.12234639, 0.031693857, 0.05514315, 0.016161889, 0.16260335, -0.092136465, -0.10129869, 0.11426495, -0.066946015, -0.18576418, -0.049222466, 0.096514925, 0.1322535, -0.09591251, -0.12715946, -0.19585845, 0.11852933, 0.07039147, 0.08282949, 0.033689614, 0.009269068, 0.14199983, 0.20808765, -0.12975812, 0.21604429, -0.03866415, 0.06802822, -0.06652715, 0.35445526, 0.018253332, 0.08005327, 0.19618662, 0.06801218, -0.15149646, -0.03455081, 0.08829955, -0.35898533, 0.1928383, -0.20995785, -0.15468188, 0.35516882, 0.076555096, 0.2186415, -0.0026571432, -0.16335364, 0.017444415, -0.13419673, -0.059180148, -0.08465373, 0.13461225, -0.04690184, -0.00095871306, -0.010057867, 0.05238462, 0.06843774, 0.04596481, 0.22935148, 0.4005039, 0.19708315, 0.36228627, 0.12392269]}, "content": "Yeah, so definitely like a human in the loop, strong component to it. And I think maybe like when we would present a human search system, and we say, hey, does this query document pair match? So it's like, well, relative to what else and it's like, maybe you show a query in a document, but then so you want to show like documents 2, 3, 4 as well. And it's like these very long paragraphs of text. It's like, I can't read through this. Whereas if you have the keyword list, so it's like query and then keyword list, comparative keyword list, maybe that's a better way to like, get a human judgment. Something like that. ", "podNum": 28, "speaker": "Connor Shorten"}, {"_additional": {"id": "fa06f61e-8374-43b2-bde8-9fd05ebe52fe", "vector": [-0.0065229093, -0.1743989, -0.25524646, -0.16917264, -0.03309926, -0.20243698, -0.12723143, -0.06314932, 0.188458, 0.010178306, -0.026808862, 0.19936755, 0.03534033, 0.07250205, 0.069087766, -0.15168266, -0.043486334, -0.15162289, -0.34260535, -0.0359421, -0.120406054, -0.11433278, 0.039227836, 0.06138316, -0.011308999, 0.13604152, 0.015231868, -0.12702136, -0.13918222, -0.13150936, 0.052493133, 0.06971283, 0.06998647, -0.109678924, -0.16925013, 0.12669194, 0.00035379734, 0.076464646, -0.008826248, 0.055755164, -0.012492382, -0.0977106, -0.13042465, 0.22798702, 0.1241816, 0.07685608, -0.033529527, -0.026406584, -0.12033516, 0.040042542, -0.11262068, 0.07118137, 0.012765385, -0.053921808, -0.06820689, 0.21628165, 0.14087206, -0.15188242, -0.058915317, 0.060145717, 0.041705247, -0.11863956, -0.20361215, 0.280195, 0.2376429, -0.17659363, 0.109083965, -0.16060916, -0.08889513, 0.13485666, 0.015941434, -0.032160744, 0.053294018, 0.06849514, 0.058415815, 0.09749055, 0.04065644, 0.0041878717, 0.13810134, -0.1664873, 0.042290002, -0.117129, 0.07542895, 0.047343753, 0.16191798, 0.11956939, 0.007894389, 0.083792284, -0.05983102, -0.11053966, -0.1732842, -0.13705005, -0.065459006, -0.025905594, -0.011599669, 0.17158484, 0.036413014, -0.06874369, 0.0008773273, 0.12143224, -0.30414966, 0.096185975, -0.0485807, -0.31575197, 0.005364064, -0.31893915, -0.024979508, 0.1019472, 0.13971844, -0.1721197, 0.027240869, 0.0113871675, -0.08256498, 0.062385876, 0.08584519, -0.18219823, -0.2872205, 0.03487224, 0.058558445, -0.14408518, -0.044935957, -0.038953938, -0.034484252, -0.00251567, 0.08425942, -0.21611819, -0.050305955, 0.15215823, 0.110804886, 0.045206822, 0.09478262, -0.079742394, -0.013444589, 0.10319592, -0.024135172, -0.053525705, 0.18273544, -0.035322763, -0.15179631, 0.1228995, 0.14708422, 0.33237845, 0.2383304, -0.058460645, -0.30513087, 0.31064206, -0.020312866, -0.059139594, 0.22602543, -0.15977874, -0.09719084, -0.057711676, 0.15365216, -0.1303891, 0.08706869, -0.008608553, -0.11939708, 0.1123971, -0.076369666, -0.0077527105, -0.2007654, 0.10375673, -0.0833713, 0.029527636, 0.14606561, -0.052903183, 0.048230283, -0.04308175, 0.12269792, 0.08561518, 0.018128278, -0.09132743, -0.0049655177, 0.034972966, -0.00677523, -0.03249877, -0.31063122, -0.0575914, 0.0737161, 0.08306537, 0.08173117, 0.009289572, 0.16046785, 0.12518439, -0.056545272, -0.1009681, 0.10057401, 0.042290393, -0.12262483, -0.021083592, -0.16108772, 0.10394132, -0.016440189, 0.23993284, -0.00844887, -0.11923036, 0.22137648, 0.15451363, -0.028578417, -0.038516875, -0.31887245, -0.11982691, -0.0033527126, -0.026441244, 0.12115875, -0.052230477, 0.07942339, -0.0073085227, -0.121866696, 0.11140391, -0.039902225, -0.18978855, -0.071805544, 0.1991752, 0.18104038, -0.017995419, -0.20575504, -0.02162665, -0.054989222, 0.07797748, 0.015143193, -0.08648893, -0.016038572, -0.4136494, -0.26642543, -0.17253411, 0.089127846, 0.10022609, 0.041353494, 0.11271447, 0.2389834, -0.19894755, -0.041495264, 0.057948, -0.06391013, -0.0536654, 0.059897125, -0.0021032616, 0.08279686, -0.10950554, -0.14074454, -0.06134973, 0.09588481, -0.022310391, 0.07360698, 0.17267546, -0.051669423, 0.23799346, 0.09472564, 0.23650935, -0.29422534, 0.029240804, -0.0389739, 0.0762972, -0.19683848, -0.15214439, -0.29739046, 0.0568424, -0.08865926, 0.11083785, 0.2040366, -0.019609477, 0.043886606, -0.06105178, 0.048350215, 0.01484799, -0.1978842, 0.2135762, -0.1013481, -0.035569724, -0.041248873, 0.12802666, -0.08570145, 0.0020956025, 0.1186053, 0.13594863, -0.04005442, -0.172126, -0.28251696, 0.059598826, 0.07042284, -0.16047415, 0.108439386, 0.078494884, 0.1356403, -0.25131646, 0.034663226, 0.019942729, 0.08536567, -0.012237794, 0.14189014, 0.137147, -0.0116445925, 0.083584934, 0.11283766, 0.10070794, 0.03255578, 0.23206067, 0.16112828, 0.14570087, -0.087472335, -0.1280205, -0.08595824, 0.014000233, -0.0007891152, -0.10478334, 0.1253514, 0.1813887, 0.23871958, -0.011348613, 0.09291755, -0.10094445, -0.054764904, 0.034439165, -0.095976934, 0.037996, -0.13197383, 0.11588138, -0.117192425, -0.060367938, -0.02296564, -0.09647143, 0.088752896, 0.20738249, -0.02829032, 0.049932387, 0.11674104, 0.121153705, -0.05345389, -0.0989718, 0.147767, -0.086243935, -0.07629118, 0.17775446, 0.2701217, 0.3379758, -0.059006147, 0.09699107, -0.11197039, 0.028208898, 0.010172194, 0.12075974, -0.010484515, 0.08014391, 0.18114936, 0.06409396, 0.0048374115, 0.43936437, -0.014811901, -0.03813982, -0.13986963, 0.15472147, 0.062540546, 0.055606864, 0.18982062, -0.10064097, -0.12806916, 0.04824596, 0.1763201, -0.23114108, -0.05428786, -0.088609755, -0.15434463, 0.31219006, -0.0771942, 0.019619003, -0.049361754, -0.039853055, -0.080235384, 0.13351059, 0.03383707, 0.1271547, 0.07511933, -0.06953154, 0.1954636, -0.052409664, -0.048739646, -0.17137253, -0.19739641, 0.15692583, 0.049403533, 0.11146961, 0.35501987, -0.10477453]}, "content": "Yeah. Yeah. I mean, we think about this thing internally, obviously, from our background, from MIT, you know, co-founders, Nir Shaveed, professor at MIT, really accredited, wonderful individual. And his postdoc, Alex Matiev, that they co-founded this company together. You know, they were working in a connectomics lab together and working with brain researchers as the computer science people to help them. And yeah, they sort of, from the problem they were working on, they were trying to image and pattern out brains. And these are obviously sparse architectures. So they came up with sparse algorithms to map onto the brain. And so, yeah, totally, you know, the road we're going down in terms of, or the road we are down in terms of training models and deploying them very much works on the idea of having dense layers, feeding into dense layers, larger and larger models that are at fully connected layers. And like I said, this works well because we found a golden bullet that works for now, stochastic gradient descent. You just throw more data at it, you regularize it enough, you show it enough data at a time, and it can just continue and continue to keep learning. But that doesn't mean that it is the best way. And I think like in the future, you know, this scaling, especially as Moore's law, you know, struggles to continue forward, we need to find more efficient ways of training and running these models. And this is what we hear exactly from our customer engagements. They, a lot of times they have models running in production, or they're gearing up, and then they're getting some load, and they're realizing, yeah, this doesn't make sense. But the value is there for their, for the people using it. It's just too expensive operationally to run all these models. And that's because most of the time, they're just training the model on the GPU. And then they're like, well, it's accurate. How do we run it? And then they go run it on the same GPU that they that they trained on. And, you know, haven't taken the thought of from training to inference, let's have a step of optimization in there. And that's really what we're what we're working on now, introducing that optimization step to more and more people. Now, of course, like, you probably shouldn't be training dense models in the first place, but it'll take a lot of research and progress in science to get there. But I'm sure we can get there. You know, purely from the idea. Yeah, the brain is a is the equivalent to a cell phone of compute with a petaflop of memory. It's not the other way around, where, you know, we don't have exaflops of compute in our brains. With it with it. Yeah, certainly we don't have teraflops of compute with just, you know, 16 gigabytes of memory attached. We we have a lot more memory and access it really efficiently so that we don't need to eat all the time. So, so, yeah, that that's that's definitely how we think about it. But also, you know, just in case of talking about this asynchronous execution that that that we built in our engine as deep tensor columns, it's not like we're the only ones working on this. You know, a great example actually is the the really famous Google paper from I think about a year ago, Pathways, or even their sparse transformers paper before that, where they trained, you know, I think a trillion parameter model even larger than GPT-3. But the key thing was, based on the input coming in, you know, you would have, say, multiple multi head attention or fully connected layers, multiple, essentially experts you could choose from. And based on the input coming in, it would route it through a different pipeline. So you have, you know, 100 times more parameters than you would actually use for each individual inference, but you're sampling them over time for different inferences. So this is obviously at a very structural, large scale, but it, you know, it makes sense. This is what the brain does. We're not accessing, we're not running all of the weights and parameters and neurons and synapses in our brain every second. It's localized to certain pieces that we need to run every single millisecond or pieces that we need to run, we need to remember a nice memory or something like that. So, so, yeah, it's, it's really interesting. ", "podNum": 27, "speaker": "Michael Goin"}, {"_additional": {"id": "fa912b44-f9d9-4cda-8ce1-cef62e620ac4", "vector": [-0.040886477, -0.21961778, -0.0664588, -0.20407343, -0.04895431, -0.035685502, -0.35709035, -0.03127019, 0.21868463, -0.063540466, 0.17815001, 0.1622553, 0.062522836, -0.058827225, 0.30187285, -0.104965046, 0.08827119, -0.01546646, -0.39683926, 0.22816896, -0.26426962, -0.21202749, 0.0139898565, 0.06216328, 0.043129183, -0.080416545, 0.08488237, 0.06638651, -0.23400725, -0.2674559, -0.013587453, 0.16332908, 0.117155045, -0.12874252, -0.04714699, 0.013931883, 0.045469467, 0.046564613, -0.04180323, 0.04340609, -0.08066122, -0.09747399, -0.041696426, 0.23571806, 0.011548942, 0.12038181, 0.048705008, 0.0020379422, -0.20826696, -0.07218142, -0.07048324, 0.022526665, -0.1135434, 0.09149491, -0.20227176, 0.0696674, -0.052312374, -0.117462724, 0.028354429, 0.013140285, 0.11060459, -0.053657196, -0.22870703, 0.26391542, 0.17870621, -0.014307902, 0.05758734, -0.19929141, -0.07585905, 0.13719185, -0.08206199, -0.16702046, -0.09255446, 0.14216971, -0.1857741, -0.1127732, 0.17701057, 0.12908578, 0.20592289, 0.09116977, -0.048592106, -0.23213695, -0.071976, 0.05021043, -0.021496248, -0.08077706, 0.22058368, -0.027073633, -0.10083335, -0.16714667, -0.21901359, 0.115384005, -0.110559344, 0.11544312, -0.027359348, 0.12397838, 0.053722706, -0.22074075, 0.035686333, 0.17479354, -0.1801659, 0.16190527, -0.013449097, -0.21690926, 0.060765218, -0.28103608, 0.026977656, 0.074207194, 0.18723553, 0.03230446, -0.04507551, 0.03855388, -0.0024708651, -0.08255861, -0.08237288, -0.07559521, -0.25298068, 0.1334057, 0.12751842, -0.18955016, 0.09368854, -0.039560556, 0.10497557, -0.066144496, 0.060410157, 0.11589419, -0.118306234, 0.17617084, 0.065499984, -0.008764845, 0.11546898, -0.12653838, 0.071541645, 0.17077592, -0.021343624, -0.021098195, 0.049837183, 0.060287345, -0.1415135, 0.05203532, -0.18364714, 0.25220796, 0.18101591, 0.045703586, -0.23605618, 0.19986215, -0.05845123, 0.017700149, 0.07077734, -0.20194346, -0.089827366, -0.055624608, 0.35186145, -0.4087836, 0.18243584, -0.08832286, -0.1487744, -0.038749922, -0.10855703, 0.062482312, -0.1648805, 0.03210583, -0.11083579, -0.030338489, -0.019072473, -0.047684316, -0.0030271357, -0.15335053, 0.12169983, 0.15875338, 0.08169503, -0.03064881, -0.0024258196, -0.0560811, 0.10594643, 0.061756823, -0.3642025, 0.121312425, 0.0055806916, 0.11014381, 0.011783435, 0.05386772, 0.036592245, 0.007120344, -0.065522954, -0.14347804, -0.0586329, 0.024764575, -0.21020006, -0.09188099, 0.07205203, 0.030634256, 0.025886059, 0.30911234, 0.02192047, -0.16474858, 0.17985664, 0.040636823, 0.019132597, 0.0067869616, -0.3965869, -0.13543195, 0.07716322, -0.23532644, 0.069129124, -0.10977772, 0.2638621, -0.022047542, -0.15836725, 0.095805414, -0.037778463, -0.04224716, -0.20091596, 0.0374105, 0.09603563, 0.1473988, 0.089161135, -0.24815258, -0.302884, -0.014428952, -0.062986635, -0.11165068, 0.06265856, -0.3847299, -0.19987097, -0.31384212, 0.0028410272, 0.22364475, 0.18632837, 0.10241905, 0.19933839, 0.096618205, 0.047955144, 0.2737734, -0.113481596, 0.04620149, 0.16456395, -0.11951711, 0.020984812, 0.0050615612, -0.045240957, -0.063051745, 0.22990388, 0.016506167, 0.12777378, 0.13428149, -0.16147055, 0.22217512, 0.09951146, 0.25256217, -0.32989326, 0.13005558, -0.12944135, 0.07752629, -0.060998105, -0.1933559, -0.28024352, 0.07179751, -0.1191313, 0.12873763, 0.1739339, -0.21955846, -0.14037731, -0.041353587, 0.119600266, 0.05927306, -0.08488417, 0.116545364, -0.2298535, -0.11745154, 0.12036193, 0.11305228, 0.07899038, -0.14050962, 0.12445111, 0.33076188, -0.06475332, 0.02524497, -0.3600644, 0.03460533, -0.06774687, -0.11962248, -0.13770276, 0.3213464, 0.17884721, -0.15080762, -0.06841034, 0.05920049, 0.10066256, -0.2204074, 0.08856664, 0.15758763, -0.114865065, 0.034444302, 0.11681934, -0.16976644, -0.008289477, 0.20604806, 0.120626256, -0.021076053, 0.18112057, -0.074212454, -0.102700494, 0.008200701, -0.059366968, 0.01146185, 0.1389176, 0.1322831, 0.16421685, 0.26636598, -0.12057266, -0.12307306, 0.017306315, 0.25622967, -0.19665962, 0.21546426, -0.038295116, 0.082809694, -0.10162473, -0.043567587, 0.107421845, 0.15163817, 0.09774759, 0.28114942, -0.1720329, 0.029659342, 0.017700516, -0.027632771, -0.018458623, -0.01707972, 0.14160375, -0.10447213, -0.06295154, 0.07182887, 0.26091707, 0.308596, 0.0095180115, 0.0015635585, -0.10242009, 0.17413782, 0.028680068, 0.20914912, 0.03849298, 0.10012016, 0.15975763, -0.0020017854, 0.062079225, 0.30052376, 0.004267606, 0.017953442, 0.12677713, 0.29958817, 0.09273791, 0.10131347, 0.061328802, -0.006955469, -0.14803042, 0.0202907, 0.07374197, -0.1899684, -0.023626257, -0.33284977, -0.1072223, 0.3157101, -0.1324717, 0.10261483, 0.020083426, -0.35876513, -0.10078443, 0.17810509, 0.31737188, 0.08004563, 0.029652249, -0.10034668, 0.12329666, -0.04448539, -0.044626333, 0.08885223, -0.22980143, 0.19100922, 0.075966075, -0.18963923, 0.24220341, -0.030678134]}, "content": "First of all, I don't think anyone knows, which makes this so exciting. I think, yeah, I mean, like, I don't know, right now, the private models are way better than the open source models. Like, I think it's, yeah, like, you know, GPT, GPT-3 is way better than the best open source models, probably Flan-T5. Anthropic, when they come out with their model, will probably be pretty good. I think there, you know, it's like, it's possible that there, it's possible there will be a better open source model release. It's possible that to your point around, like, having a model specifically for medical or specifically for law, maybe you can get that by fine tuning Flan-T5. And it's, and it's less about kind of like, you know, maybe for like, smaller, more narrow things like that. Actually, definitely for small, for smaller, narrow things. You can probably get just as good performance by fine tuning Flan-T5 or something like that. First, like, it kind of just depends on like, what small and narrow is, right? Like, is law like small and narrow? I would argue it's still kind of like big and out there, but it's definitely smaller than like, every piece of knowledge under the sun. So, yeah, I don't know. I mean, I guess my current guess would be that they'll be like, the private models will be the best general purpose models, the open source models will be fine for smaller tasks. And I think probably over time, like the, like, the open source models will start catching up. And at the same time, the private models will keep on getting better and better. So I think there'll always be this gap, it will just become, like, you know, what's in this gap? Is the real value in this gap? Or is the real value now doable with like, smaller fine tuned models? And I don't, I don't know. I mean, I think it's the real value now doable with like, smaller fine tuned models. And I don't, I don't, I don't know, I don't know how fast those move up a lot, a lot of questions. ", "podNum": 36, "speaker": "Harrison Chase"}, {"_additional": {"id": "fabc7e81-dca8-45c6-808f-454f9d4053a6", "vector": [0.021730088, -0.21121345, -0.10049623, -0.19499992, -0.07663191, -0.25139078, 0.19723661, -0.07904338, 0.054769132, 0.036323473, 0.0064887702, 0.25988412, 0.0689345, 0.14536364, 0.20008703, -0.04233751, 0.043016855, -0.23171502, -0.45185825, -0.22949733, -0.17785351, -0.21949892, 0.01239315, -0.046560418, -0.08163143, 0.2799994, -0.0564267, -0.01203614, -0.15603735, 0.00711518, 0.065333046, -0.05343722, -0.09272427, -0.08350112, -0.090473615, 0.2257294, -0.086482085, 0.11512611, 0.1989733, -0.1470562, -0.12059402, -0.16170458, -0.16426197, 0.12154254, 0.1933494, -0.077496596, 0.0030892517, 0.06444289, -0.022208735, -0.08151969, -0.06825907, 0.22096114, -0.09726683, 0.028356925, -0.01974286, 0.2138144, 0.106770225, -0.060309578, -0.14736535, 0.038152065, -0.02612312, -0.0037575234, -0.23741917, 0.36452594, 0.15564968, -0.09181001, 0.103813924, -0.14716767, -0.1713243, 0.5761774, -0.0063807718, -0.07417909, 0.031476717, 0.28548673, 0.18604694, -0.028115066, -0.0094750775, -0.123937756, 0.02882368, -0.009109999, -0.07788601, -0.2779267, 0.15550445, 0.06360374, -0.0501411, -0.11756905, 0.17085476, 0.06528541, 0.30450383, -0.008225282, -0.08736869, -0.14751878, 0.05304269, 0.057510335, 0.103258945, 0.13580844, 0.0704068, 0.22416778, -0.067525156, 0.1911062, -0.27643573, 0.06540459, -0.07846146, -0.31126627, 0.29746154, -0.2953693, -0.0014843842, -0.10534646, 0.08126131, -0.17020345, -0.067787796, 0.05308163, 0.100624494, -0.048525047, -0.14410858, 0.2704377, -0.19324528, 0.19856964, 0.056699783, -0.1521718, -0.008785884, 0.08629283, -0.17756237, -0.0018370649, 0.032451056, -0.26924816, 0.14242516, 0.04785337, 0.03920114, -0.16591872, -0.10548192, -0.10964134, 0.069436766, 0.066745155, -0.011508763, 0.062230766, 0.3181487, 0.09800243, -0.003250872, 0.01256298, 0.13480766, 0.054680664, 0.09195667, 0.13687545, -0.24406193, 0.41970006, -0.20262422, -0.03484168, 0.07816729, -0.3443505, -0.13159677, 0.2164548, 0.034326963, -0.18359824, 0.015389234, 0.030841133, 0.054305237, 0.08722031, 0.070459776, -0.10890096, -0.24031162, 0.26301053, -0.112527706, 0.019410392, 0.20617627, 0.09029523, 0.16103585, -0.0628373, -0.3276612, 0.25094983, 0.014486005, -0.046035934, -0.0075948387, -0.25099578, -0.23928992, 0.085077696, -0.28635356, 0.06144513, 0.22741729, 0.069819845, 0.25875118, 0.1558396, 0.03868576, 0.30205184, -0.11586686, -0.101792075, 0.010901536, 0.08981634, -0.00229383, -0.20551245, -0.2849558, -0.0683632, -0.04161982, 0.2825576, -0.01625335, 0.04534267, 0.2790956, 0.20163657, -0.04675897, 0.009252352, -0.27066067, -0.40694508, -0.037668325, -0.27032542, 0.1861639, -0.09155488, 0.047800798, -0.14501484, 0.32802883, -0.03728623, -0.031289205, -0.1598303, -0.049179528, 0.17170994, -0.026159802, -0.119011946, -0.121899284, 0.18432455, -0.22587918, -0.068837725, 0.08801081, -0.2183299, 0.04626469, -0.3884811, -0.108648635, -0.38266763, -0.039981116, 0.24132948, 0.022683421, 0.09002924, 0.08707604, -0.13869059, -0.0980294, -0.05005863, -0.17748626, -0.09400528, 0.13976431, 0.12090701, -0.07804186, 0.04157662, -0.13498294, 0.0007536014, -0.06721208, 0.120860755, 0.07034162, 0.20227419, -0.014343302, 0.33575773, 0.009449239, 0.08357505, -0.28108883, 0.08923146, -0.12354827, 0.15414597, -0.2220596, 0.055483624, -0.38944098, -0.0010452227, -0.24229151, 0.07116222, 0.20776258, 0.0023352702, -0.041669022, -0.08872384, 0.18322559, -0.071346454, -0.1562333, 0.327997, -0.06516019, -0.02542719, -0.15601063, 0.08192617, -0.103022605, -0.08196734, 0.0003052006, 0.124786906, 0.07672525, -0.06528954, -0.3308628, 0.16997856, -0.16198346, -0.3072596, -0.17101496, 0.0698199, 0.1383356, -0.15787198, 0.22746508, 0.09177906, 0.24024935, -0.05466826, -0.09177533, 0.0141914785, 0.08726984, -0.052920546, 0.0894928, 0.11745548, -0.07937787, 0.062482238, 0.14965165, 0.32190213, -0.09257054, -0.161451, -0.31351098, 0.14406276, -0.050828498, -0.03232411, 0.060126465, 0.17183487, -0.15084614, -0.045557152, -0.06500166, -0.023758546, -0.045719087, -0.014382742, 0.06763702, 0.09619025, -0.10279447, 0.16818523, -0.12124697, 0.009653409, -0.11969083, -0.14093827, 0.11241745, 0.2694213, 0.0054053813, 0.060346026, 0.09296963, 0.036394726, -0.06899462, -0.2334366, 0.18957031, -0.047492847, -0.1571878, -0.025260204, 0.25690326, 0.1826543, -0.134876, 0.031821776, -0.2338597, 0.17252253, 0.048170883, 0.026449375, -0.025528058, 0.34144557, 0.23538382, -0.02722772, 0.0650894, 0.28024602, -0.021530276, 0.12140864, -0.0798955, 0.22617202, 0.15993032, 0.12885168, 0.3927368, -0.09725269, 0.08209913, -0.13294213, -0.021841675, -0.18836935, -0.0029692028, -0.15523823, -0.28203347, 0.29934755, -0.23075865, -0.006412531, 0.033235904, -0.01460177, 0.13585818, 0.15524288, 0.100413464, 0.069209404, -0.0012386838, -0.16114229, 0.18472593, -0.082000844, 0.041118164, -0.077334814, -0.22230826, 0.2711902, 0.19061995, 0.14381503, 0.49707118, 0.00022338827]}, "content": "Yeah, it's never bad practice to decompose in those situations. If you find yourself with a bunch of parsing logic and then a bunch of like indexing logic, just pull those apart. You parse, you dump to Parquet, and then you have another job that just reads Parquet and indexes. And you get a little bit more introspection because of the way that Spark, the DAG execution works, it's all lazy and it's super unclear when things actually happen. And it can look like some operations take a really long time when they shouldn't because really that's the way it's shown in because really that's what actually triggers the eager execution of all the operations behind it. Yeah.", "podNum": 32, "speaker": "Sam Bean"}, {"_additional": {"id": "fc22fab6-9ca0-4eaa-a94b-66174670f3cb", "vector": [-0.1846704, -0.19842456, -0.24852405, -0.26282647, -0.07170656, -0.06516585, -0.011143415, 0.062583014, -0.14123489, 0.07067058, -0.1219513, 0.16474217, 0.022535624, 0.06943955, 0.22616105, 0.09341009, -0.12296139, 0.044148568, -0.37304044, -0.023266513, -0.122528344, -0.09038952, -0.045279004, 0.011402797, -0.012779081, 0.21015312, 0.14023268, -0.05023297, -0.058286287, -0.12345065, -0.044927064, -0.0028137374, 0.029731553, 0.082446426, -0.13684043, 0.1395521, -0.24198757, 0.08585389, -0.08254812, -0.06950761, -0.020100446, -0.064367145, -0.07970521, 0.09483556, 0.048774075, -0.15426485, 0.045672975, -0.0012165701, -0.094629936, -0.057051167, -0.038112573, 0.0075493385, -0.06874577, -0.051483985, -0.09915056, 0.21964058, 0.23169579, -0.026969032, -0.011939116, -0.03699776, -0.07206112, -0.17680618, 0.015266519, 0.10603275, 0.11165925, -0.09615717, 0.0858714, -0.058274645, 0.016055018, -0.0010881901, -0.16263457, -0.24114576, -0.25548613, -0.0026159286, 0.07620063, 0.049022924, -0.032756314, 0.03984327, 0.102017574, -0.026263481, -0.078333095, -0.032659616, -0.053081635, 0.020180369, 0.18337081, 0.19447123, 0.16818653, -0.10711146, 0.07988318, 0.15036447, -0.059620827, 0.13260671, 0.10453347, 0.1390558, -0.08216077, 0.0874738, 0.041216377, -0.07665451, 0.053189877, 0.040577974, -0.18852083, -0.07398406, -0.18963672, -0.2023285, 0.1742919, -0.29724252, 0.09222177, 0.15060319, -0.010073197, -0.2157872, 0.13999851, -0.012416506, 0.012188483, -0.20121711, 0.049693096, -0.06622645, -0.2773181, -0.0345127, -0.018921638, -0.03735011, 0.29361308, -0.011100447, 0.09488408, 0.21556649, 0.038495913, -0.17489208, -0.094644845, 0.01790588, 0.1493763, 0.21169388, 0.16861011, 0.1042172, -0.13435608, 0.118528515, -0.09784912, 0.07932515, 0.039194744, 0.0019919956, -0.11812519, 0.27781564, 0.038069807, 0.32229167, 0.06625641, -0.09910101, -0.076364376, 0.2237989, -0.15590602, 0.01226891, 0.028828891, -0.12569164, -0.07524174, -0.033857062, 0.019612882, -0.0040902374, 0.080641955, 0.012856372, -0.024519358, 0.16273889, 0.12855747, -0.25398496, -0.16422133, 0.17382036, 0.006540173, -0.20440227, 0.20383678, -0.064709835, -0.0011755705, 0.12002117, -0.08863937, 0.101709165, -0.03184893, -0.15290838, 0.06874054, -0.14950891, 0.122877985, 0.10703295, -0.22908325, -0.046692744, 0.20155792, 0.1889976, 0.32696372, 0.30624235, 0.101323105, 0.09094539, -0.121843606, -0.05544733, 0.17371996, 0.10612831, -0.16558278, -0.015180778, -0.23565765, 0.07976165, -0.13706309, 0.17011546, 0.05945151, -0.13038406, 0.11538477, 0.10870085, -0.05937994, 0.013790946, -0.36795035, -0.045076, -0.2079933, -0.2397912, 0.11274068, 0.1619168, 0.03213366, -0.07036379, -0.122990154, 0.15673737, -0.08075168, -0.18477984, 0.0100199245, 0.0054759993, 0.12027237, -0.21682468, -0.29650596, 0.06142315, -0.17595893, -0.073988326, 0.15566212, -0.16055328, 0.33390534, -0.32483143, -0.18345283, -0.063471414, 0.02852222, 0.13623077, -0.026591474, -0.02336601, 0.24035911, -0.21616463, 0.026543472, 0.062072784, -0.12537937, -0.055116728, 0.24540262, -0.17653699, 0.03434032, -0.11739822, -0.11356341, -0.08832699, -0.005438992, -0.04490699, -0.12435449, 0.3258429, -0.11358654, 0.002587793, 0.0769899, 0.08784512, -0.3099657, -0.014198976, 0.00015509248, 0.12475021, -0.27482274, 0.16218364, -0.4087191, 0.0055256756, -0.12556303, 0.07974256, 0.15522414, 0.0012675762, 0.0821761, 0.034473393, 0.12826964, -0.011398077, -0.14206041, 0.12376323, -0.3056688, 0.022831807, -0.11283225, 0.15976611, -0.0065827095, 0.227382, 0.120901965, 0.14387313, 0.14376976, -0.1404676, -0.19680713, 0.005303466, 0.12991753, -0.048075646, -0.09867315, 0.3436101, 0.14461897, -0.31131974, 0.08823549, -0.049404573, 0.22483028, -0.22088127, 0.0038337326, -0.024047485, -0.04374294, -0.090251826, 0.05098046, 0.114187114, 0.09971492, 0.19685753, 0.08099867, 0.07407631, -0.08793947, -0.08218097, -0.083742835, -0.11548458, 0.01348218, -0.20178393, 0.27206913, 0.19297573, 0.224235, -0.07450247, 0.12397803, 0.08877392, -0.035830013, -0.002537968, -0.18158768, -0.012451744, -0.10404733, 0.2039624, -0.0891114, 0.024209872, -0.0490413, -0.05369183, 0.07837296, 0.18834612, 0.02895061, 0.2705146, -0.11742339, 0.15163499, -0.09338561, -0.05077834, 0.19381328, 0.07538969, -0.029024195, 0.11230778, 0.11721298, 0.067937635, -0.019358203, 0.13135302, -0.10791165, 0.15623422, -0.00037368297, 0.16712691, -0.3494896, 0.055740066, -0.06496151, -0.14999604, 0.1429914, 0.38849586, 0.07995359, -0.026060496, -0.0010211134, 0.008399329, 0.1937621, 0.034305677, 0.04731113, 0.15976004, 0.026555672, -0.037634462, -0.009274622, -0.07891678, -0.0018483782, -0.051463872, -0.19296734, 0.11758171, -0.25490442, 0.01768461, -0.0062945737, -0.15132537, -0.024171602, 0.22221953, -0.07663642, 0.14321895, 0.008334374, -0.022705493, 0.2131405, -0.086557776, 0.09805925, -0.11599797, 0.07093815, 0.2218051, 0.0008559889, 0.16911668, 0.21454306, -0.10105545]}, "content": "Yeah, obviously, it comes with... All of the Spark connectors are different because they each require a certain amount of domain expertise with being able to marshal the data into the end, the sink, as they call it in Spark. And obviously, definitely was not a one person's effort. So definitely want to shout out everyone from Weave V8 who helped out. And absolutely, Sam Stallinga, who spent a bunch of time with me pair programming and did a bunch of the lift on developing the Spark connector with me. I think that largely, you can start out building a Spark connector by the Spark connector by figuring out how to do it in a UDF or a Pandas UDF. And in Spark, a UDF is like a user defined function. And it's just some arbitrary code that you tell Spark, you're going to loop over this data frame. We're going to tell you which columns from the data frame are going to get passed in, and then you just execute that code per row. And once you can run your... You have your data integration working in a UDF format, it becomes a matter of... You can do that forever, if you want to. At that point, you're not going to get a ton of the actual performance improvements, because you can parallelize that UDF in a massive way in the same way that you could with a native data frame writer. But you're always going to be making changes to that. You're always going to be cutting against the grain with what are the opinionated Spark idiomatic ways of doing things. And so things like error handling, things like check pointing, things like retrying, a lot of the stuff that you would use Spark for, because you don't want to think about that, because it's hard. And you have enough things to do on your plate that you don't want to think about what retry logic needs to look like in a data pipeline, or error recovery, that you delegate all of that complexity into Spark. So it makes sense at some point, once you're dealing with a certain level of complexity, to try to graft all of that code into what is the opinionated Spark way of doing things. And that usually means extending a number of the core abstract classes that are available in Spark. So like I said, the Spark data frame writer. There's a number of examples that you can look at it, be it Neo4j or Elasticsearch. I think that there's even some examples that you can look at, but there's just a number of core classes that you need to override, but largely, once you have that code operating in a UDF, it just becomes a matter of grafting that into the objects that Spark expects. And then figuring out how to deploy that code in a JAR format into a Spark cluster, and then accessing that as one of the writers. But it really becomes a matter of you're either going to have a UDF, and you're going to run a map. You're going to map that UDF over your data frame versus being able to say, just take the data frame, and I'm going to call itjust .write.format.weaviate.save, and then you're done. And so you take all that logic that you might have to maintain or evolve in a way that is going to be more difficult, and then try to, once again, delegate all of that complexity into a central place, which is the Weaviate Spark connector. And then as a community, we can all swarm on that and make sure that it's the best in class for writing data into Weaviate, and then lots of people get to access it, and it becomes very easy to turn your brain off, which is the point, right? Make it really easy to take your Spark data frame, pump it into Weaviate, and not have to think twice about it.", "podNum": 32, "speaker": "Sam Bean"}, {"_additional": {"id": "fc9ad639-8b09-4331-a2c5-0c04f6e4126f", "vector": [0.09402809, 0.040354025, 0.08895772, -0.08491278, 0.0033326198, -0.18586917, 0.31064177, 0.081632845, -0.22618969, 0.010783597, -0.019940354, -0.08133184, 0.21504207, -0.026742613, 0.3647054, 0.11224101, 0.25635073, -0.042993184, -0.340639, -0.032061566, -0.19578254, 0.07248196, 0.0920972, 0.024780773, -0.038513817, -0.062033046, 0.05100273, 0.18418205, -0.008647365, -0.019688904, -0.027706483, -0.011285235, -0.2089293, -0.08703091, -0.04047149, 0.19338334, 0.07118256, 0.11721661, -0.1189405, 0.18114342, 0.0067965784, -0.3669465, -0.0659272, -0.024003252, 0.0032871645, -0.0070955977, -0.066665314, 0.040142883, -0.018593542, 0.17496936, 0.14290534, -0.037210356, -0.13725857, 0.091175586, 0.113729954, 0.36440778, 0.035749268, -0.35604036, -0.086567335, 0.08842065, 0.04991971, -0.10845903, -0.29598585, 0.7333923, 0.24087061, -0.13094988, -0.098026566, -0.109273374, -0.3380488, 0.224449, 0.00021822129, -0.0042646527, 0.07953089, 0.070997946, -0.10469336, -0.2778789, 0.07848469, 0.029280545, -0.0826431, -0.24266337, -0.01248262, -0.28400442, -0.05020979, 0.015459478, 0.0051711276, -0.19419599, 0.071521655, 0.1298803, -0.22372274, -0.19031824, -0.37608805, 0.24613881, -0.008697976, 0.02652057, -0.07726753, 0.062067848, 0.13519748, -0.23889597, -0.11016696, 0.85859966, -0.38267288, 0.087570064, -0.11978739, -0.3174822, 0.02002282, -0.166113, -0.21861093, -0.052472327, 0.17883134, -0.08549879, -0.008178969, -0.08588907, -0.057091653, 0.17276727, -0.070364125, -0.064421825, -0.07290734, 0.12724014, 0.1777433, -0.45956728, 0.07138663, 0.0003166677, 0.13739489, 0.13218796, -0.07476931, -0.49105927, 0.46415362, 0.19191909, 0.0024700563, 0.038021427, 0.108747445, -0.016980851, 0.26470032, 0.37604582, -0.29642114, -0.24085557, 0.016185531, 0.15532751, -0.1646647, -0.043350834, -0.13645107, 0.10992243, 0.26679054, 0.014730863, -0.13201164, 0.14513688, -0.15531038, 0.028834164, -0.084258534, 0.017498821, -0.1936488, 0.29160675, 0.37203264, -0.22074111, 0.33543003, -0.17890853, 0.42072758, 0.09074267, 0.17866905, -0.059262052, -0.040844787, 0.18083106, -0.044831168, -0.25874522, -0.22764878, -0.046463534, -0.029522464, 0.06745611, 0.026682504, 0.13463701, 0.033736464, 0.0527359, 0.11539141, 0.24046536, -0.112671524, 0.0075833327, -0.044974465, 0.08570879, 0.11494265, 0.12874752, 0.009866923, 0.04954697, 0.14547218, 0.024887294, -0.10863608, 0.035014357, -0.018186064, 0.14819291, -0.21876787, -0.09357152, -0.13127346, -0.28581923, -0.28401926, 0.27130383, 0.06889213, -0.16382387, 0.32623386, -0.01579276, 0.08831198, 0.016552938, -0.363614, -0.1938042, 0.15708826, -0.29206797, 0.25243083, -0.107500054, 0.3682404, -0.11313897, 0.120574, 0.21047115, -0.20515327, 0.0007658452, -0.02907922, 0.11226303, -0.015833437, 0.001700153, -0.026880547, 0.18723226, -0.21122567, 0.10620087, 0.124922216, -0.038491488, -0.24890883, -0.58283514, -0.004478361, -0.20947802, 0.013386044, 0.5262789, 0.141579, -0.019433655, 0.11519008, -0.19749485, -0.142577, -0.0020043452, -0.0054404736, -0.0926165, 0.116333805, -0.13854282, 0.08358308, 0.14069067, -0.19609182, 0.06902211, -0.010043369, 0.27368823, 0.18044853, 0.27467367, -0.2332664, 0.42300603, -0.091603704, 0.37573624, -0.3530762, -0.043164168, -0.4201585, 0.03804207, -0.31035236, -0.099751174, -0.269478, -0.07606091, -0.14161368, 0.27271393, 0.42953587, -0.5764727, -0.29886124, 0.029457187, 0.21518677, -0.22993489, -0.21558042, 0.6552372, -0.25635794, -0.036170483, -0.23200338, 0.01889438, -0.097646244, -0.15389965, -0.23462152, 0.18851413, 0.0076038516, 0.010953386, -0.2332509, -0.10212622, -0.13861312, -0.13700847, 0.016385317, 0.19486766, 0.06277286, -0.23112124, 0.13120462, 0.13358603, -0.11475045, -0.13382666, -0.035111766, 0.11990768, -0.25910866, -0.009895128, 0.17758016, -0.036606345, 0.0941535, 0.3433845, 0.17842154, 0.01643473, 0.08795637, -0.07616535, -0.0436012, 0.000455294, -0.121252336, -0.0013583004, 0.0583397, 0.1034138, 0.11257818, -0.045298487, -0.018105632, -0.24825664, -0.07707361, 0.08062173, 0.21823074, 0.0935721, -0.16996332, 0.041773025, -0.03361723, -0.10117158, 0.039140753, -0.119583994, -0.007861577, 0.04633203, -0.039553788, -0.042258706, 0.14451635, -0.15027907, -0.1178965, -0.24297042, 0.23610426, -0.049820364, 0.024014056, 0.06768489, 0.22818506, 0.22168589, -0.09559703, 0.0012501627, -0.26942763, 0.12100495, -0.02186016, 0.30417192, 0.004784877, 0.35532287, 0.14621164, -0.053736586, 0.16206707, 0.113309145, 0.027553244, 0.031797994, 0.0033538055, 0.5112802, -0.14305508, -0.05190814, 0.5990819, -0.13236909, 0.0074968985, -0.19106297, 0.17155205, -0.38699624, 0.09865692, 0.052363027, -0.225613, 0.28460586, 0.055026192, 0.10768172, 0.3772324, 0.002106121, -0.1802681, 0.09384406, -0.00320446, -0.0505378, 0.16021551, -0.13924386, -0.025722787, -0.3087569, 0.004384853, -0.0038029451, -0.2778689, 0.16499354, 0.34819007, -0.03060996, 0.24109001, 0.059646178]}, "content": "Cool. Nice. Yeah. So as I mentioned before, we talked about modal, I mentioned benchmarks and of course there is ANN benchmarks, which is, I would say, the de facto standard for comparing yeah, comparing a vector search. I don't want to say either libraries or databases, I guess you technically have a mix of them in there, but maybe I'm just going to say algorithms and their implementations. Would that be correct? ", "podNum": 25, "speaker": "Etienne Dilocker"}, {"_additional": {"id": "fd1cfc5e-904f-4996-9d8d-ffae996d01b9", "vector": [0.17589991, -0.1885721, 0.09602726, -0.20273916, -0.035987888, -0.16113278, 0.07019194, -0.15364511, 0.16916557, 0.10488444, -0.06515991, -0.018784592, 0.19613169, -0.0006251335, 0.29076976, -0.052220687, -0.024768079, -0.43555364, -0.3294231, -0.050871912, -0.48564398, -0.14828289, 0.19682048, -0.026661346, -0.024968565, -0.14135154, 0.15496011, 0.14657754, -0.19994521, 0.056942213, 0.01789533, -0.057366073, 0.05814946, -0.095483534, -0.016058987, 0.17500384, 0.042335536, 0.026451105, -0.09077392, 0.007214854, -0.011839509, -0.5043538, -0.17881282, 0.1948096, 0.019288683, 0.13257457, 0.082920305, 0.10738331, 0.03171366, 0.086791836, 0.25359398, 0.11481107, 0.11038527, 0.16561975, -0.040396288, 0.48048174, -0.055607293, -0.08092282, -0.124224454, 0.06079029, 0.1900421, 0.026524842, -0.44211325, 0.6476876, 0.17399675, -0.23234707, -0.042153668, -0.16585453, -0.36410883, 0.2708544, -0.044654284, -0.024265572, 0.07724049, 0.32939824, -0.0041907975, 0.08592542, 0.27323058, -0.010934788, 0.14369297, 0.19123666, 0.24635585, -0.21839897, 0.10856555, -0.10921819, 0.12844525, -0.051919293, -0.26441368, 0.27694947, -0.14603014, -0.17232145, -0.52714574, 0.20783176, 0.31060913, -0.06520309, -0.07970599, 0.02302286, 0.07338317, -0.13067333, -0.3125446, 0.53850514, -0.20832974, 0.07560681, -0.35241437, -0.5009797, -0.05236399, -0.25951344, -0.13962333, -0.08673334, 0.10489484, -0.0028944686, -0.0659635, -0.12216383, -0.17085455, 0.22140627, -0.20806402, 0.037286792, -0.3544111, 0.14657055, 0.23527522, -0.53427625, -0.047573272, 0.03157775, -0.10240879, -0.29169258, -0.043354493, -0.40096822, 0.31112418, 0.20492764, -0.009497766, 0.2154655, -0.14118719, -0.07248748, 0.25297108, 0.2651153, -0.18568517, -0.15196104, 0.034558546, -0.08801993, -0.09033209, 0.0030557364, 0.3258963, 0.07114042, 0.3157384, -0.005297644, -0.25648335, 0.19412963, 0.26226485, -0.003023602, 0.2443621, -0.20879579, -0.022912862, 0.38736513, 0.24909987, -0.054220665, 0.16379969, 0.09061977, 0.31663346, -0.01433409, 0.17623864, 0.1523922, -0.08660197, 0.034066327, 0.15821467, -0.031994414, -0.14069904, -0.18298036, -0.052502993, 0.13543881, -0.14383797, 0.07090951, -0.33199605, 0.17409885, 0.3582375, 0.051598415, 0.043616205, -0.083068065, 0.17392814, 0.10242638, 0.090815715, 0.1238451, -0.24695282, 0.0036761214, -0.048641637, 0.06389118, -0.048794482, -0.20181203, -0.15456434, -0.23997027, 0.011992444, -0.58778673, -0.17554964, -0.14097403, -0.11443556, 0.2095108, 0.317807, 0.02907367, 0.06485353, 0.08171043, 0.21562617, -0.02137302, -0.4650921, -0.19938916, -0.010293476, -0.026919892, 0.23392312, -0.043272316, 0.47195005, 0.03514311, -0.07141825, -0.07265382, -0.0069904528, -0.017340949, 0.09753581, 0.28558365, 0.21239744, -0.17861034, -0.27227423, 0.2591913, 0.050160438, 0.03780061, -0.055444926, 0.12811467, 0.13780473, -0.68809223, -0.05049013, -0.2301151, -0.0503561, 0.24034588, 0.34322944, -0.06368202, 0.3040985, 0.18272944, -0.3342079, 0.088930964, -0.2713977, -0.094441004, 0.20660184, 0.011219889, -0.2159435, -0.3031117, 0.0748167, -0.031918123, 0.022960538, 0.052775647, 0.081008404, 0.3731805, -0.20358463, 0.30687755, -0.12532005, 0.34457088, -0.21356185, -0.15272902, -0.47052094, 0.18553905, -0.21168192, -0.1765089, -0.46969804, -0.0062928894, 0.008875132, 0.3667359, 0.43929258, -0.19508868, -0.06846079, -0.11285689, 0.022999907, -0.2849873, -0.09362524, 0.63572437, -0.20005201, 0.12556659, -0.04063553, 0.22782852, -0.030373437, 0.0024205893, -0.082397304, 0.10879984, 0.09678972, -0.016602451, -0.15389197, 0.2170219, -0.09115557, -0.22955765, 0.0059121572, 0.06259731, -0.08950225, -0.13234164, 0.25500926, 0.18742101, 0.13347067, 0.122073494, 0.1061276, 0.27383667, -0.14113866, 0.23435605, 0.0148195475, -0.047120307, -0.14821573, 0.17322409, 0.18228555, 0.2534191, 0.040009305, 0.028950289, -0.053927064, -0.096585415, -0.047837775, -0.11032944, -0.13533956, 0.12137282, 0.1990617, -0.13229947, 0.20896627, -0.2446271, -0.08119281, 0.003397584, -0.091439314, -0.13015516, -0.17284428, -0.07812851, 0.09040909, -0.19794445, 0.15022905, 0.17068255, -0.14888604, 0.0014475087, -0.00027026236, 0.30180055, 0.024153696, -0.0037046222, 0.09186208, -0.066371046, 0.00879167, -0.046639185, -0.17267786, 0.22209334, 0.37141755, 0.32187125, -0.19694458, 0.11567571, -0.19398068, 0.13439196, 0.08183343, 0.078091584, 0.10327413, 0.24019922, 0.16002034, 0.079598375, 0.059121236, 0.3557352, 0.07677071, -0.16534968, -0.33755347, -0.060121525, -0.15682936, 0.008034541, 0.10442302, -0.1568446, -0.34282652, -0.25553843, 0.38790247, -0.7193896, 0.15630187, 0.27757725, -0.05904174, 0.41140285, -0.35333464, 0.2723308, -0.06049789, 0.2159586, -0.24811812, 0.09559671, -0.07687323, -0.13786077, 0.21322681, -0.12577543, 0.17284065, -0.24587037, -0.006024131, -0.021897009, -0.07521932, 0.01564286, 0.24729836, 0.048656702, 0.4810799, -0.16576219]}, "content": "It's an opportunity for us. Yeah. For some reason, they won't connect it to the internet, but we're happy to. ", "podNum": 30, "speaker": "Chris Dossman"}, {"_additional": {"id": "fe2623ff-9623-4fc9-9eb4-0795f031c48d", "vector": [-0.031564325, -0.18024457, -0.08311471, -0.15716565, 0.057995584, -0.15477252, -0.08285622, -0.0843879, -0.011786912, 0.029070426, -0.027709447, 0.3159753, 0.074221775, 0.021648249, 0.16335377, -0.08868201, -0.00355776, -0.13541704, -0.38009113, -0.036982324, -0.14960681, -0.19522145, -0.09784399, -0.06238257, 0.11751139, 0.11598271, -0.018852443, 0.0032303208, -0.19618648, -0.16644026, 0.0039437357, 0.08395055, 0.017786494, -0.041601215, 0.02215194, 0.10974191, -0.03600205, 0.0770624, -0.0030186945, -0.040679753, -0.06806793, -0.07116885, -0.13679837, 0.14880857, 0.121763155, -0.05701185, -0.012121069, 0.070499234, 0.08387299, 0.05796941, -0.05441556, -0.07497434, -0.005762412, -0.028960327, -0.11440987, 0.20045558, 0.11513467, -0.008482798, 0.017510314, 0.12404729, 0.07501679, -0.19644365, -0.10689768, 0.31610447, 0.118164875, -0.060231168, 0.0044231424, -0.1696614, -0.14286393, 0.23536903, -0.16916418, -0.15709431, -0.18086827, 0.08399963, -0.013598596, 0.060719173, 0.0411792, -0.0745451, 0.12839398, -0.021457851, -0.11503862, -0.09042354, 0.06374079, 0.06842986, 0.009660674, 0.09640643, 0.19048043, 0.11296615, 0.21334314, -0.122433454, -0.060162377, -0.032350965, 0.09180765, -0.028929163, -0.04581209, 0.099613756, 0.047312822, -0.19260062, 0.027989775, 0.068637274, -0.17463171, -0.06590429, -0.014234683, -0.41557056, 0.051303513, -0.27860403, 0.11887006, 0.052793693, 0.08544968, -0.057963297, 0.01277348, 0.10838938, 0.086031206, -0.08161199, -0.03136426, 0.06236948, -0.23258457, 0.006007402, 0.13443734, -0.041571077, 0.15218873, 0.034733687, 0.025760712, -0.043065157, 0.023445247, -0.17993756, 0.08983825, 0.21700126, -0.031967644, -0.035626173, 0.021364085, 0.033009715, 0.08421676, 0.06352377, -0.014969345, -0.00041461084, 0.061419062, -0.051408738, -0.028615642, 0.18025017, -0.06319219, 0.30091465, 0.20523955, -0.020829689, -0.16766976, 0.36570585, -0.12261977, -0.010931024, -0.028829498, -0.27475742, -0.093848586, 0.06952529, 0.2295489, -0.044476744, 0.03408099, -0.0016343798, 0.10873767, 0.09705454, 0.031790674, -0.14082403, -0.22629347, 0.06950318, -0.13152118, 0.0036187489, 0.09693851, -0.035393033, 0.049691226, -0.00045590103, -0.119824946, 0.14232163, 0.015584998, -0.087388106, -0.08339173, -0.03018165, 0.04911834, 0.02721317, -0.15467599, -0.01941994, 0.0109342905, 0.1522264, 0.1317495, 0.12473154, 0.064987496, 0.1447227, -0.06335163, -0.1305636, 0.004965769, 0.029968986, -0.1011975, -0.0047203247, -0.08781299, 0.084729716, 0.013950041, 0.20718779, -0.018381555, 0.01651634, 0.18595836, 0.15744808, -0.110002846, -0.011839986, -0.19901854, -0.15993929, -0.08087, -0.12610891, 0.08966309, -0.0038353512, 0.077916935, -0.06595143, 0.062458646, 0.07211062, -0.024258498, -0.11656872, 0.048826672, 0.09189716, 0.100819275, -0.04918667, -0.14832698, -0.011311462, -0.20750576, -0.039437484, 0.006442859, -0.11983517, 0.079054736, -0.43285066, -0.18882889, -0.2437218, 0.0033466928, 0.063818865, 0.04530502, 0.061645225, 0.15669023, -0.0138552, -0.010138867, 0.14721414, -0.19649792, 0.014541288, 0.10127886, -0.012517028, 0.00076330267, 0.080062926, -0.0073084906, -0.010929031, 0.0932481, -0.028366845, -0.021557026, 0.119320124, -0.11504939, 0.24704036, 0.11927664, 0.13234517, -0.15463251, -0.061118543, -0.107989594, 0.073146656, -0.26523656, -0.16967314, -0.3117507, 0.11100921, -0.037597716, 0.017614972, 0.2028271, -0.25103143, 0.012021685, 0.034786772, 0.09581156, -0.07387175, -0.03451424, 0.16814251, -0.21169356, -0.09466644, -0.05997204, 0.14548755, 0.043900564, 0.025779027, 0.1136704, 0.13150702, 0.11252345, -0.18118289, -0.22092158, 0.094645694, -0.0248532, -0.16000265, 0.012499971, 0.24431373, -0.05640603, -0.21861005, 0.05213636, 0.06929977, 0.124099694, -0.1768346, 0.05434528, 0.11509689, -0.07054162, -0.016354224, 0.021417405, 0.10307385, 0.03228321, 0.09725878, 0.13930026, 0.15696812, 0.10401829, -0.0193967, -0.11546794, -0.06753917, 0.01443526, -0.0009203749, 0.13045561, 0.18509483, 0.10530727, 0.027599901, 0.08686057, 0.0207427, -0.046194367, 0.108589545, -0.07023167, 0.017613888, -0.10670075, 0.20835137, -0.03577745, -0.063405275, 0.012917829, -0.011486588, 0.12482754, 0.28888655, 0.040533744, 0.13077852, 0.02676307, 0.20246473, -0.037015166, -0.121961504, 0.18561456, -0.056085624, -0.11562049, 0.12930161, 0.08318353, 0.15989593, -0.085606664, 0.084381536, -0.09464702, 0.073260866, 0.092200905, 0.15279973, 0.025156744, 0.07528441, 0.05814618, 0.09630088, 0.051684856, 0.3018639, 0.018253634, 0.028279182, -0.089084156, 0.10378013, -0.03919994, 0.058452625, 0.10003576, 0.00066865236, -0.1523853, -0.02598384, -0.0022922773, -0.22567677, 0.031480137, -0.09405776, -0.1732726, 0.23931614, -0.15929279, -0.021132262, -0.139418, -0.16255221, -0.0046008993, 0.00095729716, 0.029456362, -0.050503217, 0.07762867, 0.07692684, 0.22803017, -0.15540014, 0.018703079, -0.0982708, -0.1250668, 0.29198706, 0.029563496, 0.06349761, 0.14537895, 0.036261205]}, "content": "Yeah, I think it's another excellent, you know, topic to think about because I've been consulting a few startups that are trying to build vector search, right? And they sort of get quickly far ahead, you know, because they have, let's say, a database, a vector database, they have their data, obviously, they've chosen the model to vectorize with. They're already scratching the relevancy side of things. But then someone comes in and says, hey, we just received another batch of objects. We have half a million, you know, objects to index. Can you please index them? And by the way, I have a demo tomorrow, right? So what options do you have, right? And literally, some of the developers would reach out to me and say, hey, any options, anything to save this situation? And you know, like, of course, naively, what you can do is that you can start writing a Python or Java, you know, concurrent app, which will start unpacking this, you know, datasets, you know, reading from S3 or something like that. And then vectorizing, you hear the problem that, oh, you need to use GPU to speed things up and that's quite costly. So we need to kind of like, rethink a lot of things and not make a mistake if we launch this in batch mode, and it will run for two weeks. So you go back to your manager and say, it's going to take two weeks and they're like, what? And how much is it? $5,000. Oh my God. So like, each time we crawl the data, you're going to need $5,000 in two weeks. That's like going out of hand, right? And so, especially what you mentioned in Jina, and also there is a framework called txt.ai, which I learned just, you know, by kind of like Googling inside GitHub, if I can say that. So they have this notion of kind of this workflow. So for example, as you said, in Jina, you can have an executor that will read kind of like an archive and basically iterate PDF files and then transform, parse the textual content out of a PDF file, and then it proceeds to the next stage, right? And txt.ai, for example, also has, you know, some connectors for other types of data, like in computer vision space or automatic speech recognition space. And so they have different like workflows that will help you set things up really quickly. They have one demo app on Hugging Face Spaces, which essentially what it does is that it goes to Hacker News front page, it scrapes, you know, the top links, and then it indexes the titles, you know, of that top page, the top on that front page, and then it shows a search box. So it basically indexes all these titles, you know, embeds them on the fly. And then basically, when it's ready, you have the search box appearing on the screen, and now you're ready to query it. And so it is that easy. And they show, you know, how easy it is. Of course, it's not what you will use in production setting, most likely, you know, like in production, you want to have like a workflow that routinely goes and checks that front page, you know, like a cron tab, and then indexes that. And you still have the index that is serving the query. So you have some offline index, which is being prepared, and then you do the swap, you know, and things like that. But they also simplify things like deploying on Kubernetes, so you can scale things up. Because like, literally, if you if you write your own Python app, and one of the startups, by the way, there was a bottleneck, specifically in this component that would read the objects, one by one, and then it would try to classify the object and then embed it. And then it proceeds to the next step. And it was like, I think it was like single thread application, which would kind of like take forever. And it was very convoluted, right? Because if you don't have the framework in your hands, you start reinventing the wheel. And so most likely, you will kind of cut the corners. And you will be basically wasting time, unless you have a lot of time, which usually is not the case in startups, like you need to build something really quickly. And so this is this is something that I think is probably, you know, hasn't been in the minds of the makers, maybe like more than a year ago. But I think it becomes more and more important that you don't just bring the vector search core functionality, you don't just sell the statement that, hey, move to neural search, and all your problems will be solved. But you can actually show the path to get there, right? And with these workflows that process the data, access the data quickly, and allow you to do this repeatedly, is going to win more customers. ", "podNum": 34, "speaker": "Dmitry"}, {"_additional": {"id": "ff5dbeac-e332-45ab-b5aa-ff2b9d80f0ca", "vector": [-0.03182958, -0.18982935, -0.05777272, -0.24051225, 0.0020765867, -0.091455445, -0.07784882, -0.113615975, 0.049695, 0.007438807, 0.024049, 0.15594502, 0.13164954, -0.019762227, 0.31832278, -0.11225871, 0.011550326, -0.06217315, -0.52086985, 0.08711879, -0.0126872435, -0.117112964, -0.0746986, -0.07717535, -0.0388085, 0.015390398, 0.103503555, 0.040038675, -0.15420012, -0.16259311, -0.08022704, 0.08394328, 0.062354814, 0.003128238, -0.017359314, 0.038195446, 0.06875459, 0.063309714, -0.038061142, 0.0063279513, -0.054142766, -0.19908643, -0.041261304, 0.15438783, 0.06424316, -0.086248845, -0.06858905, 0.009649344, -0.095522456, 0.16354859, -0.063829996, -0.011981772, -0.08652062, -0.15468776, -0.07813709, 0.10052736, 0.117839396, -0.07433904, -0.09918878, 0.11077594, -0.11206696, -0.045613043, -0.028999593, 0.28597677, 0.16290689, -0.02246557, -0.012977635, -0.04886859, -0.03050014, 0.1550241, -0.13746357, -0.125878, -0.14616704, 0.054109607, -0.10025351, -0.0020038933, 0.14293665, 0.07529007, 0.12767011, -0.026069548, -0.09138855, -0.08388668, 0.026080566, 0.06366326, -0.022991799, -0.054715708, 0.1551812, 0.1350992, 0.06089646, -0.12043409, -0.231547, -0.22957593, 0.052891396, 0.030198902, -0.1915164, 0.21678299, -0.055683102, -0.14809778, 0.1704799, 0.09193573, -0.3029531, 0.033108428, -0.1348891, -0.18562832, 0.13116767, -0.24978068, -0.027326778, -0.06275113, 0.15085065, -0.15239125, 0.0017563393, 0.060952436, 0.14105734, -0.0759068, -0.050424214, -0.21137747, -0.06991525, 0.12063999, -0.025647044, -0.3245445, 0.07819918, -0.05896496, 0.11286102, -0.030504398, 0.023888353, -0.14981224, 0.09013974, 0.13636346, 0.093610294, -0.114598766, 0.21679325, -0.065095276, 0.11083296, 0.1693906, -0.15085849, -0.1646362, 0.043599475, 0.00938472, -0.08932087, 0.02352737, 0.019490344, 0.16997698, 0.16149819, 0.20257366, -0.31100002, 0.19556087, -0.055206, 0.017004613, 0.07388033, -0.24353413, 0.12030885, -0.044454932, 0.2524803, -0.07160727, 0.024034502, -0.05914246, -0.004966855, 0.06999244, -0.08693458, -0.061411984, -0.22852759, 0.1474104, -0.08664846, -0.09204992, 0.26125827, 0.036445227, 0.001256126, 0.2072353, 0.17655721, 0.121135995, 0.110476576, 0.025648916, -0.10519649, -0.1630028, 0.009497171, 0.044207826, -0.29511547, -0.06679922, 0.0063692844, 0.094676204, 0.076153934, -0.03582757, 0.14080146, 0.12878963, -0.044470757, -0.11415145, -0.025032267, -0.009419242, -0.14569522, -0.20057069, 0.12544349, 0.07919388, 0.014388282, 0.1550749, -0.15189078, -0.16297913, 0.17414308, 0.079437315, -0.13075036, -0.096432075, -0.2863617, -0.18061891, -0.069087304, -0.12090179, 0.09140534, -0.0758733, 0.21756716, -0.10109544, 0.06523716, 0.13597162, -0.03146766, -0.09278139, -0.054354973, 0.20271331, 0.20519152, -0.03184639, -0.1435714, -0.003904801, -0.22101472, -0.04773231, -0.04958453, -0.21031523, 0.035548482, -0.3644687, -0.18591723, 0.023302436, 0.0075420476, 0.04527368, 0.16525318, 0.035832524, 0.2619126, -0.0018703546, -0.14430079, 0.20466788, -0.08388116, -0.08595466, 0.2196787, -0.08359981, 0.009889044, 0.099026054, -0.043068253, -0.084773205, -0.09257396, 0.020588854, -0.057535667, 0.17545314, -0.18794802, 0.22467521, 0.08924265, 0.10555647, -0.13257295, -0.050893724, -0.02444094, 0.1881792, -0.17015581, -0.00548142, -0.17736438, 0.14336261, -0.05655923, 0.24764341, 0.3305878, -0.28171667, 0.02673268, -0.08752716, 0.028036406, -0.07438314, -0.102049336, 0.14828618, -0.25031665, -0.11296849, -0.0019115545, 0.27545208, 0.00029689772, -0.017540343, 0.077305734, 0.16031669, -0.09279984, -0.12809625, -0.2676471, -0.022848142, -0.0060221907, -0.28673738, -0.013798501, 0.14348991, 0.00073608337, -0.17340244, 0.11533852, 0.023036122, 0.08939518, -0.0856272, -0.03467064, 0.25502494, -0.06795275, -0.010335656, 0.14558896, -0.034953777, 0.10701075, 0.2971462, 0.2250185, 0.04962404, -0.12883815, -0.06846376, -0.09810289, 0.014128494, -0.037851296, -0.05986984, 0.14443621, 0.15678503, 0.22904502, 0.116662435, 0.04412038, -0.04546574, -0.07372489, 0.051795855, -0.054064482, -0.00024952553, -0.15188858, 0.24474373, -0.07014119, 0.013853184, -0.017964672, -0.10483862, 0.16090374, 0.28118014, 0.05873927, 0.12836523, 0.0784163, 0.09638936, -0.027652752, -0.07476238, 0.018182848, 0.083702065, 0.0022953022, 0.115706936, 0.17869195, 0.30900696, 0.045992155, -0.050442338, -0.11964231, 0.19713904, 0.1241965, 0.22334763, -0.11362812, 0.09108502, 0.16500053, 0.047467437, 0.030330956, 0.32448587, -0.0063595492, 0.1295941, -0.03618674, 0.077018626, -0.029700426, 0.105051026, 0.1348924, -0.048213303, -0.017044166, -0.06492311, 0.09979109, -0.34304377, -0.00073637604, -0.033549868, -0.21906298, 0.44415918, -0.01414803, 0.11089807, -0.03971283, -0.34944433, -0.099075966, 0.09029043, -0.086867794, 0.051046163, 0.09637546, -0.06388291, 0.2314497, -0.029991925, -0.058380943, 0.047307067, -0.13269296, 0.290689, 0.03096011, 0.06623136, 0.2170714, -0.18808079]}, "content": "Yeah. I mean, that would be, again, you, you know, me, I only do dumb things. That would be the first dumb thing I'd try. What if you just literally take the row of the database, format it, basically treat it as a sentence, like put a little symbol between each of the items in the database, maybe give it the field name, like put it into a little record format. And then those are the sentences you train the language model on. I wonder what would happen. I wonder if that would be enough, given a sufficient amount of data for you to be able to query the model. Maybe you do need to pre-train it first on something that looks like C4 and then you train this. But really the question is just how do you shove the data into the model? And at that point, maybe new relations show up. Maybe the model has some pre-conceived notions if you pre-trained it on C4. But really at the end of the day, the question becomes in my mind, don't you want your data in your database in some sense? I also wonder whether you can have a language model that learns to do SQL queries on a database to extract data out of that the same way we're doing with Google or Wikipedia right now. We could kind of go either way, but the important part is allowing the model to find these new emergent soft relationships between data. Like I'm totally convinced now of the Weaviate mission in that sense. Like this is, you know, there's so much we can unlock from our data that we couldn't before by just letting the model figure out how things are connected in ways that are hard for us to write down. ", "podNum": 26, "speaker": "Jonathan Frankle"}]